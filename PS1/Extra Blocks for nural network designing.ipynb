{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "(n_inputs,dimension,hidden_in_each_layer) =(2,1,[6])\n",
    "lr = 0.001\n",
    "error=[]\n",
    "net = initialize_network(n_inputs,dimension, hidden_in_each_layer)\n",
    "(wts,b) = (net[2],net[3])\n",
    "a = feed_forward(net[0],wts,b)\n",
    "err = back_prop(net[0], net[1],a,wts)\n",
    "error.append(err[3])\n",
    "err[1]['br2'].shape\n",
    "# net[3]\n",
    "update = update_network(wts,b,err[0],err[1],lr)\n",
    "\n",
    "# err[2]\n",
    "# a['al'].shape\n",
    "# err[1]['br3']\n",
    "# a\n",
    "# a_relu['a1'].shape\n",
    "# net[0].shape\n",
    "# net[2]['w1'].shape\n",
    "# net[2]\n",
    "# net[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input=5\n",
    "dimensions=3\n",
    "n_hidden_layers = len(hidden_in_each_layer)\n",
    "wts={'w1':np.random.randn(n_input,dimensions) }\n",
    "b = {'b1':np.random.randn(hidden_in_each_layer[0],1)}\n",
    "for i in range(n_hidden_layers-1):\n",
    "    wts['w'+str(i+2)]= np.random.randn(hidden_in_each_layer[i],hidden_in_each_layer[i+1])       ## Weight Initialization\n",
    "    b['b'+str(i+2)] = np.random.randn(hidden_in_each_layer[i+1],1)\n",
    "wts['w'+str(n_hidden_layers+1)] = np.random.randn(hidden_in_each_layer[-1],1) \n",
    "b ['b'+str(n_hidden_layers+1)] = np.random.randn(1)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENPM 808X- Week4 - PID Implementation using Test Driven Development\n",
    "[![Build Status](https://travis-ci.com/anirudhtopiwala/ENPM-808X-Week4_Test_Driven_PID_Implementation.svg?branch=master)](https://travis-ci.com/anirudhtopiwala/ENPM-808X-Week4_Test_Driven_PID_Implementation)\n",
    "[![Coverage Status](https://coveralls.io/repos/github/anirudhtopiwala/ENPM-808X-Week4_Test_Driven_PID_Implementation/badge.svg?branch=master)](https://coveralls.io/github/anirudhtopiwala/ENPM-808X-Week4_Test_Driven_PID_Implementation?branch=master)\n",
    "---\n",
    "\n",
    "## TODO\n",
    "\n",
    "* Run the tests iteratively so we can compute the error function for derivative and integral terms.\n",
    "* Write a test for constructor for better code coverage.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Week 4 ENPM 808X Assignment\n",
    "This is a simple implementeation of a PID Controller.\n",
    "\n",
    "Pair B: \n",
    "* Part1 - Driver: **Anirudh Topiwala** Navigator: **Bharat Mathur** \n",
    "* Part2 - Driver: **Akash Guha**       Navigator: **Rohitkrishna Nambiar**\n",
    "\n",
    "## Standard install via command-line\n",
    "```\n",
    "git clone --recursive https://github.com/anirudhtopiwala/ENPM-808X Week4_Test_Driven_PID_Implementation.git\n",
    "cd <path to repository>\n",
    "mkdir build\n",
    "cd build\n",
    "cmake ..\n",
    "make\n",
    "Run tests: ./test/cpp-test\n",
    "Run program: ./app/shell-app\n",
    "```\n",
    "\n",
    "## Building for code coverage (for assignments beginning in Week 4)\n",
    "```\n",
    "sudo apt-get install lcov\n",
    "cmake -D COVERAGE=ON -D CMAKE_BUILD_TYPE=Debug ../\n",
    "make\n",
    "make code_coverage\n",
    "```\n",
    "This generates a index.html page in the build/coverage sub-directory that can be viewed locally in a web browser.\n",
    "\n",
    "## Working with Eclipse IDE ##\n",
    "\n",
    "## Installation\n",
    "\n",
    "In your Eclipse workspace directory (or create a new one), checkout the repo (and submodules)\n",
    "```\n",
    "mkdir -p ~/workspace\n",
    "cd ~/workspace\n",
    "git clone --recursive https://github.com/anirudhtopiwala/ENPM-808X-Week4_Test_Driven_PID_Implementation.git\n",
    "```\n",
    "\n",
    "In your work directory, use cmake to create an Eclipse project for an [out-of-source build] of cpp-boilerplate\n",
    "\n",
    "```\n",
    "cd ~/workspace\n",
    "mkdir -p boilerplate-eclipse\n",
    "cd boilerplate-eclipse\n",
    "cmake -G \"Eclipse CDT4 - Unix Makefiles\" -D CMAKE_BUILD_TYPE=Debug -D CMAKE_ECLIPSE_VERSION=4.7.0 -D CMAKE_CXX_COMPILER_ARG1=-std=c++14 ../cpp-boilerplate/\n",
    "```\n",
    "\n",
    "## Import\n",
    "\n",
    "Open Eclipse, go to File -> Import -> General -> Existing Projects into Workspace -> \n",
    "Select \"boilerplate-eclipse\" directory created previously as root directory -> Finish\n",
    "\n",
    "# Edit\n",
    "\n",
    "Source files may be edited under the \"[Source Directory]\" label in the Project Explorer.\n",
    "\n",
    "\n",
    "## Build\n",
    "\n",
    "To build the project, in Eclipse, unfold boilerplate-eclipse project in Project Explorer,\n",
    "unfold Build Targets, double click on \"all\" to build all projects.\n",
    "\n",
    "## Run\n",
    "\n",
    "1. In Eclipse, right click on the boilerplate-eclipse in Project Explorer,\n",
    "select Run As -> Local C/C++ Application\n",
    "\n",
    "2. Choose the binaries to run (e.g. shell-app, cpp-test for unit testing)\n",
    "\n",
    "\n",
    "## Debug\n",
    "\n",
    "\n",
    "1. Set breakpoint in source file (i.e. double click in the left margin on the line you want \n",
    "the program to break).\n",
    "\n",
    "2. In Eclipse, right click on the boilerplate-eclipse in Project Explorer, select Debug As -> \n",
    "Local C/C++ Application, choose the binaries to run (e.g. shell-app).\n",
    "\n",
    "3. If prompt to \"Confirm Perspective Switch\", select yes.\n",
    "\n",
    "4. Program will break at the breakpoint you set.\n",
    "\n",
    "5. Press Step Into (F5), Step Over (F6), Step Return (F7) to step/debug your program.\n",
    "\n",
    "6. Right click on the variable in editor to add watch expression to watch the variable in \n",
    "debugger window.\n",
    "\n",
    "7. Press Terminate icon to terminate debugging and press C/C++ icon to switch back to C/C++ \n",
    "perspetive view (or Windows->Perspective->Open Perspective->C/C++).\n",
    "\n",
    "\n",
    "## Plugins\n",
    "\n",
    "- CppChEclipse\n",
    "\n",
    "    To install and run cppcheck in Eclipse\n",
    "\n",
    "    1. In Eclipse, go to Window -> Preferences -> C/C++ -> cppcheclipse.\n",
    "    Set cppcheck binary path to \"/usr/bin/cppcheck\".\n",
    "\n",
    "    2. To run CPPCheck on a project, right click on the project name in the Project Explorer \n",
    "    and choose cppcheck -> Run cppcheck.\n",
    "\n",
    "\n",
    "- Google C++ Sytle\n",
    "\n",
    "    To include and use Google C++ Style formatter in Eclipse\n",
    "\n",
    "    1. In Eclipse, go to Window -> Preferences -> C/C++ -> Code Style -> Formatter. \n",
    "    Import [eclipse-cpp-google-style][reference-id-for-eclipse-cpp-google-style] and apply.\n",
    "\n",
    "    2. To use Google C++ style formatter, right click on the source code or folder in \n",
    "    Project Explorer and choose Source -> Format\n",
    "\n",
    "[reference-id-for-eclipse-cpp-google-style]: https://raw.githubusercontent.com/google/styleguide/gh-pages/eclipse-cpp-google-style.xml\n",
    "\n",
    "- Git\n",
    "\n",
    "    It is possible to manage version control through Eclipse and the git plugin, but it typically requires creating another project. If you're interested in this, try it out yourself and contact me on Canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Network Setup\n",
    "\n",
    "from random import seed\n",
    "from random import random\n",
    "# Initialize a network\n",
    "def initialize_network(n_inputs):\n",
    "    network = list()\n",
    "    output_layer = [{'weights':[random() for i in range(n_inputs + 1)]}] #n_inputs\n",
    "    network.append(output_layer)\n",
    "    return network\n",
    "\n",
    "# As there is no inlinearity, we staright away go to feedforward function and ignore the activation function\n",
    "\n",
    "# Calculating Feed Forward for an input\n",
    "def feed_forward(network, inputs):\n",
    "    layer = network[0]\n",
    "    neuron = layer[0]\n",
    "    weights= neuron['weights']\n",
    "    activation = weights[-1]\n",
    "    for i in range(len(weights)-1):\n",
    "        activation += weights[i] * inputs[i]\n",
    "    return activation\n",
    "\n",
    "# Back Propogation\n",
    "def back_prop(target,predict)\n",
    "    \n",
    "    error= target - output\n",
    "    \n",
    "\n",
    "\n",
    "# Training Network\n",
    "def train (inputs, targets)\n",
    "    for j in range(10):\n",
    "\n",
    "        out = feed_forward(network,inputs)\n",
    "        l0 = inputs\n",
    "        out = feed_forward(network,inputs)\n",
    "        error = targets - out\n",
    "        layer = network[0]\n",
    "        neuron = layer[0]\n",
    "        weights= neuron['weights']\n",
    "        for i in range(len(weights)):\n",
    "            activation += weights[i] * inputs[i]\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.12852687]\n",
      " [-2.16549733]\n",
      " [-3.00647868]\n",
      " [-0.74248302]\n",
      " [-0.9257383 ]\n",
      " [ 0.95648648]\n",
      " [ 2.73275444]\n",
      " [ 2.15003732]\n",
      " [ 0.96458299]\n",
      " [-1.10132318]]\n"
     ]
    }
   ],
   "source": [
    "n_inputs = 10\n",
    "dimensions= 3\n",
    "x= np.random.randn(n_inputs,dimensions)\n",
    "## Breaking the inputs such that, the first input goes to the sin curve and the rest adds on as linear functions\n",
    "x1=np.reshape(x[:,0],(n_inputs,1)) \n",
    "x2 = np.sum(x[:,1:],axis=1,keepdims= True) \n",
    "y= np.sin(x1) + x2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "lr=0.001\n",
    "net=initialize_network(2,6,4)\n",
    "a= feed_forward(net[0],net[2],net[3],net[4],net[5])\n",
    "err= back_prop(net[0], net[1],a[0],a[1],net[2],net[3])\n",
    "# net[2]\n",
    "# update = update_network(net[2], net[3],net[4],net[5], err[0], err[1],err[2],err[3],lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug\n",
    "a1 = feed_forward(net[0],net[2],net[3])\n",
    "err= back_prop(net[0], net[1],a1)\n",
    "# print(a1)\n",
    "# net[1]\n",
    "update = update_network(net[2], net[3], err[0], err[1],lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from math import exp\n",
    "\n",
    "# def nonlin(x, deriv = False):\n",
    "#     if (deriv == True):\n",
    "#         return 1 if (x>0) else 0\n",
    "#     return np.maximum(0,x)\n",
    "\n",
    "def nonlin(x, deriv = False):\n",
    "    if (deriv == True):\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def train (dataset):\n",
    "    # Weights for the first and only layer \n",
    "    lr= 0.001\n",
    "    wts = np.random.random((1,1))\n",
    "    b=np.random.random((1))\n",
    "    err = []\n",
    "    for j in range(1000):\n",
    "        er=0\n",
    "        for i in range(len(dataset)):\n",
    "            row = np.reshape(dataset[i,:],(1,2))\n",
    "            inp = np.reshape(row[0,0:row.size-1],(1,1))\n",
    "#             print(\"inp shape\"+ str(inp.shape))\n",
    "            target = row[0,row.size-1]\n",
    "#             print(\"target shape\"+ str(target.shape))\n",
    "            a1= np.dot(inp,wts)+b\n",
    "#             print(\"a1 shape\"+ str(a1.shape))\n",
    "            a1_error = target - a1 \n",
    "            err.append(a1_error)\n",
    "            er=er+ a1_error\n",
    "#             print(\"a1_error shape\"+ str(a1_error.shape))\n",
    "            wts = wts - lr*a1_error*inp\n",
    "#             b = b - lr*a1_error\n",
    "#             print(a1_error)\n",
    "#             print(wts)\n",
    "#             print(\"end of row\"+ str(i))\n",
    "        print(\"end of iteration\"+ str(j))\n",
    "        print(\"er\"+ str(er))\n",
    "        \n",
    "    print (\"Output after Training\")\n",
    "    print (a1_error)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = np.random.random((2,1))\n",
    "b=np.random.random((1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from math import exp\n",
    "seed(1)\n",
    "err= train(dataset)\n",
    "x= np.linspace(0,100,100)\n",
    "# plt.plot(x,err,'ro')\n",
    "print(err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = np.random.random((2,1))\n",
    "b=np.random.random((1))\n",
    "lr= 0.0001\n",
    "for i in range(len(dataset)):\n",
    "    row = np.reshape(dataset[i,:],(1,3))\n",
    "    inp = np.reshape(row[0,0:row.size-1],(1,2))\n",
    "#   print(\"inp shape\"+ str(inp.shape))\n",
    "    target = row[0,row.size-1]\n",
    "#   print(\"target shape\"+ str(target.shape))\n",
    "    a1= np.dot(inp,wts)+b\n",
    "#   print(\"a1 shape\"+ str(a1.shape))\n",
    "    a1_error = target - a1\n",
    "#   print(\"a1_error shape\"+ str(a1_error.shape))\n",
    "    wts = wts + lr*a1_error\n",
    "    b = b + lr*a1_error\n",
    "#     print(a1_error.sum())\n",
    "    print(wts)\n",
    "#     print(target)\n",
    "    print(\"end of row\"+ str(i))\n",
    "print(\"end of iteration\"+ str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = np.reshape(row[0,0:row.size-1],(1,inp.size))\n",
    "print(\"inp shape\"+ str(inp.shape))\n",
    "target = row[0,row.size-1]\n",
    "print(\"target shape\"+ str(target.shape))\n",
    "wts = np.random.random((inp.size,1))\n",
    "b=np.random.random((1))\n",
    "a1= np.dot(inp,wts)+b\n",
    "print(\"a1 shape\"+ str(a1.shape))\n",
    "a1_error = target - a1 * inp\n",
    "print(\"a1_error shape\"+ str(a1_error.shape))\n",
    "wts = wts + a1_error\n",
    "b = b + a1_error.sum()\n",
    "\n",
    "\n",
    "# syn.shape\n",
    "\n",
    "# assert(inputs.shape==targets.shape)\n",
    "# inputs.shape\n",
    "# inputs.size\n",
    "\n",
    "# len(inputs)\n",
    "# syn.shape\n",
    "# print(syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.random.random((10,1))\n",
    "inputs2= 4 * inputs\n",
    "targets = 8 * inputs\n",
    "dataset =  np.column_stack ((inputs,targets))\n",
    "print(dataset)\n",
    "print(dataset.shape)\n",
    "dataset.shape[0]\n",
    "# row = np.reshape(dataset[0,:],(1,row.size))\n",
    "# print(row)\n",
    "# # row.size\n",
    "# # row.shape\n",
    "# # row.size\n",
    "# # print(row[0])\n",
    "# # row.size\n",
    "# inp = np.reshape(row[0,0:row.size-1],(1,inp.size))\n",
    "# print(inp)\n",
    "# inp.shape\n",
    "# inp.size\n",
    "# # print(row(0:end).size)\n",
    "# out= row[0,row.size-1]\n",
    "# print(out)\n",
    "\n",
    "# print(inp.sum())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(inputs)\n",
    "# print(targets)\n",
    "# print((targets.shape))\n",
    "# np.random.seed(1)\n",
    "# print(len(dataset))\n",
    "train(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# To print and check the Network Weights\n",
    "seed(1)\n",
    "network = initialize_network(1)\n",
    "for layer in network:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = range(0,2)\n",
    "# input[4]\n",
    "\n",
    "feed_forward(network, input)\n",
    "# layer= network[0]\n",
    "# layer['weights'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Network Setup\n",
    "\n",
    "from random import seed\n",
    "from random import random\n",
    "# Initialize a network\n",
    "def initialize_network(n_inputs):\n",
    "    network = list()\n",
    "    output_layer = [{'weights':[random() for i in range(n_inputs + 1)]}] #n_inputs\n",
    "    network.append(output_layer)\n",
    "    return network\n",
    "\n",
    "# As there is no inlinearity, we staright away go to feedforward function and ignore the activation function\n",
    "\n",
    "# Calculating Feed Forward for an input\n",
    "def feed_forward(network, inputs):\n",
    "    layer = network[0]\n",
    "    neuron = layer[0]\n",
    "    weights= neuron['weights']\n",
    "    activation = weights[-1]\n",
    "    for i in range(len(weights)-1):\n",
    "        activation += weights[i] * inputs[i]\n",
    "    return activation\n",
    "\n",
    "# Back Propogation\n",
    "def back_prop(target,predict)\n",
    "    \n",
    "    error= target - output\n",
    "    \n",
    "\n",
    "\n",
    "# Training Network\n",
    "def train (inputs, targets)\n",
    "    for j in range(10):\n",
    "\n",
    "        out = feed_forward(network,inputs)\n",
    "        l0 = inputs\n",
    "        out = feed_forward(network,inputs)\n",
    "        error = targets - out\n",
    "        layer = network[0]\n",
    "        neuron = layer[0]\n",
    "        weights= neuron['weights']\n",
    "        for i in range(len(weights)):\n",
    "            activation += weights[i] * inputs[i]\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
