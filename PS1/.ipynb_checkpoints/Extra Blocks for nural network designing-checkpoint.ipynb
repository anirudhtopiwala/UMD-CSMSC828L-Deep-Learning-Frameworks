{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.12852687]\n",
      " [-2.16549733]\n",
      " [-3.00647868]\n",
      " [-0.74248302]\n",
      " [-0.9257383 ]\n",
      " [ 0.95648648]\n",
      " [ 2.73275444]\n",
      " [ 2.15003732]\n",
      " [ 0.96458299]\n",
      " [-1.10132318]]\n"
     ]
    }
   ],
   "source": [
    "n_inputs = 10\n",
    "dimensions= 3\n",
    "x= np.random.randn(n_inputs,dimensions)\n",
    "## Breaking the inputs such that, the first input goes to the sin curve and the rest adds on as linear functions\n",
    "x1=np.reshape(x[:,0],(n_inputs,1)) \n",
    "x2 = np.sum(x[:,1:],axis=1,keepdims= True) \n",
    "y= np.sin(x1) + x2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "lr=0.001\n",
    "net=initialize_network(2,6,4)\n",
    "a= feed_forward(net[0],net[2],net[3],net[4],net[5])\n",
    "err= back_prop(net[0], net[1],a[0],a[1],net[2],net[3])\n",
    "# net[2]\n",
    "# update = update_network(net[2], net[3],net[4],net[5], err[0], err[1],err[2],err[3],lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug\n",
    "a1 = feed_forward(net[0],net[2],net[3])\n",
    "err= back_prop(net[0], net[1],a1)\n",
    "# print(a1)\n",
    "# net[1]\n",
    "update = update_network(net[2], net[3], err[0], err[1],lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from math import exp\n",
    "\n",
    "# def nonlin(x, deriv = False):\n",
    "#     if (deriv == True):\n",
    "#         return 1 if (x>0) else 0\n",
    "#     return np.maximum(0,x)\n",
    "\n",
    "def nonlin(x, deriv = False):\n",
    "    if (deriv == True):\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def train (dataset):\n",
    "    # Weights for the first and only layer \n",
    "    lr= 0.001\n",
    "    wts = np.random.random((1,1))\n",
    "    b=np.random.random((1))\n",
    "    err = []\n",
    "    for j in range(1000):\n",
    "        er=0\n",
    "        for i in range(len(dataset)):\n",
    "            row = np.reshape(dataset[i,:],(1,2))\n",
    "            inp = np.reshape(row[0,0:row.size-1],(1,1))\n",
    "#             print(\"inp shape\"+ str(inp.shape))\n",
    "            target = row[0,row.size-1]\n",
    "#             print(\"target shape\"+ str(target.shape))\n",
    "            a1= np.dot(inp,wts)+b\n",
    "#             print(\"a1 shape\"+ str(a1.shape))\n",
    "            a1_error = target - a1 \n",
    "            err.append(a1_error)\n",
    "            er=er+ a1_error\n",
    "#             print(\"a1_error shape\"+ str(a1_error.shape))\n",
    "            wts = wts - lr*a1_error*inp\n",
    "#             b = b - lr*a1_error\n",
    "#             print(a1_error)\n",
    "#             print(wts)\n",
    "#             print(\"end of row\"+ str(i))\n",
    "        print(\"end of iteration\"+ str(j))\n",
    "        print(\"er\"+ str(er))\n",
    "        \n",
    "    print (\"Output after Training\")\n",
    "    print (a1_error)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = np.random.random((2,1))\n",
    "b=np.random.random((1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from math import exp\n",
    "seed(1)\n",
    "err= train(dataset)\n",
    "x= np.linspace(0,100,100)\n",
    "# plt.plot(x,err,'ro')\n",
    "print(err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = np.random.random((2,1))\n",
    "b=np.random.random((1))\n",
    "lr= 0.0001\n",
    "for i in range(len(dataset)):\n",
    "    row = np.reshape(dataset[i,:],(1,3))\n",
    "    inp = np.reshape(row[0,0:row.size-1],(1,2))\n",
    "#   print(\"inp shape\"+ str(inp.shape))\n",
    "    target = row[0,row.size-1]\n",
    "#   print(\"target shape\"+ str(target.shape))\n",
    "    a1= np.dot(inp,wts)+b\n",
    "#   print(\"a1 shape\"+ str(a1.shape))\n",
    "    a1_error = target - a1\n",
    "#   print(\"a1_error shape\"+ str(a1_error.shape))\n",
    "    wts = wts + lr*a1_error\n",
    "    b = b + lr*a1_error\n",
    "#     print(a1_error.sum())\n",
    "    print(wts)\n",
    "#     print(target)\n",
    "    print(\"end of row\"+ str(i))\n",
    "print(\"end of iteration\"+ str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = np.reshape(row[0,0:row.size-1],(1,inp.size))\n",
    "print(\"inp shape\"+ str(inp.shape))\n",
    "target = row[0,row.size-1]\n",
    "print(\"target shape\"+ str(target.shape))\n",
    "wts = np.random.random((inp.size,1))\n",
    "b=np.random.random((1))\n",
    "a1= np.dot(inp,wts)+b\n",
    "print(\"a1 shape\"+ str(a1.shape))\n",
    "a1_error = target - a1 * inp\n",
    "print(\"a1_error shape\"+ str(a1_error.shape))\n",
    "wts = wts + a1_error\n",
    "b = b + a1_error.sum()\n",
    "\n",
    "\n",
    "# syn.shape\n",
    "\n",
    "# assert(inputs.shape==targets.shape)\n",
    "# inputs.shape\n",
    "# inputs.size\n",
    "\n",
    "# len(inputs)\n",
    "# syn.shape\n",
    "# print(syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.random.random((10,1))\n",
    "inputs2= 4 * inputs\n",
    "targets = 8 * inputs\n",
    "dataset =  np.column_stack ((inputs,targets))\n",
    "print(dataset)\n",
    "print(dataset.shape)\n",
    "dataset.shape[0]\n",
    "# row = np.reshape(dataset[0,:],(1,row.size))\n",
    "# print(row)\n",
    "# # row.size\n",
    "# # row.shape\n",
    "# # row.size\n",
    "# # print(row[0])\n",
    "# # row.size\n",
    "# inp = np.reshape(row[0,0:row.size-1],(1,inp.size))\n",
    "# print(inp)\n",
    "# inp.shape\n",
    "# inp.size\n",
    "# # print(row(0:end).size)\n",
    "# out= row[0,row.size-1]\n",
    "# print(out)\n",
    "\n",
    "# print(inp.sum())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(inputs)\n",
    "# print(targets)\n",
    "# print((targets.shape))\n",
    "# np.random.seed(1)\n",
    "# print(len(dataset))\n",
    "train(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# To print and check the Network Weights\n",
    "seed(1)\n",
    "network = initialize_network(1)\n",
    "for layer in network:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = range(0,2)\n",
    "# input[4]\n",
    "\n",
    "feed_forward(network, input)\n",
    "# layer= network[0]\n",
    "# layer['weights'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Network Setup\n",
    "\n",
    "from random import seed\n",
    "from random import random\n",
    "# Initialize a network\n",
    "def initialize_network(n_inputs):\n",
    "    network = list()\n",
    "    output_layer = [{'weights':[random() for i in range(n_inputs + 1)]}] #n_inputs\n",
    "    network.append(output_layer)\n",
    "    return network\n",
    "\n",
    "# As there is no inlinearity, we staright away go to feedforward function and ignore the activation function\n",
    "\n",
    "# Calculating Feed Forward for an input\n",
    "def feed_forward(network, inputs):\n",
    "    layer = network[0]\n",
    "    neuron = layer[0]\n",
    "    weights= neuron['weights']\n",
    "    activation = weights[-1]\n",
    "    for i in range(len(weights)-1):\n",
    "        activation += weights[i] * inputs[i]\n",
    "    return activation\n",
    "\n",
    "# Back Propogation\n",
    "def back_prop(target,predict)\n",
    "    \n",
    "    error= target - output\n",
    "    \n",
    "\n",
    "\n",
    "# Training Network\n",
    "def train (inputs, targets)\n",
    "    for j in range(10):\n",
    "\n",
    "        out = feed_forward(network,inputs)\n",
    "        l0 = inputs\n",
    "        out = feed_forward(network,inputs)\n",
    "        error = targets - out\n",
    "        layer = network[0]\n",
    "        neuron = layer[0]\n",
    "        weights= neuron['weights']\n",
    "        for i in range(len(weights)):\n",
    "            activation += weights[i] * inputs[i]\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
