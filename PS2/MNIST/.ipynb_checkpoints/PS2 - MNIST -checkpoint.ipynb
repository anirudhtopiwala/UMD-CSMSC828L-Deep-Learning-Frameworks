{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify the data shown in the MNIST data\n",
    "\n",
    "\n",
    "* Do this using the best practices discussed in class (i.e. one hot encoding, ReLU, CNNS when you should, etc.)\n",
    "\n",
    "* Have reasonable hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anirudh/anaconda2/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.layers import Dense, Dropout, Lambda, Flatten, Activation, Dropout\n",
    "from mnist import MNIST #python-mnist package (available only through pip)\n",
    "import os\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImages = np.load('trainImages.npy')\n",
    "testImages = np.load('testImages.npy')\n",
    "trainLabels = np.load('trainLabels.npy')\n",
    "testLabels = np.load('testLabels.npy')\n",
    "\n",
    "\n",
    "#data from http://yann.lecun.com/exdb/mnist/\n",
    "#must be uncompresed without having been renamed\n",
    "# data = MNIST(os.getcwd())\n",
    "\n",
    "# trainImages, trainLabels = data.load_training()\n",
    "# testImages, testLabels = data.load_testing()\n",
    "\n",
    "# trainImages = np.reshape(trainImages,(60000,28,28,1)) #correct orientation, you can view the images and see below\n",
    "# testImages = np.reshape(testImages,(10000,28,28,1))\n",
    "\n",
    "# trainImages = trainImages.astype('uint8') #images loaded in as int64, 0 to 255 integers\n",
    "# testImages = testImages.astype('uint8')\n",
    "\n",
    "# \"\"\"\n",
    "# from matplotlib import pyplot as plt\n",
    "# #7 because it has a 3, so you know no flips have occured\n",
    "# #Second slice because matplotlib disapproves of 3D image arrays with only 1 channel\n",
    "# plt.imshow(trainImages[7][0,:,:], interpolation='nearest') \n",
    "# plt.show()\n",
    "# \"\"\"\n",
    "\n",
    "# trainLabels=keras.utils.to_categorical(trainLabels) #these preserve dtype\n",
    "# testLabels=keras.utils.to_categorical(testLabels)\n",
    "\n",
    "# trainLabels = trainLabels.astype('uint8')\n",
    "# testLabels = testLabels.astype('uint8')\n",
    "\n",
    "# np.save('trainImages.npy',trainImages)\n",
    "# np.save('testImages.npy',testImages)\n",
    "# np.save('trainLabels.npy',trainLabels)\n",
    "# np.save('testLabels.npy',testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainImages = trainImages.astype('float32') #images loaded in as int64, 0 to 255 integers\n",
    "\n",
    "trainImages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reorienting and Normalizing the data\n",
    "# trainImages = np.reshape(trainImages,(60000,28,28,1)) #correct orientation, you can view the images and see below\n",
    "# testImages = np.reshape(testImages,(10000,28,28,1))\n",
    "\n",
    "trainImages = trainImages.astype('float32') #images loaded in as int64, 0 to 255 integers\n",
    "testImages = testImages.astype('float32')\n",
    "trainImages /= 255\n",
    "testImages /= 255\n",
    "# trainImages = trainImages.astype('uint8') #images loaded in as int64, 0 to 255 integers\n",
    "# testImages = testImages.astype('uint8')\n",
    "\n",
    "# # convert to one-hot encoding\n",
    "# trainLabels=keras.utils.to_categorical(trainLabels1)\n",
    "\n",
    "\n",
    "# #converts it to binary\n",
    "# testLabels=keras.utils.to_categorical(testLabels1)\n",
    "\n",
    "# trainLabels = trainLabels.astype('uint8')\n",
    "# testLabels = testLabels.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testLabels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0fb623cbda0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# trainImages[0].shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# testImages[0].shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtestLabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'testLabels' is not defined"
     ]
    }
   ],
   "source": [
    "# trainImages[0].shape\n",
    "# testImages[0].shape\n",
    "testLabels.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the images first\n",
    "plt.figure(figsize=(12,10))\n",
    "x, y = 10, 4\n",
    "for i in range(40):  \n",
    "    plt.subplot(y, x, i+1)\n",
    "    plt.imshow(trainImages[i].reshape((28,28)),interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImages[1][:,:,0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "input_shape = (img_rows, img_cols,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testLabels.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "batch_size = 128\n",
    "num_classes = testLabels.shape[1]\n",
    "epochs = 12\n",
    "# create model\n",
    "# Hyper Parameters\n",
    "batch_size = 128\n",
    "num_classes = testLabels.shape[1]\n",
    "epochs = 12\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "    optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "h = model.fit(trainImages, trainLabels,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "validation_data=(testImages, testLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(testImages, testLabels, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at confusion matrix \n",
    "#Note, this code is taken straight from the SKLEARN website, an nice way of viewing confusion matrix.\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(testImages)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred, axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(testLabels, axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(h.history.keys())\n",
    "accuracy = h.history['acc']\n",
    "val_accuracy = h.history['val_acc']\n",
    "loss = h.history['loss']\n",
    "val_loss = h.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Errors are difference between predicted labels and true labels\n",
    "errors = (Y_pred_classes - Y_true != 0)\n",
    "\n",
    "Y_pred_classes_errors = Y_pred_classes[errors]\n",
    "Y_pred_errors = Y_pred[errors]\n",
    "Y_true_errors = Y_true[errors]\n",
    "X_val_errors = testImages[errors]\n",
    "\n",
    "def display_errors(errors_index,img_errors,pred_errors, obs_errors):\n",
    "    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n",
    "    n = 0\n",
    "    nrows = 2\n",
    "    ncols = 3\n",
    "    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            error = errors_index[n]\n",
    "            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n",
    "            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n",
    "            n += 1\n",
    "    \n",
    "# Probabilities of the wrong predicted numbers\n",
    "Y_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n",
    "\n",
    "# Predicted probabilities of the true values in the error set\n",
    "true_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n",
    "\n",
    "# Difference between the probability of the predicted label and the true label\n",
    "delta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n",
    "\n",
    "# Sorted list of the delta prob errors\n",
    "sorted_dela_errors = np.argsort(delta_pred_true_errors)\n",
    "\n",
    "# Top 6 errors \n",
    "most_important_errors = sorted_dela_errors[-6:]\n",
    "\n",
    "# Show the top 6 errors\n",
    "display_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
