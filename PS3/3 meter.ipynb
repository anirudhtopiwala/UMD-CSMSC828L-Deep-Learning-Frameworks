{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##  Create the best autoencoder for the three meter dataset you can (best measured by MAE, more info in file), noting that the network must have at least one layer with less than half the number of datapoints rounded down\n",
    "\n",
    "* Reasonable hyperparameters are all that is needed, please describe the optimization process in your writeup and do not make the hyperparameter search run by default\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# !pip install torchsummary \n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Training and Testing Data using Data Loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Training and Testing Data\n",
    "X = pd.read_csv('./Three Meter/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139201, 33)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the Data into Training and Test Data    trainImages.max(axis=0)\n",
    "X_train, X_test = train_test_split(X, test_size=0.15, shuffle = True)\n",
    "\n",
    "# batch_size\n",
    "batch = 256\n",
    "\n",
    "# Train Data Loader\n",
    "train = data_utils.TensorDataset(torch.from_numpy(X_train).float(),torch.from_numpy(X_train).float())\n",
    "train_loader = data_utils.DataLoader(train, batch_size=batch, shuffle=True)\n",
    "\n",
    "# Test Data loader\n",
    "test = data_utils.TensorDataset(torch.from_numpy(X_test).float(),torch.from_numpy(X_test).float())\n",
    "test_loader = data_utils.DataLoader(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showing the Training Data after Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data\n",
      "torch.Size([256, 33])\n"
     ]
    }
   ],
   "source": [
    "# Preview the training data\n",
    "for batch_idx, (data,label) in enumerate(train_loader):\n",
    "    print(\"Training Data\")\n",
    "    print(label.shape)\n",
    "\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Convolution Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=33, out_features=128, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (3): ReLU(inplace)\n",
       "    (4): Linear(in_features=64, out_features=12, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): Linear(in_features=12, out_features=3, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=12, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Linear(in_features=12, out_features=64, bias=True)\n",
       "    (3): ReLU(inplace)\n",
       "    (4): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): Linear(in_features=128, out_features=33, bias=True)\n",
       "    (7): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(33, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True), \n",
    "            nn.Linear(64, 12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(12, 3))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 33),\n",
    "            nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1              [256, 1, 128]           4,352\n",
      "              ReLU-2              [256, 1, 128]               0\n",
      "            Linear-3               [256, 1, 64]           8,256\n",
      "              ReLU-4               [256, 1, 64]               0\n",
      "            Linear-5               [256, 1, 12]             780\n",
      "              ReLU-6               [256, 1, 12]               0\n",
      "            Linear-7                [256, 1, 3]              39\n",
      "            Linear-8               [256, 1, 12]              48\n",
      "              ReLU-9               [256, 1, 12]               0\n",
      "           Linear-10               [256, 1, 64]             832\n",
      "             ReLU-11               [256, 1, 64]               0\n",
      "           Linear-12              [256, 1, 128]           8,320\n",
      "             ReLU-13              [256, 1, 128]               0\n",
      "           Linear-14               [256, 1, 33]           4,257\n",
      "             Tanh-15               [256, 1, 33]               0\n",
      "================================================================\n",
      "Total params: 26,884\n",
      "Trainable params: 26,884\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 1.73\n",
      "Params size (MB): 0.10\n",
      "Estimated Total Size (MB): 1.86\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net,input_size = (1,33),batch_size=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(net.parameters())\n",
    "# print(len(params))\n",
    "# print(params[0].size())  # conv1's .weight\n",
    "\n",
    "# params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Define a Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "train_loss =[]\n",
    "val_loss = []\n",
    "train_accu = []\n",
    "test_accu=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = net(data)\n",
    "#         print(target.dtype,output.dtype)\n",
    "# loss = criterion(output, output)\n",
    "# loss.backward()\n",
    "# optimizer.step()\n",
    "# torch.sum(output==target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch,device):\n",
    "    model.train()\n",
    "    training_loss = 0\n",
    "    lo = []\n",
    "    for batch_idx, (data,target) in enumerate(train_loader):\n",
    "        data,target = data.to(device), target.to(device)\n",
    "\n",
    "        #=====Forward====\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "         #=====Backward====\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #=== Loss Calculation\n",
    "        lo.append(loss.item()/batch)\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()/batch))\n",
    "    train_loss.append(np.mean(lo))\n",
    "\n",
    "def test(model, test_loader,device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    testlo = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            #== Forward===\n",
    "            output = model(data)\n",
    "            test_loss = criterion(output, target)\n",
    "            #=== Test loss====\n",
    "            testlo.append(test_loss.item()/batch)\n",
    "    val_loss.append(np.mean(testlo))\n",
    "    print('\\nTest set: Average loss: {:.4f}\\n'.format(np.mean(testlo)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/118320 (0%)]\tLoss: 0.003310\n",
      "Train Epoch: 1 [2560/118320 (2%)]\tLoss: 0.003252\n",
      "Train Epoch: 1 [5120/118320 (4%)]\tLoss: 0.003275\n",
      "Train Epoch: 1 [7680/118320 (6%)]\tLoss: 0.003264\n",
      "Train Epoch: 1 [10240/118320 (9%)]\tLoss: 0.003237\n",
      "Train Epoch: 1 [12800/118320 (11%)]\tLoss: 0.003290\n",
      "Train Epoch: 1 [15360/118320 (13%)]\tLoss: 0.003288\n",
      "Train Epoch: 1 [17920/118320 (15%)]\tLoss: 0.003258\n",
      "Train Epoch: 1 [20480/118320 (17%)]\tLoss: 0.003252\n",
      "Train Epoch: 1 [23040/118320 (19%)]\tLoss: 0.003256\n",
      "Train Epoch: 1 [25600/118320 (22%)]\tLoss: 0.003273\n",
      "Train Epoch: 1 [28160/118320 (24%)]\tLoss: 0.003262\n",
      "Train Epoch: 1 [30720/118320 (26%)]\tLoss: 0.003268\n",
      "Train Epoch: 1 [33280/118320 (28%)]\tLoss: 0.003273\n",
      "Train Epoch: 1 [35840/118320 (30%)]\tLoss: 0.003232\n",
      "Train Epoch: 1 [38400/118320 (32%)]\tLoss: 0.003281\n",
      "Train Epoch: 1 [40960/118320 (35%)]\tLoss: 0.003279\n",
      "Train Epoch: 1 [43520/118320 (37%)]\tLoss: 0.003295\n",
      "Train Epoch: 1 [46080/118320 (39%)]\tLoss: 0.003254\n",
      "Train Epoch: 1 [48640/118320 (41%)]\tLoss: 0.003275\n",
      "Train Epoch: 1 [51200/118320 (43%)]\tLoss: 0.003303\n",
      "Train Epoch: 1 [53760/118320 (45%)]\tLoss: 0.003241\n",
      "Train Epoch: 1 [56320/118320 (48%)]\tLoss: 0.003249\n",
      "Train Epoch: 1 [58880/118320 (50%)]\tLoss: 0.003294\n",
      "Train Epoch: 1 [61440/118320 (52%)]\tLoss: 0.003255\n",
      "Train Epoch: 1 [64000/118320 (54%)]\tLoss: 0.003252\n",
      "Train Epoch: 1 [66560/118320 (56%)]\tLoss: 0.003265\n",
      "Train Epoch: 1 [69120/118320 (58%)]\tLoss: 0.003252\n",
      "Train Epoch: 1 [71680/118320 (60%)]\tLoss: 0.003233\n",
      "Train Epoch: 1 [74240/118320 (63%)]\tLoss: 0.003225\n",
      "Train Epoch: 1 [76800/118320 (65%)]\tLoss: 0.003275\n",
      "Train Epoch: 1 [79360/118320 (67%)]\tLoss: 0.003287\n",
      "Train Epoch: 1 [81920/118320 (69%)]\tLoss: 0.003226\n",
      "Train Epoch: 1 [84480/118320 (71%)]\tLoss: 0.003281\n",
      "Train Epoch: 1 [87040/118320 (73%)]\tLoss: 0.003277\n",
      "Train Epoch: 1 [89600/118320 (76%)]\tLoss: 0.003309\n",
      "Train Epoch: 1 [92160/118320 (78%)]\tLoss: 0.003201\n",
      "Train Epoch: 1 [94720/118320 (80%)]\tLoss: 0.003290\n",
      "Train Epoch: 1 [97280/118320 (82%)]\tLoss: 0.003261\n",
      "Train Epoch: 1 [99840/118320 (84%)]\tLoss: 0.003264\n",
      "Train Epoch: 1 [102400/118320 (86%)]\tLoss: 0.003286\n",
      "Train Epoch: 1 [104960/118320 (89%)]\tLoss: 0.003288\n",
      "Train Epoch: 1 [107520/118320 (91%)]\tLoss: 0.003244\n",
      "Train Epoch: 1 [110080/118320 (93%)]\tLoss: 0.003296\n",
      "Train Epoch: 1 [112640/118320 (95%)]\tLoss: 0.003304\n",
      "Train Epoch: 1 [115200/118320 (97%)]\tLoss: 0.003259\n",
      "Train Epoch: 1 [117760/118320 (99%)]\tLoss: 0.003283\n",
      "\n",
      "Test set: Average loss: 0.0033\n",
      "\n",
      "Train Epoch: 2 [0/118320 (0%)]\tLoss: 0.003287\n",
      "Train Epoch: 2 [2560/118320 (2%)]\tLoss: 0.003274\n",
      "Train Epoch: 2 [5120/118320 (4%)]\tLoss: 0.003261\n",
      "Train Epoch: 2 [7680/118320 (6%)]\tLoss: 0.003324\n",
      "Train Epoch: 2 [10240/118320 (9%)]\tLoss: 0.003278\n",
      "Train Epoch: 2 [12800/118320 (11%)]\tLoss: 0.003268\n",
      "Train Epoch: 2 [15360/118320 (13%)]\tLoss: 0.003267\n",
      "Train Epoch: 2 [17920/118320 (15%)]\tLoss: 0.003262\n",
      "Train Epoch: 2 [20480/118320 (17%)]\tLoss: 0.003285\n",
      "Train Epoch: 2 [23040/118320 (19%)]\tLoss: 0.003227\n",
      "Train Epoch: 2 [25600/118320 (22%)]\tLoss: 0.003271\n",
      "Train Epoch: 2 [28160/118320 (24%)]\tLoss: 0.003261\n",
      "Train Epoch: 2 [30720/118320 (26%)]\tLoss: 0.003259\n",
      "Train Epoch: 2 [33280/118320 (28%)]\tLoss: 0.003274\n",
      "Train Epoch: 2 [35840/118320 (30%)]\tLoss: 0.003243\n",
      "Train Epoch: 2 [38400/118320 (32%)]\tLoss: 0.003229\n",
      "Train Epoch: 2 [40960/118320 (35%)]\tLoss: 0.003282\n",
      "Train Epoch: 2 [43520/118320 (37%)]\tLoss: 0.003278\n",
      "Train Epoch: 2 [46080/118320 (39%)]\tLoss: 0.003285\n",
      "Train Epoch: 2 [48640/118320 (41%)]\tLoss: 0.003284\n",
      "Train Epoch: 2 [51200/118320 (43%)]\tLoss: 0.003281\n",
      "Train Epoch: 2 [53760/118320 (45%)]\tLoss: 0.003304\n",
      "Train Epoch: 2 [56320/118320 (48%)]\tLoss: 0.003308\n",
      "Train Epoch: 2 [58880/118320 (50%)]\tLoss: 0.003299\n",
      "Train Epoch: 2 [61440/118320 (52%)]\tLoss: 0.003287\n",
      "Train Epoch: 2 [64000/118320 (54%)]\tLoss: 0.003229\n",
      "Train Epoch: 2 [66560/118320 (56%)]\tLoss: 0.003271\n",
      "Train Epoch: 2 [69120/118320 (58%)]\tLoss: 0.003288\n",
      "Train Epoch: 2 [71680/118320 (60%)]\tLoss: 0.003275\n",
      "Train Epoch: 2 [74240/118320 (63%)]\tLoss: 0.003306\n",
      "Train Epoch: 2 [76800/118320 (65%)]\tLoss: 0.003251\n",
      "Train Epoch: 2 [79360/118320 (67%)]\tLoss: 0.003271\n",
      "Train Epoch: 2 [81920/118320 (69%)]\tLoss: 0.003271\n",
      "Train Epoch: 2 [84480/118320 (71%)]\tLoss: 0.003290\n",
      "Train Epoch: 2 [87040/118320 (73%)]\tLoss: 0.003275\n",
      "Train Epoch: 2 [89600/118320 (76%)]\tLoss: 0.003268\n",
      "Train Epoch: 2 [92160/118320 (78%)]\tLoss: 0.003295\n",
      "Train Epoch: 2 [94720/118320 (80%)]\tLoss: 0.003262\n",
      "Train Epoch: 2 [97280/118320 (82%)]\tLoss: 0.003268\n",
      "Train Epoch: 2 [99840/118320 (84%)]\tLoss: 0.003263\n",
      "Train Epoch: 2 [102400/118320 (86%)]\tLoss: 0.003257\n",
      "Train Epoch: 2 [104960/118320 (89%)]\tLoss: 0.003302\n",
      "Train Epoch: 2 [107520/118320 (91%)]\tLoss: 0.003273\n",
      "Train Epoch: 2 [110080/118320 (93%)]\tLoss: 0.003271\n",
      "Train Epoch: 2 [112640/118320 (95%)]\tLoss: 0.003269\n",
      "Train Epoch: 2 [115200/118320 (97%)]\tLoss: 0.003246\n",
      "Train Epoch: 2 [117760/118320 (99%)]\tLoss: 0.003242\n",
      "\n",
      "Test set: Average loss: 0.0033\n",
      "\n",
      "Train Epoch: 3 [0/118320 (0%)]\tLoss: 0.003282\n",
      "Train Epoch: 3 [2560/118320 (2%)]\tLoss: 0.003241\n",
      "Train Epoch: 3 [5120/118320 (4%)]\tLoss: 0.003241\n",
      "Train Epoch: 3 [7680/118320 (6%)]\tLoss: 0.003268\n",
      "Train Epoch: 3 [10240/118320 (9%)]\tLoss: 0.003256\n",
      "Train Epoch: 3 [12800/118320 (11%)]\tLoss: 0.003248\n",
      "Train Epoch: 3 [15360/118320 (13%)]\tLoss: 0.003303\n",
      "Train Epoch: 3 [17920/118320 (15%)]\tLoss: 0.003318\n",
      "Train Epoch: 3 [20480/118320 (17%)]\tLoss: 0.003245\n",
      "Train Epoch: 3 [23040/118320 (19%)]\tLoss: 0.003250\n",
      "Train Epoch: 3 [25600/118320 (22%)]\tLoss: 0.003223\n",
      "Train Epoch: 3 [28160/118320 (24%)]\tLoss: 0.003272\n",
      "Train Epoch: 3 [30720/118320 (26%)]\tLoss: 0.003222\n",
      "Train Epoch: 3 [33280/118320 (28%)]\tLoss: 0.003256\n",
      "Train Epoch: 3 [35840/118320 (30%)]\tLoss: 0.003287\n",
      "Train Epoch: 3 [38400/118320 (32%)]\tLoss: 0.003289\n",
      "Train Epoch: 3 [40960/118320 (35%)]\tLoss: 0.003251\n",
      "Train Epoch: 3 [43520/118320 (37%)]\tLoss: 0.003328\n",
      "Train Epoch: 3 [46080/118320 (39%)]\tLoss: 0.003212\n",
      "Train Epoch: 3 [48640/118320 (41%)]\tLoss: 0.003248\n",
      "Train Epoch: 3 [51200/118320 (43%)]\tLoss: 0.003272\n",
      "Train Epoch: 3 [53760/118320 (45%)]\tLoss: 0.003250\n",
      "Train Epoch: 3 [56320/118320 (48%)]\tLoss: 0.003300\n",
      "Train Epoch: 3 [58880/118320 (50%)]\tLoss: 0.003242\n",
      "Train Epoch: 3 [61440/118320 (52%)]\tLoss: 0.003275\n",
      "Train Epoch: 3 [64000/118320 (54%)]\tLoss: 0.003228\n",
      "Train Epoch: 3 [66560/118320 (56%)]\tLoss: 0.003278\n",
      "Train Epoch: 3 [69120/118320 (58%)]\tLoss: 0.003255\n",
      "Train Epoch: 3 [71680/118320 (60%)]\tLoss: 0.003255\n",
      "Train Epoch: 3 [74240/118320 (63%)]\tLoss: 0.003239\n",
      "Train Epoch: 3 [76800/118320 (65%)]\tLoss: 0.003249\n",
      "Train Epoch: 3 [79360/118320 (67%)]\tLoss: 0.003208\n",
      "Train Epoch: 3 [81920/118320 (69%)]\tLoss: 0.003300\n",
      "Train Epoch: 3 [84480/118320 (71%)]\tLoss: 0.003226\n",
      "Train Epoch: 3 [87040/118320 (73%)]\tLoss: 0.003241\n",
      "Train Epoch: 3 [89600/118320 (76%)]\tLoss: 0.003268\n",
      "Train Epoch: 3 [92160/118320 (78%)]\tLoss: 0.003292\n",
      "Train Epoch: 3 [94720/118320 (80%)]\tLoss: 0.003264\n",
      "Train Epoch: 3 [97280/118320 (82%)]\tLoss: 0.003290\n",
      "Train Epoch: 3 [99840/118320 (84%)]\tLoss: 0.003287\n",
      "Train Epoch: 3 [102400/118320 (86%)]\tLoss: 0.003264\n",
      "Train Epoch: 3 [104960/118320 (89%)]\tLoss: 0.003319\n",
      "Train Epoch: 3 [107520/118320 (91%)]\tLoss: 0.003240\n",
      "Train Epoch: 3 [110080/118320 (93%)]\tLoss: 0.003238\n",
      "Train Epoch: 3 [112640/118320 (95%)]\tLoss: 0.003273\n",
      "Train Epoch: 3 [115200/118320 (97%)]\tLoss: 0.003277\n",
      "Train Epoch: 3 [117760/118320 (99%)]\tLoss: 0.003238\n",
      "\n",
      "Test set: Average loss: 0.0033\n",
      "\n",
      "Train Epoch: 4 [0/118320 (0%)]\tLoss: 0.003287\n",
      "Train Epoch: 4 [2560/118320 (2%)]\tLoss: 0.003249\n",
      "Train Epoch: 4 [5120/118320 (4%)]\tLoss: 0.003294\n",
      "Train Epoch: 4 [7680/118320 (6%)]\tLoss: 0.003217\n",
      "Train Epoch: 4 [10240/118320 (9%)]\tLoss: 0.003244\n",
      "Train Epoch: 4 [12800/118320 (11%)]\tLoss: 0.003295\n",
      "Train Epoch: 4 [15360/118320 (13%)]\tLoss: 0.003266\n",
      "Train Epoch: 4 [17920/118320 (15%)]\tLoss: 0.003253\n",
      "Train Epoch: 4 [20480/118320 (17%)]\tLoss: 0.003257\n",
      "Train Epoch: 4 [23040/118320 (19%)]\tLoss: 0.003280\n",
      "Train Epoch: 4 [25600/118320 (22%)]\tLoss: 0.003303\n",
      "Train Epoch: 4 [28160/118320 (24%)]\tLoss: 0.003306\n",
      "Train Epoch: 4 [30720/118320 (26%)]\tLoss: 0.003276\n",
      "Train Epoch: 4 [33280/118320 (28%)]\tLoss: 0.003263\n",
      "Train Epoch: 4 [35840/118320 (30%)]\tLoss: 0.003259\n",
      "Train Epoch: 4 [38400/118320 (32%)]\tLoss: 0.003235\n",
      "Train Epoch: 4 [40960/118320 (35%)]\tLoss: 0.003258\n",
      "Train Epoch: 4 [43520/118320 (37%)]\tLoss: 0.003281\n",
      "Train Epoch: 4 [46080/118320 (39%)]\tLoss: 0.003241\n",
      "Train Epoch: 4 [48640/118320 (41%)]\tLoss: 0.003262\n",
      "Train Epoch: 4 [51200/118320 (43%)]\tLoss: 0.003275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [53760/118320 (45%)]\tLoss: 0.003296\n",
      "Train Epoch: 4 [56320/118320 (48%)]\tLoss: 0.003231\n",
      "Train Epoch: 4 [58880/118320 (50%)]\tLoss: 0.003260\n",
      "Train Epoch: 4 [61440/118320 (52%)]\tLoss: 0.003276\n",
      "Train Epoch: 4 [64000/118320 (54%)]\tLoss: 0.003276\n",
      "Train Epoch: 4 [66560/118320 (56%)]\tLoss: 0.003260\n",
      "Train Epoch: 4 [69120/118320 (58%)]\tLoss: 0.003294\n",
      "Train Epoch: 4 [71680/118320 (60%)]\tLoss: 0.003258\n",
      "Train Epoch: 4 [74240/118320 (63%)]\tLoss: 0.003290\n",
      "Train Epoch: 4 [76800/118320 (65%)]\tLoss: 0.003272\n",
      "Train Epoch: 4 [79360/118320 (67%)]\tLoss: 0.003245\n",
      "Train Epoch: 4 [81920/118320 (69%)]\tLoss: 0.003245\n",
      "Train Epoch: 4 [84480/118320 (71%)]\tLoss: 0.003252\n",
      "Train Epoch: 4 [87040/118320 (73%)]\tLoss: 0.003249\n",
      "Train Epoch: 4 [89600/118320 (76%)]\tLoss: 0.003253\n",
      "Train Epoch: 4 [92160/118320 (78%)]\tLoss: 0.003235\n",
      "Train Epoch: 4 [94720/118320 (80%)]\tLoss: 0.003296\n",
      "Train Epoch: 4 [97280/118320 (82%)]\tLoss: 0.003249\n",
      "Train Epoch: 4 [99840/118320 (84%)]\tLoss: 0.003318\n",
      "Train Epoch: 4 [102400/118320 (86%)]\tLoss: 0.003292\n",
      "Train Epoch: 4 [104960/118320 (89%)]\tLoss: 0.003280\n",
      "Train Epoch: 4 [107520/118320 (91%)]\tLoss: 0.003306\n",
      "Train Epoch: 4 [110080/118320 (93%)]\tLoss: 0.003295\n",
      "Train Epoch: 4 [112640/118320 (95%)]\tLoss: 0.003261\n",
      "Train Epoch: 4 [115200/118320 (97%)]\tLoss: 0.003233\n",
      "Train Epoch: 4 [117760/118320 (99%)]\tLoss: 0.003285\n",
      "\n",
      "Test set: Average loss: 0.0033\n",
      "\n",
      "Train Epoch: 5 [0/118320 (0%)]\tLoss: 0.003276\n",
      "Train Epoch: 5 [2560/118320 (2%)]\tLoss: 0.003285\n",
      "Train Epoch: 5 [5120/118320 (4%)]\tLoss: 0.003264\n",
      "Train Epoch: 5 [7680/118320 (6%)]\tLoss: 0.003273\n",
      "Train Epoch: 5 [10240/118320 (9%)]\tLoss: 0.003228\n",
      "Train Epoch: 5 [12800/118320 (11%)]\tLoss: 0.003232\n",
      "Train Epoch: 5 [15360/118320 (13%)]\tLoss: 0.003241\n",
      "Train Epoch: 5 [17920/118320 (15%)]\tLoss: 0.003281\n",
      "Train Epoch: 5 [20480/118320 (17%)]\tLoss: 0.003260\n",
      "Train Epoch: 5 [23040/118320 (19%)]\tLoss: 0.003293\n",
      "Train Epoch: 5 [25600/118320 (22%)]\tLoss: 0.003257\n",
      "Train Epoch: 5 [28160/118320 (24%)]\tLoss: 0.003290\n",
      "Train Epoch: 5 [30720/118320 (26%)]\tLoss: 0.003223\n",
      "Train Epoch: 5 [33280/118320 (28%)]\tLoss: 0.003238\n",
      "Train Epoch: 5 [35840/118320 (30%)]\tLoss: 0.003252\n",
      "Train Epoch: 5 [38400/118320 (32%)]\tLoss: 0.003302\n",
      "Train Epoch: 5 [40960/118320 (35%)]\tLoss: 0.003268\n",
      "Train Epoch: 5 [43520/118320 (37%)]\tLoss: 0.003257\n",
      "Train Epoch: 5 [46080/118320 (39%)]\tLoss: 0.003233\n",
      "Train Epoch: 5 [48640/118320 (41%)]\tLoss: 0.003299\n",
      "Train Epoch: 5 [51200/118320 (43%)]\tLoss: 0.003267\n",
      "Train Epoch: 5 [53760/118320 (45%)]\tLoss: 0.003230\n",
      "Train Epoch: 5 [56320/118320 (48%)]\tLoss: 0.003275\n",
      "Train Epoch: 5 [58880/118320 (50%)]\tLoss: 0.003307\n",
      "Train Epoch: 5 [61440/118320 (52%)]\tLoss: 0.003271\n",
      "Train Epoch: 5 [64000/118320 (54%)]\tLoss: 0.003216\n",
      "Train Epoch: 5 [66560/118320 (56%)]\tLoss: 0.003283\n",
      "Train Epoch: 5 [69120/118320 (58%)]\tLoss: 0.003263\n",
      "Train Epoch: 5 [71680/118320 (60%)]\tLoss: 0.003275\n",
      "Train Epoch: 5 [74240/118320 (63%)]\tLoss: 0.003286\n",
      "Train Epoch: 5 [76800/118320 (65%)]\tLoss: 0.003264\n",
      "Train Epoch: 5 [79360/118320 (67%)]\tLoss: 0.003297\n",
      "Train Epoch: 5 [81920/118320 (69%)]\tLoss: 0.003303\n",
      "Train Epoch: 5 [84480/118320 (71%)]\tLoss: 0.003234\n",
      "Train Epoch: 5 [87040/118320 (73%)]\tLoss: 0.003271\n",
      "Train Epoch: 5 [89600/118320 (76%)]\tLoss: 0.003258\n",
      "Train Epoch: 5 [92160/118320 (78%)]\tLoss: 0.003262\n",
      "Train Epoch: 5 [94720/118320 (80%)]\tLoss: 0.003263\n",
      "Train Epoch: 5 [97280/118320 (82%)]\tLoss: 0.003256\n",
      "Train Epoch: 5 [99840/118320 (84%)]\tLoss: 0.003255\n",
      "Train Epoch: 5 [102400/118320 (86%)]\tLoss: 0.003265\n",
      "Train Epoch: 5 [104960/118320 (89%)]\tLoss: 0.003279\n",
      "Train Epoch: 5 [107520/118320 (91%)]\tLoss: 0.003284\n",
      "Train Epoch: 5 [110080/118320 (93%)]\tLoss: 0.003277\n",
      "Train Epoch: 5 [112640/118320 (95%)]\tLoss: 0.003279\n",
      "Train Epoch: 5 [115200/118320 (97%)]\tLoss: 0.003272\n",
      "Train Epoch: 5 [117760/118320 (99%)]\tLoss: 0.003245\n",
      "\n",
      "Test set: Average loss: 0.0033\n",
      "\n",
      "Train Epoch: 6 [0/118320 (0%)]\tLoss: 0.003251\n",
      "Train Epoch: 6 [2560/118320 (2%)]\tLoss: 0.003249\n",
      "Train Epoch: 6 [5120/118320 (4%)]\tLoss: 0.003260\n",
      "Train Epoch: 6 [7680/118320 (6%)]\tLoss: 0.003255\n",
      "Train Epoch: 6 [10240/118320 (9%)]\tLoss: 0.003294\n",
      "Train Epoch: 6 [12800/118320 (11%)]\tLoss: 0.003278\n",
      "Train Epoch: 6 [15360/118320 (13%)]\tLoss: 0.003249\n",
      "Train Epoch: 6 [17920/118320 (15%)]\tLoss: 0.003248\n",
      "Train Epoch: 6 [20480/118320 (17%)]\tLoss: 0.003260\n",
      "Train Epoch: 6 [23040/118320 (19%)]\tLoss: 0.003259\n",
      "Train Epoch: 6 [25600/118320 (22%)]\tLoss: 0.003278\n",
      "Train Epoch: 6 [28160/118320 (24%)]\tLoss: 0.003281\n",
      "Train Epoch: 6 [30720/118320 (26%)]\tLoss: 0.003260\n",
      "Train Epoch: 6 [33280/118320 (28%)]\tLoss: 0.003239\n",
      "Train Epoch: 6 [35840/118320 (30%)]\tLoss: 0.003280\n",
      "Train Epoch: 6 [38400/118320 (32%)]\tLoss: 0.003269\n",
      "Train Epoch: 6 [40960/118320 (35%)]\tLoss: 0.003268\n",
      "Train Epoch: 6 [43520/118320 (37%)]\tLoss: 0.003260\n",
      "Train Epoch: 6 [46080/118320 (39%)]\tLoss: 0.003260\n",
      "Train Epoch: 6 [48640/118320 (41%)]\tLoss: 0.003205\n",
      "Train Epoch: 6 [51200/118320 (43%)]\tLoss: 0.003250\n",
      "Train Epoch: 6 [53760/118320 (45%)]\tLoss: 0.003259\n",
      "Train Epoch: 6 [56320/118320 (48%)]\tLoss: 0.003235\n",
      "Train Epoch: 6 [58880/118320 (50%)]\tLoss: 0.003259\n",
      "Train Epoch: 6 [61440/118320 (52%)]\tLoss: 0.003257\n",
      "Train Epoch: 6 [64000/118320 (54%)]\tLoss: 0.003267\n",
      "Train Epoch: 6 [66560/118320 (56%)]\tLoss: 0.003260\n",
      "Train Epoch: 6 [69120/118320 (58%)]\tLoss: 0.003254\n",
      "Train Epoch: 6 [71680/118320 (60%)]\tLoss: 0.003284\n",
      "Train Epoch: 6 [74240/118320 (63%)]\tLoss: 0.003234\n",
      "Train Epoch: 6 [76800/118320 (65%)]\tLoss: 0.003273\n",
      "Train Epoch: 6 [79360/118320 (67%)]\tLoss: 0.003252\n",
      "Train Epoch: 6 [81920/118320 (69%)]\tLoss: 0.003263\n",
      "Train Epoch: 6 [84480/118320 (71%)]\tLoss: 0.003291\n",
      "Train Epoch: 6 [87040/118320 (73%)]\tLoss: 0.003278\n",
      "Train Epoch: 6 [89600/118320 (76%)]\tLoss: 0.003255\n",
      "Train Epoch: 6 [92160/118320 (78%)]\tLoss: 0.003224\n",
      "Train Epoch: 6 [94720/118320 (80%)]\tLoss: 0.003235\n",
      "Train Epoch: 6 [97280/118320 (82%)]\tLoss: 0.003252\n",
      "Train Epoch: 6 [99840/118320 (84%)]\tLoss: 0.003228\n",
      "Train Epoch: 6 [102400/118320 (86%)]\tLoss: 0.003251\n",
      "Train Epoch: 6 [104960/118320 (89%)]\tLoss: 0.003229\n",
      "Train Epoch: 6 [107520/118320 (91%)]\tLoss: 0.003237\n",
      "Train Epoch: 6 [110080/118320 (93%)]\tLoss: 0.003293\n",
      "Train Epoch: 6 [112640/118320 (95%)]\tLoss: 0.003249\n",
      "Train Epoch: 6 [115200/118320 (97%)]\tLoss: 0.003244\n",
      "Train Epoch: 6 [117760/118320 (99%)]\tLoss: 0.003274\n",
      "\n",
      "Test set: Average loss: 0.0033\n",
      "\n",
      "Train Epoch: 7 [0/118320 (0%)]\tLoss: 0.003246\n",
      "Train Epoch: 7 [2560/118320 (2%)]\tLoss: 0.003262\n",
      "Train Epoch: 7 [5120/118320 (4%)]\tLoss: 0.003252\n",
      "Train Epoch: 7 [7680/118320 (6%)]\tLoss: 0.003289\n",
      "Train Epoch: 7 [10240/118320 (9%)]\tLoss: 0.003287\n",
      "Train Epoch: 7 [12800/118320 (11%)]\tLoss: 0.003307\n",
      "Train Epoch: 7 [15360/118320 (13%)]\tLoss: 0.003252\n",
      "Train Epoch: 7 [17920/118320 (15%)]\tLoss: 0.003317\n",
      "Train Epoch: 7 [20480/118320 (17%)]\tLoss: 0.003266\n",
      "Train Epoch: 7 [23040/118320 (19%)]\tLoss: 0.003243\n",
      "Train Epoch: 7 [25600/118320 (22%)]\tLoss: 0.003271\n",
      "Train Epoch: 7 [28160/118320 (24%)]\tLoss: 0.003267\n",
      "Train Epoch: 7 [30720/118320 (26%)]\tLoss: 0.003271\n",
      "Train Epoch: 7 [33280/118320 (28%)]\tLoss: 0.003292\n",
      "Train Epoch: 7 [35840/118320 (30%)]\tLoss: 0.003234\n",
      "Train Epoch: 7 [38400/118320 (32%)]\tLoss: 0.003263\n",
      "Train Epoch: 7 [40960/118320 (35%)]\tLoss: 0.003290\n",
      "Train Epoch: 7 [43520/118320 (37%)]\tLoss: 0.003324\n",
      "Train Epoch: 7 [46080/118320 (39%)]\tLoss: 0.003284\n",
      "Train Epoch: 7 [48640/118320 (41%)]\tLoss: 0.003289\n",
      "Train Epoch: 7 [51200/118320 (43%)]\tLoss: 0.003279\n",
      "Train Epoch: 7 [53760/118320 (45%)]\tLoss: 0.003263\n",
      "Train Epoch: 7 [56320/118320 (48%)]\tLoss: 0.003251\n",
      "Train Epoch: 7 [58880/118320 (50%)]\tLoss: 0.003283\n",
      "Train Epoch: 7 [61440/118320 (52%)]\tLoss: 0.003267\n",
      "Train Epoch: 7 [64000/118320 (54%)]\tLoss: 0.003270\n",
      "Train Epoch: 7 [66560/118320 (56%)]\tLoss: 0.003245\n",
      "Train Epoch: 7 [69120/118320 (58%)]\tLoss: 0.003285\n",
      "Train Epoch: 7 [71680/118320 (60%)]\tLoss: 0.003251\n",
      "Train Epoch: 7 [74240/118320 (63%)]\tLoss: 0.003244\n",
      "Train Epoch: 7 [76800/118320 (65%)]\tLoss: 0.003257\n",
      "Train Epoch: 7 [79360/118320 (67%)]\tLoss: 0.003244\n",
      "Train Epoch: 7 [81920/118320 (69%)]\tLoss: 0.003252\n",
      "Train Epoch: 7 [84480/118320 (71%)]\tLoss: 0.003240\n",
      "Train Epoch: 7 [87040/118320 (73%)]\tLoss: 0.003230\n",
      "Train Epoch: 7 [89600/118320 (76%)]\tLoss: 0.003246\n",
      "Train Epoch: 7 [92160/118320 (78%)]\tLoss: 0.003245\n",
      "Train Epoch: 7 [94720/118320 (80%)]\tLoss: 0.003193\n",
      "Train Epoch: 7 [97280/118320 (82%)]\tLoss: 0.003224\n",
      "Train Epoch: 7 [99840/118320 (84%)]\tLoss: 0.003300\n",
      "Train Epoch: 7 [102400/118320 (86%)]\tLoss: 0.003234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [104960/118320 (89%)]\tLoss: 0.003288\n",
      "Train Epoch: 7 [107520/118320 (91%)]\tLoss: 0.003270\n",
      "Train Epoch: 7 [110080/118320 (93%)]\tLoss: 0.003274\n",
      "Train Epoch: 7 [112640/118320 (95%)]\tLoss: 0.003262\n",
      "Train Epoch: 7 [115200/118320 (97%)]\tLoss: 0.003269\n",
      "Train Epoch: 7 [117760/118320 (99%)]\tLoss: 0.003265\n",
      "\n",
      "Test set: Average loss: 0.0033\n",
      "\n",
      "Train Epoch: 8 [0/118320 (0%)]\tLoss: 0.003264\n",
      "Train Epoch: 8 [2560/118320 (2%)]\tLoss: 0.003245\n",
      "Train Epoch: 8 [5120/118320 (4%)]\tLoss: 0.003249\n",
      "Train Epoch: 8 [7680/118320 (6%)]\tLoss: 0.003238\n",
      "Train Epoch: 8 [10240/118320 (9%)]\tLoss: 0.003287\n",
      "Train Epoch: 8 [12800/118320 (11%)]\tLoss: 0.003256\n",
      "Train Epoch: 8 [15360/118320 (13%)]\tLoss: 0.003255\n",
      "Train Epoch: 8 [17920/118320 (15%)]\tLoss: 0.003259\n",
      "Train Epoch: 8 [20480/118320 (17%)]\tLoss: 0.003272\n",
      "Train Epoch: 8 [23040/118320 (19%)]\tLoss: 0.003268\n",
      "Train Epoch: 8 [25600/118320 (22%)]\tLoss: 0.003270\n",
      "Train Epoch: 8 [28160/118320 (24%)]\tLoss: 0.003281\n",
      "Train Epoch: 8 [30720/118320 (26%)]\tLoss: 0.003271\n",
      "Train Epoch: 8 [33280/118320 (28%)]\tLoss: 0.003288\n",
      "Train Epoch: 8 [35840/118320 (30%)]\tLoss: 0.003254\n",
      "Train Epoch: 8 [38400/118320 (32%)]\tLoss: 0.003278\n",
      "Train Epoch: 8 [40960/118320 (35%)]\tLoss: 0.003243\n",
      "Train Epoch: 8 [43520/118320 (37%)]\tLoss: 0.003281\n",
      "Train Epoch: 8 [46080/118320 (39%)]\tLoss: 0.003257\n",
      "Train Epoch: 8 [48640/118320 (41%)]\tLoss: 0.003252\n",
      "Train Epoch: 8 [51200/118320 (43%)]\tLoss: 0.003256\n",
      "Train Epoch: 8 [53760/118320 (45%)]\tLoss: 0.003284\n",
      "Train Epoch: 8 [56320/118320 (48%)]\tLoss: 0.003245\n",
      "Train Epoch: 8 [58880/118320 (50%)]\tLoss: 0.003313\n",
      "Train Epoch: 8 [61440/118320 (52%)]\tLoss: 0.003289\n",
      "Train Epoch: 8 [64000/118320 (54%)]\tLoss: 0.003257\n",
      "Train Epoch: 8 [66560/118320 (56%)]\tLoss: 0.003239\n",
      "Train Epoch: 8 [69120/118320 (58%)]\tLoss: 0.003278\n",
      "Train Epoch: 8 [71680/118320 (60%)]\tLoss: 0.003265\n",
      "Train Epoch: 8 [74240/118320 (63%)]\tLoss: 0.003289\n",
      "Train Epoch: 8 [76800/118320 (65%)]\tLoss: 0.003273\n",
      "Train Epoch: 8 [79360/118320 (67%)]\tLoss: 0.003263\n",
      "Train Epoch: 8 [81920/118320 (69%)]\tLoss: 0.003257\n",
      "Train Epoch: 8 [84480/118320 (71%)]\tLoss: 0.003296\n",
      "Train Epoch: 8 [87040/118320 (73%)]\tLoss: 0.003224\n",
      "Train Epoch: 8 [89600/118320 (76%)]\tLoss: 0.003260\n",
      "Train Epoch: 8 [92160/118320 (78%)]\tLoss: 0.003272\n",
      "Train Epoch: 8 [94720/118320 (80%)]\tLoss: 0.003234\n",
      "Train Epoch: 8 [97280/118320 (82%)]\tLoss: 0.003246\n",
      "Train Epoch: 8 [99840/118320 (84%)]\tLoss: 0.003276\n",
      "Train Epoch: 8 [102400/118320 (86%)]\tLoss: 0.003268\n",
      "Train Epoch: 8 [104960/118320 (89%)]\tLoss: 0.003209\n",
      "Train Epoch: 8 [107520/118320 (91%)]\tLoss: 0.003254\n",
      "Train Epoch: 8 [110080/118320 (93%)]\tLoss: 0.003268\n",
      "Train Epoch: 8 [112640/118320 (95%)]\tLoss: 0.003227\n",
      "Train Epoch: 8 [115200/118320 (97%)]\tLoss: 0.003257\n",
      "Train Epoch: 8 [117760/118320 (99%)]\tLoss: 0.003243\n",
      "\n",
      "Test set: Average loss: 0.0033\n",
      "\n",
      "Train Epoch: 9 [0/118320 (0%)]\tLoss: 0.003277\n",
      "Train Epoch: 9 [2560/118320 (2%)]\tLoss: 0.003241\n",
      "Train Epoch: 9 [5120/118320 (4%)]\tLoss: 0.003287\n",
      "Train Epoch: 9 [7680/118320 (6%)]\tLoss: 0.003268\n",
      "Train Epoch: 9 [10240/118320 (9%)]\tLoss: 0.003284\n",
      "Train Epoch: 9 [12800/118320 (11%)]\tLoss: 0.003252\n",
      "Train Epoch: 9 [15360/118320 (13%)]\tLoss: 0.003245\n",
      "Train Epoch: 9 [17920/118320 (15%)]\tLoss: 0.003223\n",
      "Train Epoch: 9 [20480/118320 (17%)]\tLoss: 0.003250\n",
      "Train Epoch: 9 [23040/118320 (19%)]\tLoss: 0.003258\n",
      "Train Epoch: 9 [25600/118320 (22%)]\tLoss: 0.003229\n",
      "Train Epoch: 9 [28160/118320 (24%)]\tLoss: 0.003288\n",
      "Train Epoch: 9 [30720/118320 (26%)]\tLoss: 0.003232\n",
      "Train Epoch: 9 [33280/118320 (28%)]\tLoss: 0.003321\n",
      "Train Epoch: 9 [35840/118320 (30%)]\tLoss: 0.003261\n",
      "Train Epoch: 9 [38400/118320 (32%)]\tLoss: 0.003233\n",
      "Train Epoch: 9 [40960/118320 (35%)]\tLoss: 0.003302\n",
      "Train Epoch: 9 [43520/118320 (37%)]\tLoss: 0.003225\n",
      "Train Epoch: 9 [46080/118320 (39%)]\tLoss: 0.003234\n",
      "Train Epoch: 9 [48640/118320 (41%)]\tLoss: 0.003272\n",
      "Train Epoch: 9 [51200/118320 (43%)]\tLoss: 0.003283\n",
      "Train Epoch: 9 [53760/118320 (45%)]\tLoss: 0.003267\n",
      "Train Epoch: 9 [56320/118320 (48%)]\tLoss: 0.003260\n",
      "Train Epoch: 9 [58880/118320 (50%)]\tLoss: 0.003256\n",
      "Train Epoch: 9 [61440/118320 (52%)]\tLoss: 0.003256\n",
      "Train Epoch: 9 [64000/118320 (54%)]\tLoss: 0.003243\n",
      "Train Epoch: 9 [66560/118320 (56%)]\tLoss: 0.003253\n",
      "Train Epoch: 9 [69120/118320 (58%)]\tLoss: 0.003268\n",
      "Train Epoch: 9 [71680/118320 (60%)]\tLoss: 0.003256\n",
      "Train Epoch: 9 [74240/118320 (63%)]\tLoss: 0.003244\n",
      "Train Epoch: 9 [76800/118320 (65%)]\tLoss: 0.003232\n",
      "Train Epoch: 9 [79360/118320 (67%)]\tLoss: 0.003251\n",
      "Train Epoch: 9 [81920/118320 (69%)]\tLoss: 0.003272\n",
      "Train Epoch: 9 [84480/118320 (71%)]\tLoss: 0.003291\n",
      "Train Epoch: 9 [87040/118320 (73%)]\tLoss: 0.003265\n",
      "Train Epoch: 9 [89600/118320 (76%)]\tLoss: 0.003241\n",
      "Train Epoch: 9 [92160/118320 (78%)]\tLoss: 0.003234\n",
      "Train Epoch: 9 [94720/118320 (80%)]\tLoss: 0.003258\n",
      "Train Epoch: 9 [97280/118320 (82%)]\tLoss: 0.003296\n",
      "Train Epoch: 9 [99840/118320 (84%)]\tLoss: 0.003243\n",
      "Train Epoch: 9 [102400/118320 (86%)]\tLoss: 0.003240\n",
      "Train Epoch: 9 [104960/118320 (89%)]\tLoss: 0.003260\n",
      "Train Epoch: 9 [107520/118320 (91%)]\tLoss: 0.003299\n",
      "Train Epoch: 9 [110080/118320 (93%)]\tLoss: 0.003284\n",
      "Train Epoch: 9 [112640/118320 (95%)]\tLoss: 0.003243\n",
      "Train Epoch: 9 [115200/118320 (97%)]\tLoss: 0.003281\n",
      "Train Epoch: 9 [117760/118320 (99%)]\tLoss: 0.003240\n",
      "\n",
      "Test set: Average loss: 0.0033\n",
      "\n",
      "Train Epoch: 10 [0/118320 (0%)]\tLoss: 0.003273\n",
      "Train Epoch: 10 [2560/118320 (2%)]\tLoss: 0.003287\n",
      "Train Epoch: 10 [5120/118320 (4%)]\tLoss: 0.003257\n",
      "Train Epoch: 10 [7680/118320 (6%)]\tLoss: 0.003301\n",
      "Train Epoch: 10 [10240/118320 (9%)]\tLoss: 0.003225\n",
      "Train Epoch: 10 [12800/118320 (11%)]\tLoss: 0.003241\n",
      "Train Epoch: 10 [15360/118320 (13%)]\tLoss: 0.003294\n",
      "Train Epoch: 10 [17920/118320 (15%)]\tLoss: 0.003273\n",
      "Train Epoch: 10 [20480/118320 (17%)]\tLoss: 0.003279\n",
      "Train Epoch: 10 [23040/118320 (19%)]\tLoss: 0.003270\n",
      "Train Epoch: 10 [25600/118320 (22%)]\tLoss: 0.003269\n",
      "Train Epoch: 10 [28160/118320 (24%)]\tLoss: 0.003255\n",
      "Train Epoch: 10 [30720/118320 (26%)]\tLoss: 0.003220\n",
      "Train Epoch: 10 [33280/118320 (28%)]\tLoss: 0.003225\n",
      "Train Epoch: 10 [35840/118320 (30%)]\tLoss: 0.003301\n",
      "Train Epoch: 10 [38400/118320 (32%)]\tLoss: 0.003307\n",
      "Train Epoch: 10 [40960/118320 (35%)]\tLoss: 0.003261\n",
      "Train Epoch: 10 [43520/118320 (37%)]\tLoss: 0.003234\n",
      "Train Epoch: 10 [46080/118320 (39%)]\tLoss: 0.003223\n",
      "Train Epoch: 10 [48640/118320 (41%)]\tLoss: 0.003246\n",
      "Train Epoch: 10 [51200/118320 (43%)]\tLoss: 0.003257\n",
      "Train Epoch: 10 [53760/118320 (45%)]\tLoss: 0.003247\n",
      "Train Epoch: 10 [56320/118320 (48%)]\tLoss: 0.003319\n",
      "Train Epoch: 10 [58880/118320 (50%)]\tLoss: 0.003283\n",
      "Train Epoch: 10 [61440/118320 (52%)]\tLoss: 0.003249\n",
      "Train Epoch: 10 [64000/118320 (54%)]\tLoss: 0.003302\n",
      "Train Epoch: 10 [66560/118320 (56%)]\tLoss: 0.003226\n",
      "Train Epoch: 10 [69120/118320 (58%)]\tLoss: 0.003281\n",
      "Train Epoch: 10 [71680/118320 (60%)]\tLoss: 0.003253\n",
      "Train Epoch: 10 [74240/118320 (63%)]\tLoss: 0.003255\n",
      "Train Epoch: 10 [76800/118320 (65%)]\tLoss: 0.003278\n",
      "Train Epoch: 10 [79360/118320 (67%)]\tLoss: 0.003253\n",
      "Train Epoch: 10 [81920/118320 (69%)]\tLoss: 0.003218\n",
      "Train Epoch: 10 [84480/118320 (71%)]\tLoss: 0.003316\n",
      "Train Epoch: 10 [87040/118320 (73%)]\tLoss: 0.003267\n",
      "Train Epoch: 10 [89600/118320 (76%)]\tLoss: 0.003282\n",
      "Train Epoch: 10 [92160/118320 (78%)]\tLoss: 0.003268\n",
      "Train Epoch: 10 [94720/118320 (80%)]\tLoss: 0.003292\n",
      "Train Epoch: 10 [97280/118320 (82%)]\tLoss: 0.003242\n",
      "Train Epoch: 10 [99840/118320 (84%)]\tLoss: 0.003296\n",
      "Train Epoch: 10 [102400/118320 (86%)]\tLoss: 0.003290\n",
      "Train Epoch: 10 [104960/118320 (89%)]\tLoss: 0.003219\n",
      "Train Epoch: 10 [107520/118320 (91%)]\tLoss: 0.003210\n",
      "Train Epoch: 10 [110080/118320 (93%)]\tLoss: 0.003265\n",
      "Train Epoch: 10 [112640/118320 (95%)]\tLoss: 0.003241\n",
      "Train Epoch: 10 [115200/118320 (97%)]\tLoss: 0.003274\n",
      "Train Epoch: 10 [117760/118320 (99%)]\tLoss: 0.003283\n",
      "\n",
      "Test set: Average loss: 0.0033\n",
      "\n",
      "Train Epoch: 11 [0/118320 (0%)]\tLoss: 0.003243\n",
      "Train Epoch: 11 [2560/118320 (2%)]\tLoss: 0.003242\n",
      "Train Epoch: 11 [5120/118320 (4%)]\tLoss: 0.003244\n",
      "Train Epoch: 11 [7680/118320 (6%)]\tLoss: 0.003276\n",
      "Train Epoch: 11 [10240/118320 (9%)]\tLoss: 0.003227\n",
      "Train Epoch: 11 [12800/118320 (11%)]\tLoss: 0.003252\n",
      "Train Epoch: 11 [15360/118320 (13%)]\tLoss: 0.003278\n",
      "Train Epoch: 11 [17920/118320 (15%)]\tLoss: 0.003315\n",
      "Train Epoch: 11 [20480/118320 (17%)]\tLoss: 0.003261\n",
      "Train Epoch: 11 [23040/118320 (19%)]\tLoss: 0.003267\n",
      "Train Epoch: 11 [25600/118320 (22%)]\tLoss: 0.003244\n",
      "Train Epoch: 11 [28160/118320 (24%)]\tLoss: 0.003301\n",
      "Train Epoch: 11 [30720/118320 (26%)]\tLoss: 0.003243\n",
      "Train Epoch: 11 [33280/118320 (28%)]\tLoss: 0.003223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11 [35840/118320 (30%)]\tLoss: 0.003283\n",
      "Train Epoch: 11 [38400/118320 (32%)]\tLoss: 0.003267\n",
      "Train Epoch: 11 [40960/118320 (35%)]\tLoss: 0.003295\n",
      "Train Epoch: 11 [43520/118320 (37%)]\tLoss: 0.003254\n",
      "Train Epoch: 11 [46080/118320 (39%)]\tLoss: 0.003287\n",
      "Train Epoch: 11 [48640/118320 (41%)]\tLoss: 0.003270\n",
      "Train Epoch: 11 [51200/118320 (43%)]\tLoss: 0.003271\n",
      "Train Epoch: 11 [53760/118320 (45%)]\tLoss: 0.003245\n",
      "Train Epoch: 11 [56320/118320 (48%)]\tLoss: 0.003252\n",
      "Train Epoch: 11 [58880/118320 (50%)]\tLoss: 0.003276\n",
      "Train Epoch: 11 [61440/118320 (52%)]\tLoss: 0.003268\n",
      "Train Epoch: 11 [64000/118320 (54%)]\tLoss: 0.003280\n",
      "Train Epoch: 11 [66560/118320 (56%)]\tLoss: 0.003258\n",
      "Train Epoch: 11 [69120/118320 (58%)]\tLoss: 0.003267\n",
      "Train Epoch: 11 [71680/118320 (60%)]\tLoss: 0.003228\n",
      "Train Epoch: 11 [74240/118320 (63%)]\tLoss: 0.003231\n",
      "Train Epoch: 11 [76800/118320 (65%)]\tLoss: 0.003293\n",
      "Train Epoch: 11 [79360/118320 (67%)]\tLoss: 0.003278\n",
      "Train Epoch: 11 [81920/118320 (69%)]\tLoss: 0.003233\n",
      "Train Epoch: 11 [84480/118320 (71%)]\tLoss: 0.003271\n",
      "Train Epoch: 11 [87040/118320 (73%)]\tLoss: 0.003274\n",
      "Train Epoch: 11 [89600/118320 (76%)]\tLoss: 0.003267\n",
      "Train Epoch: 11 [92160/118320 (78%)]\tLoss: 0.003275\n",
      "Train Epoch: 11 [94720/118320 (80%)]\tLoss: 0.003218\n",
      "Train Epoch: 11 [97280/118320 (82%)]\tLoss: 0.003241\n",
      "Train Epoch: 11 [99840/118320 (84%)]\tLoss: 0.003264\n",
      "Train Epoch: 11 [102400/118320 (86%)]\tLoss: 0.003270\n",
      "Train Epoch: 11 [104960/118320 (89%)]\tLoss: 0.003273\n",
      "Train Epoch: 11 [107520/118320 (91%)]\tLoss: 0.003303\n",
      "Train Epoch: 11 [110080/118320 (93%)]\tLoss: 0.003256\n",
      "Train Epoch: 11 [112640/118320 (95%)]\tLoss: 0.003306\n",
      "Train Epoch: 11 [115200/118320 (97%)]\tLoss: 0.003271\n",
      "Train Epoch: 11 [117760/118320 (99%)]\tLoss: 0.003242\n",
      "\n",
      "Test set: Average loss: 0.0033\n",
      "\n",
      "Train Epoch: 12 [0/118320 (0%)]\tLoss: 0.003237\n",
      "Train Epoch: 12 [2560/118320 (2%)]\tLoss: 0.003263\n",
      "Train Epoch: 12 [5120/118320 (4%)]\tLoss: 0.003242\n",
      "Train Epoch: 12 [7680/118320 (6%)]\tLoss: 0.003256\n",
      "Train Epoch: 12 [10240/118320 (9%)]\tLoss: 0.003243\n",
      "Train Epoch: 12 [12800/118320 (11%)]\tLoss: 0.003240\n",
      "Train Epoch: 12 [15360/118320 (13%)]\tLoss: 0.003327\n",
      "Train Epoch: 12 [17920/118320 (15%)]\tLoss: 0.003241\n",
      "Train Epoch: 12 [20480/118320 (17%)]\tLoss: 0.003241\n",
      "Train Epoch: 12 [23040/118320 (19%)]\tLoss: 0.003253\n",
      "Train Epoch: 12 [25600/118320 (22%)]\tLoss: 0.003276\n",
      "Train Epoch: 12 [28160/118320 (24%)]\tLoss: 0.003251\n",
      "Train Epoch: 12 [30720/118320 (26%)]\tLoss: 0.003286\n",
      "Train Epoch: 12 [33280/118320 (28%)]\tLoss: 0.003324\n",
      "Train Epoch: 12 [35840/118320 (30%)]\tLoss: 0.003269\n",
      "Train Epoch: 12 [38400/118320 (32%)]\tLoss: 0.003269\n",
      "Train Epoch: 12 [40960/118320 (35%)]\tLoss: 0.003215\n",
      "Train Epoch: 12 [43520/118320 (37%)]\tLoss: 0.003274\n",
      "Train Epoch: 12 [46080/118320 (39%)]\tLoss: 0.003271\n",
      "Train Epoch: 12 [48640/118320 (41%)]\tLoss: 0.003289\n",
      "Train Epoch: 12 [51200/118320 (43%)]\tLoss: 0.003269\n",
      "Train Epoch: 12 [53760/118320 (45%)]\tLoss: 0.003285\n",
      "Train Epoch: 12 [56320/118320 (48%)]\tLoss: 0.003278\n",
      "Train Epoch: 12 [58880/118320 (50%)]\tLoss: 0.003266\n",
      "Train Epoch: 12 [61440/118320 (52%)]\tLoss: 0.003239\n",
      "Train Epoch: 12 [64000/118320 (54%)]\tLoss: 0.003241\n",
      "Train Epoch: 12 [66560/118320 (56%)]\tLoss: 0.003256\n",
      "Train Epoch: 12 [69120/118320 (58%)]\tLoss: 0.003282\n",
      "Train Epoch: 12 [71680/118320 (60%)]\tLoss: 0.003267\n",
      "Train Epoch: 12 [74240/118320 (63%)]\tLoss: 0.003213\n",
      "Train Epoch: 12 [76800/118320 (65%)]\tLoss: 0.003275\n",
      "Train Epoch: 12 [79360/118320 (67%)]\tLoss: 0.003254\n",
      "Train Epoch: 12 [81920/118320 (69%)]\tLoss: 0.003266\n",
      "Train Epoch: 12 [84480/118320 (71%)]\tLoss: 0.003246\n",
      "Train Epoch: 12 [87040/118320 (73%)]\tLoss: 0.003221\n",
      "Train Epoch: 12 [89600/118320 (76%)]\tLoss: 0.003257\n",
      "Train Epoch: 12 [92160/118320 (78%)]\tLoss: 0.003248\n",
      "Train Epoch: 12 [94720/118320 (80%)]\tLoss: 0.003268\n",
      "Train Epoch: 12 [97280/118320 (82%)]\tLoss: 0.003273\n",
      "Train Epoch: 12 [99840/118320 (84%)]\tLoss: 0.003288\n",
      "Train Epoch: 12 [102400/118320 (86%)]\tLoss: 0.003275\n",
      "Train Epoch: 12 [104960/118320 (89%)]\tLoss: 0.003319\n",
      "Train Epoch: 12 [107520/118320 (91%)]\tLoss: 0.003215\n",
      "Train Epoch: 12 [110080/118320 (93%)]\tLoss: 0.003225\n",
      "Train Epoch: 12 [112640/118320 (95%)]\tLoss: 0.003249\n",
      "Train Epoch: 12 [115200/118320 (97%)]\tLoss: 0.003296\n",
      "Train Epoch: 12 [117760/118320 (99%)]\tLoss: 0.003264\n",
      "\n",
      "Test set: Average loss: 0.0033\n",
      "\n",
      "Train Epoch: 13 [0/118320 (0%)]\tLoss: 0.003247\n",
      "Train Epoch: 13 [2560/118320 (2%)]\tLoss: 0.003287\n",
      "Train Epoch: 13 [5120/118320 (4%)]\tLoss: 0.003215\n",
      "Train Epoch: 13 [7680/118320 (6%)]\tLoss: 0.003218\n",
      "Train Epoch: 13 [10240/118320 (9%)]\tLoss: 0.003250\n",
      "Train Epoch: 13 [12800/118320 (11%)]\tLoss: 0.003250\n",
      "Train Epoch: 13 [15360/118320 (13%)]\tLoss: 0.003261\n",
      "Train Epoch: 13 [17920/118320 (15%)]\tLoss: 0.003242\n",
      "Train Epoch: 13 [20480/118320 (17%)]\tLoss: 0.003253\n",
      "Train Epoch: 13 [23040/118320 (19%)]\tLoss: 0.003244\n",
      "Train Epoch: 13 [25600/118320 (22%)]\tLoss: 0.003253\n",
      "Train Epoch: 13 [28160/118320 (24%)]\tLoss: 0.003246\n",
      "Train Epoch: 13 [30720/118320 (26%)]\tLoss: 0.003260\n",
      "Train Epoch: 13 [33280/118320 (28%)]\tLoss: 0.003264\n",
      "Train Epoch: 13 [35840/118320 (30%)]\tLoss: 0.003229\n",
      "Train Epoch: 13 [38400/118320 (32%)]\tLoss: 0.003220\n",
      "Train Epoch: 13 [40960/118320 (35%)]\tLoss: 0.003248\n",
      "Train Epoch: 13 [43520/118320 (37%)]\tLoss: 0.003287\n",
      "Train Epoch: 13 [46080/118320 (39%)]\tLoss: 0.003262\n",
      "Train Epoch: 13 [48640/118320 (41%)]\tLoss: 0.003251\n",
      "Train Epoch: 13 [51200/118320 (43%)]\tLoss: 0.003211\n",
      "Train Epoch: 13 [53760/118320 (45%)]\tLoss: 0.003271\n",
      "Train Epoch: 13 [56320/118320 (48%)]\tLoss: 0.003239\n",
      "Train Epoch: 13 [58880/118320 (50%)]\tLoss: 0.003223\n",
      "Train Epoch: 13 [61440/118320 (52%)]\tLoss: 0.003283\n",
      "Train Epoch: 13 [64000/118320 (54%)]\tLoss: 0.003270\n",
      "Train Epoch: 13 [66560/118320 (56%)]\tLoss: 0.003262\n",
      "Train Epoch: 13 [69120/118320 (58%)]\tLoss: 0.003279\n",
      "Train Epoch: 13 [71680/118320 (60%)]\tLoss: 0.003281\n",
      "Train Epoch: 13 [74240/118320 (63%)]\tLoss: 0.003216\n",
      "Train Epoch: 13 [76800/118320 (65%)]\tLoss: 0.003258\n",
      "Train Epoch: 13 [79360/118320 (67%)]\tLoss: 0.003280\n",
      "Train Epoch: 13 [81920/118320 (69%)]\tLoss: 0.003240\n",
      "Train Epoch: 13 [84480/118320 (71%)]\tLoss: 0.003273\n",
      "Train Epoch: 13 [87040/118320 (73%)]\tLoss: 0.003243\n",
      "Train Epoch: 13 [89600/118320 (76%)]\tLoss: 0.003269\n",
      "Train Epoch: 13 [92160/118320 (78%)]\tLoss: 0.003241\n",
      "Train Epoch: 13 [94720/118320 (80%)]\tLoss: 0.003266\n",
      "Train Epoch: 13 [97280/118320 (82%)]\tLoss: 0.003262\n",
      "Train Epoch: 13 [99840/118320 (84%)]\tLoss: 0.003270\n",
      "Train Epoch: 13 [102400/118320 (86%)]\tLoss: 0.003231\n",
      "Train Epoch: 13 [104960/118320 (89%)]\tLoss: 0.003242\n",
      "Train Epoch: 13 [107520/118320 (91%)]\tLoss: 0.003312\n",
      "Train Epoch: 13 [110080/118320 (93%)]\tLoss: 0.003258\n",
      "Train Epoch: 13 [112640/118320 (95%)]\tLoss: 0.003238\n",
      "Train Epoch: 13 [115200/118320 (97%)]\tLoss: 0.003202\n",
      "Train Epoch: 13 [117760/118320 (99%)]\tLoss: 0.003252\n",
      "\n",
      "Test set: Average loss: 0.0033\n",
      "\n",
      "Train Epoch: 14 [0/118320 (0%)]\tLoss: 0.003254\n",
      "Train Epoch: 14 [2560/118320 (2%)]\tLoss: 0.003259\n",
      "Train Epoch: 14 [5120/118320 (4%)]\tLoss: 0.003266\n",
      "Train Epoch: 14 [7680/118320 (6%)]\tLoss: 0.003268\n",
      "Train Epoch: 14 [10240/118320 (9%)]\tLoss: 0.003287\n",
      "Train Epoch: 14 [12800/118320 (11%)]\tLoss: 0.003287\n",
      "Train Epoch: 14 [15360/118320 (13%)]\tLoss: 0.003250\n",
      "Train Epoch: 14 [17920/118320 (15%)]\tLoss: 0.003267\n",
      "Train Epoch: 14 [20480/118320 (17%)]\tLoss: 0.003258\n",
      "Train Epoch: 14 [23040/118320 (19%)]\tLoss: 0.003225\n",
      "Train Epoch: 14 [25600/118320 (22%)]\tLoss: 0.003284\n",
      "Train Epoch: 14 [28160/118320 (24%)]\tLoss: 0.003253\n",
      "Train Epoch: 14 [30720/118320 (26%)]\tLoss: 0.003213\n",
      "Train Epoch: 14 [33280/118320 (28%)]\tLoss: 0.003273\n",
      "Train Epoch: 14 [35840/118320 (30%)]\tLoss: 0.003268\n",
      "Train Epoch: 14 [38400/118320 (32%)]\tLoss: 0.003197\n",
      "Train Epoch: 14 [40960/118320 (35%)]\tLoss: 0.003221\n",
      "Train Epoch: 14 [43520/118320 (37%)]\tLoss: 0.003257\n",
      "Train Epoch: 14 [46080/118320 (39%)]\tLoss: 0.003260\n",
      "Train Epoch: 14 [48640/118320 (41%)]\tLoss: 0.003252\n",
      "Train Epoch: 14 [51200/118320 (43%)]\tLoss: 0.003231\n",
      "Train Epoch: 14 [53760/118320 (45%)]\tLoss: 0.003289\n",
      "Train Epoch: 14 [56320/118320 (48%)]\tLoss: 0.003257\n",
      "Train Epoch: 14 [58880/118320 (50%)]\tLoss: 0.003249\n",
      "Train Epoch: 14 [61440/118320 (52%)]\tLoss: 0.003235\n",
      "Train Epoch: 14 [64000/118320 (54%)]\tLoss: 0.003262\n",
      "Train Epoch: 14 [66560/118320 (56%)]\tLoss: 0.003260\n",
      "Train Epoch: 14 [69120/118320 (58%)]\tLoss: 0.003250\n",
      "Train Epoch: 14 [71680/118320 (60%)]\tLoss: 0.003245\n",
      "Train Epoch: 14 [74240/118320 (63%)]\tLoss: 0.003268\n",
      "Train Epoch: 14 [76800/118320 (65%)]\tLoss: 0.003251\n",
      "Train Epoch: 14 [79360/118320 (67%)]\tLoss: 0.003258\n",
      "Train Epoch: 14 [81920/118320 (69%)]\tLoss: 0.003271\n",
      "Train Epoch: 14 [84480/118320 (71%)]\tLoss: 0.003244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14 [87040/118320 (73%)]\tLoss: 0.003287\n",
      "Train Epoch: 14 [89600/118320 (76%)]\tLoss: 0.003275\n",
      "Train Epoch: 14 [92160/118320 (78%)]\tLoss: 0.003262\n",
      "Train Epoch: 14 [94720/118320 (80%)]\tLoss: 0.003205\n",
      "Train Epoch: 14 [97280/118320 (82%)]\tLoss: 0.003265\n",
      "Train Epoch: 14 [99840/118320 (84%)]\tLoss: 0.003221\n",
      "Train Epoch: 14 [102400/118320 (86%)]\tLoss: 0.003281\n",
      "Train Epoch: 14 [104960/118320 (89%)]\tLoss: 0.003272\n",
      "Train Epoch: 14 [107520/118320 (91%)]\tLoss: 0.003238\n",
      "Train Epoch: 14 [110080/118320 (93%)]\tLoss: 0.003274\n",
      "Train Epoch: 14 [112640/118320 (95%)]\tLoss: 0.003244\n",
      "Train Epoch: 14 [115200/118320 (97%)]\tLoss: 0.003257\n",
      "Train Epoch: 14 [117760/118320 (99%)]\tLoss: 0.003271\n",
      "\n",
      "Test set: Average loss: 0.0033\n",
      "\n",
      "Train Epoch: 15 [0/118320 (0%)]\tLoss: 0.003296\n",
      "Train Epoch: 15 [2560/118320 (2%)]\tLoss: 0.003258\n",
      "Train Epoch: 15 [5120/118320 (4%)]\tLoss: 0.003203\n",
      "Train Epoch: 15 [7680/118320 (6%)]\tLoss: 0.003226\n",
      "Train Epoch: 15 [10240/118320 (9%)]\tLoss: 0.003238\n",
      "Train Epoch: 15 [12800/118320 (11%)]\tLoss: 0.003212\n",
      "Train Epoch: 15 [15360/118320 (13%)]\tLoss: 0.003261\n",
      "Train Epoch: 15 [17920/118320 (15%)]\tLoss: 0.003259\n",
      "Train Epoch: 15 [20480/118320 (17%)]\tLoss: 0.003217\n",
      "Train Epoch: 15 [23040/118320 (19%)]\tLoss: 0.003265\n",
      "Train Epoch: 15 [25600/118320 (22%)]\tLoss: 0.003217\n",
      "Train Epoch: 15 [28160/118320 (24%)]\tLoss: 0.003219\n",
      "Train Epoch: 15 [30720/118320 (26%)]\tLoss: 0.003257\n",
      "Train Epoch: 15 [33280/118320 (28%)]\tLoss: 0.003267\n",
      "Train Epoch: 15 [35840/118320 (30%)]\tLoss: 0.003242\n",
      "Train Epoch: 15 [38400/118320 (32%)]\tLoss: 0.003226\n",
      "Train Epoch: 15 [40960/118320 (35%)]\tLoss: 0.003238\n",
      "Train Epoch: 15 [43520/118320 (37%)]\tLoss: 0.003265\n",
      "Train Epoch: 15 [46080/118320 (39%)]\tLoss: 0.003245\n",
      "Train Epoch: 15 [48640/118320 (41%)]\tLoss: 0.003246\n",
      "Train Epoch: 15 [51200/118320 (43%)]\tLoss: 0.003282\n",
      "Train Epoch: 15 [53760/118320 (45%)]\tLoss: 0.003216\n",
      "Train Epoch: 15 [56320/118320 (48%)]\tLoss: 0.003277\n",
      "Train Epoch: 15 [58880/118320 (50%)]\tLoss: 0.003197\n",
      "Train Epoch: 15 [61440/118320 (52%)]\tLoss: 0.003253\n",
      "Train Epoch: 15 [64000/118320 (54%)]\tLoss: 0.003285\n",
      "Train Epoch: 15 [66560/118320 (56%)]\tLoss: 0.003244\n",
      "Train Epoch: 15 [69120/118320 (58%)]\tLoss: 0.003251\n",
      "Train Epoch: 15 [71680/118320 (60%)]\tLoss: 0.003251\n",
      "Train Epoch: 15 [74240/118320 (63%)]\tLoss: 0.003258\n",
      "Train Epoch: 15 [76800/118320 (65%)]\tLoss: 0.003279\n",
      "Train Epoch: 15 [79360/118320 (67%)]\tLoss: 0.003285\n",
      "Train Epoch: 15 [81920/118320 (69%)]\tLoss: 0.003261\n",
      "Train Epoch: 15 [84480/118320 (71%)]\tLoss: 0.003250\n",
      "Train Epoch: 15 [87040/118320 (73%)]\tLoss: 0.003240\n",
      "Train Epoch: 15 [89600/118320 (76%)]\tLoss: 0.003259\n",
      "Train Epoch: 15 [92160/118320 (78%)]\tLoss: 0.003265\n",
      "Train Epoch: 15 [94720/118320 (80%)]\tLoss: 0.003213\n",
      "Train Epoch: 15 [97280/118320 (82%)]\tLoss: 0.003297\n",
      "Train Epoch: 15 [99840/118320 (84%)]\tLoss: 0.003247\n",
      "Train Epoch: 15 [102400/118320 (86%)]\tLoss: 0.003191\n",
      "Train Epoch: 15 [104960/118320 (89%)]\tLoss: 0.003218\n",
      "Train Epoch: 15 [107520/118320 (91%)]\tLoss: 0.003230\n",
      "Train Epoch: 15 [110080/118320 (93%)]\tLoss: 0.003256\n",
      "Train Epoch: 15 [112640/118320 (95%)]\tLoss: 0.003254\n",
      "Train Epoch: 15 [115200/118320 (97%)]\tLoss: 0.003271\n",
      "Train Epoch: 15 [117760/118320 (99%)]\tLoss: 0.003254\n",
      "\n",
      "Test set: Average loss: 0.0032\n",
      "\n",
      "Train Epoch: 16 [0/118320 (0%)]\tLoss: 0.003264\n",
      "Train Epoch: 16 [2560/118320 (2%)]\tLoss: 0.003260\n",
      "Train Epoch: 16 [5120/118320 (4%)]\tLoss: 0.003206\n",
      "Train Epoch: 16 [7680/118320 (6%)]\tLoss: 0.003273\n",
      "Train Epoch: 16 [10240/118320 (9%)]\tLoss: 0.003262\n",
      "Train Epoch: 16 [12800/118320 (11%)]\tLoss: 0.003254\n",
      "Train Epoch: 16 [15360/118320 (13%)]\tLoss: 0.003220\n",
      "Train Epoch: 16 [17920/118320 (15%)]\tLoss: 0.003260\n",
      "Train Epoch: 16 [20480/118320 (17%)]\tLoss: 0.003266\n",
      "Train Epoch: 16 [23040/118320 (19%)]\tLoss: 0.003249\n",
      "Train Epoch: 16 [25600/118320 (22%)]\tLoss: 0.003233\n",
      "Train Epoch: 16 [28160/118320 (24%)]\tLoss: 0.003232\n",
      "Train Epoch: 16 [30720/118320 (26%)]\tLoss: 0.003248\n",
      "Train Epoch: 16 [33280/118320 (28%)]\tLoss: 0.003257\n",
      "Train Epoch: 16 [35840/118320 (30%)]\tLoss: 0.003256\n",
      "Train Epoch: 16 [38400/118320 (32%)]\tLoss: 0.003288\n",
      "Train Epoch: 16 [40960/118320 (35%)]\tLoss: 0.003233\n",
      "Train Epoch: 16 [43520/118320 (37%)]\tLoss: 0.003258\n",
      "Train Epoch: 16 [46080/118320 (39%)]\tLoss: 0.003240\n",
      "Train Epoch: 16 [48640/118320 (41%)]\tLoss: 0.003260\n",
      "Train Epoch: 16 [51200/118320 (43%)]\tLoss: 0.003231\n",
      "Train Epoch: 16 [53760/118320 (45%)]\tLoss: 0.003271\n",
      "Train Epoch: 16 [56320/118320 (48%)]\tLoss: 0.003220\n",
      "Train Epoch: 16 [58880/118320 (50%)]\tLoss: 0.003242\n",
      "Train Epoch: 16 [61440/118320 (52%)]\tLoss: 0.003222\n",
      "Train Epoch: 16 [64000/118320 (54%)]\tLoss: 0.003279\n",
      "Train Epoch: 16 [66560/118320 (56%)]\tLoss: 0.003255\n",
      "Train Epoch: 16 [69120/118320 (58%)]\tLoss: 0.003235\n",
      "Train Epoch: 16 [71680/118320 (60%)]\tLoss: 0.003289\n",
      "Train Epoch: 16 [74240/118320 (63%)]\tLoss: 0.003230\n",
      "Train Epoch: 16 [76800/118320 (65%)]\tLoss: 0.003241\n",
      "Train Epoch: 16 [79360/118320 (67%)]\tLoss: 0.003244\n",
      "Train Epoch: 16 [81920/118320 (69%)]\tLoss: 0.003249\n",
      "Train Epoch: 16 [84480/118320 (71%)]\tLoss: 0.003281\n",
      "Train Epoch: 16 [87040/118320 (73%)]\tLoss: 0.003266\n",
      "Train Epoch: 16 [89600/118320 (76%)]\tLoss: 0.003280\n",
      "Train Epoch: 16 [92160/118320 (78%)]\tLoss: 0.003216\n",
      "Train Epoch: 16 [94720/118320 (80%)]\tLoss: 0.003227\n",
      "Train Epoch: 16 [97280/118320 (82%)]\tLoss: 0.003232\n",
      "Train Epoch: 16 [99840/118320 (84%)]\tLoss: 0.003234\n",
      "Train Epoch: 16 [102400/118320 (86%)]\tLoss: 0.003271\n",
      "Train Epoch: 16 [104960/118320 (89%)]\tLoss: 0.003216\n",
      "Train Epoch: 16 [107520/118320 (91%)]\tLoss: 0.003254\n",
      "Train Epoch: 16 [110080/118320 (93%)]\tLoss: 0.003256\n",
      "Train Epoch: 16 [112640/118320 (95%)]\tLoss: 0.003221\n",
      "Train Epoch: 16 [115200/118320 (97%)]\tLoss: 0.003245\n",
      "Train Epoch: 16 [117760/118320 (99%)]\tLoss: 0.003207\n",
      "\n",
      "Test set: Average loss: 0.0032\n",
      "\n",
      "Train Epoch: 17 [0/118320 (0%)]\tLoss: 0.003254\n",
      "Train Epoch: 17 [2560/118320 (2%)]\tLoss: 0.003306\n",
      "Train Epoch: 17 [5120/118320 (4%)]\tLoss: 0.003215\n",
      "Train Epoch: 17 [7680/118320 (6%)]\tLoss: 0.003281\n",
      "Train Epoch: 17 [10240/118320 (9%)]\tLoss: 0.003260\n",
      "Train Epoch: 17 [12800/118320 (11%)]\tLoss: 0.003292\n",
      "Train Epoch: 17 [15360/118320 (13%)]\tLoss: 0.003263\n",
      "Train Epoch: 17 [17920/118320 (15%)]\tLoss: 0.003252\n",
      "Train Epoch: 17 [20480/118320 (17%)]\tLoss: 0.003264\n",
      "Train Epoch: 17 [23040/118320 (19%)]\tLoss: 0.003247\n",
      "Train Epoch: 17 [25600/118320 (22%)]\tLoss: 0.003254\n",
      "Train Epoch: 17 [28160/118320 (24%)]\tLoss: 0.003222\n",
      "Train Epoch: 17 [30720/118320 (26%)]\tLoss: 0.003248\n",
      "Train Epoch: 17 [33280/118320 (28%)]\tLoss: 0.003262\n",
      "Train Epoch: 17 [35840/118320 (30%)]\tLoss: 0.003230\n",
      "Train Epoch: 17 [38400/118320 (32%)]\tLoss: 0.003231\n",
      "Train Epoch: 17 [40960/118320 (35%)]\tLoss: 0.003226\n",
      "Train Epoch: 17 [43520/118320 (37%)]\tLoss: 0.003224\n",
      "Train Epoch: 17 [46080/118320 (39%)]\tLoss: 0.003259\n",
      "Train Epoch: 17 [48640/118320 (41%)]\tLoss: 0.003255\n",
      "Train Epoch: 17 [51200/118320 (43%)]\tLoss: 0.003230\n",
      "Train Epoch: 17 [53760/118320 (45%)]\tLoss: 0.003270\n",
      "Train Epoch: 17 [56320/118320 (48%)]\tLoss: 0.003257\n",
      "Train Epoch: 17 [58880/118320 (50%)]\tLoss: 0.003250\n",
      "Train Epoch: 17 [61440/118320 (52%)]\tLoss: 0.003198\n",
      "Train Epoch: 17 [64000/118320 (54%)]\tLoss: 0.003240\n",
      "Train Epoch: 17 [66560/118320 (56%)]\tLoss: 0.003246\n",
      "Train Epoch: 17 [69120/118320 (58%)]\tLoss: 0.003201\n",
      "Train Epoch: 17 [71680/118320 (60%)]\tLoss: 0.003234\n",
      "Train Epoch: 17 [74240/118320 (63%)]\tLoss: 0.003232\n",
      "Train Epoch: 17 [76800/118320 (65%)]\tLoss: 0.003231\n",
      "Train Epoch: 17 [79360/118320 (67%)]\tLoss: 0.003211\n",
      "Train Epoch: 17 [81920/118320 (69%)]\tLoss: 0.003220\n",
      "Train Epoch: 17 [84480/118320 (71%)]\tLoss: 0.003195\n",
      "Train Epoch: 17 [87040/118320 (73%)]\tLoss: 0.003236\n",
      "Train Epoch: 17 [89600/118320 (76%)]\tLoss: 0.003244\n",
      "Train Epoch: 17 [92160/118320 (78%)]\tLoss: 0.003240\n",
      "Train Epoch: 17 [94720/118320 (80%)]\tLoss: 0.003242\n",
      "Train Epoch: 17 [97280/118320 (82%)]\tLoss: 0.003242\n",
      "Train Epoch: 17 [99840/118320 (84%)]\tLoss: 0.003253\n",
      "Train Epoch: 17 [102400/118320 (86%)]\tLoss: 0.003220\n",
      "Train Epoch: 17 [104960/118320 (89%)]\tLoss: 0.003261\n",
      "Train Epoch: 17 [107520/118320 (91%)]\tLoss: 0.003212\n",
      "Train Epoch: 17 [110080/118320 (93%)]\tLoss: 0.003194\n",
      "Train Epoch: 17 [112640/118320 (95%)]\tLoss: 0.003237\n",
      "Train Epoch: 17 [115200/118320 (97%)]\tLoss: 0.003217\n",
      "Train Epoch: 17 [117760/118320 (99%)]\tLoss: 0.003247\n",
      "\n",
      "Test set: Average loss: 0.0032\n",
      "\n",
      "Train Epoch: 18 [0/118320 (0%)]\tLoss: 0.003237\n",
      "Train Epoch: 18 [2560/118320 (2%)]\tLoss: 0.003225\n",
      "Train Epoch: 18 [5120/118320 (4%)]\tLoss: 0.003226\n",
      "Train Epoch: 18 [7680/118320 (6%)]\tLoss: 0.003201\n",
      "Train Epoch: 18 [10240/118320 (9%)]\tLoss: 0.003232\n",
      "Train Epoch: 18 [12800/118320 (11%)]\tLoss: 0.003167\n",
      "Train Epoch: 18 [15360/118320 (13%)]\tLoss: 0.003197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 18 [17920/118320 (15%)]\tLoss: 0.003221\n",
      "Train Epoch: 18 [20480/118320 (17%)]\tLoss: 0.003213\n",
      "Train Epoch: 18 [23040/118320 (19%)]\tLoss: 0.003235\n",
      "Train Epoch: 18 [25600/118320 (22%)]\tLoss: 0.003208\n",
      "Train Epoch: 18 [28160/118320 (24%)]\tLoss: 0.003238\n",
      "Train Epoch: 18 [30720/118320 (26%)]\tLoss: 0.003221\n",
      "Train Epoch: 18 [33280/118320 (28%)]\tLoss: 0.003224\n",
      "Train Epoch: 18 [35840/118320 (30%)]\tLoss: 0.003217\n",
      "Train Epoch: 18 [38400/118320 (32%)]\tLoss: 0.003241\n",
      "Train Epoch: 18 [40960/118320 (35%)]\tLoss: 0.003195\n",
      "Train Epoch: 18 [43520/118320 (37%)]\tLoss: 0.003225\n",
      "Train Epoch: 18 [46080/118320 (39%)]\tLoss: 0.003220\n",
      "Train Epoch: 18 [48640/118320 (41%)]\tLoss: 0.003217\n",
      "Train Epoch: 18 [51200/118320 (43%)]\tLoss: 0.003180\n",
      "Train Epoch: 18 [53760/118320 (45%)]\tLoss: 0.003220\n",
      "Train Epoch: 18 [56320/118320 (48%)]\tLoss: 0.003214\n",
      "Train Epoch: 18 [58880/118320 (50%)]\tLoss: 0.003240\n",
      "Train Epoch: 18 [61440/118320 (52%)]\tLoss: 0.003186\n",
      "Train Epoch: 18 [64000/118320 (54%)]\tLoss: 0.003236\n",
      "Train Epoch: 18 [66560/118320 (56%)]\tLoss: 0.003254\n",
      "Train Epoch: 18 [69120/118320 (58%)]\tLoss: 0.003223\n",
      "Train Epoch: 18 [71680/118320 (60%)]\tLoss: 0.003213\n",
      "Train Epoch: 18 [74240/118320 (63%)]\tLoss: 0.003197\n",
      "Train Epoch: 18 [76800/118320 (65%)]\tLoss: 0.003243\n",
      "Train Epoch: 18 [79360/118320 (67%)]\tLoss: 0.003197\n",
      "Train Epoch: 18 [81920/118320 (69%)]\tLoss: 0.003206\n",
      "Train Epoch: 18 [84480/118320 (71%)]\tLoss: 0.003206\n",
      "Train Epoch: 18 [87040/118320 (73%)]\tLoss: 0.003215\n",
      "Train Epoch: 18 [89600/118320 (76%)]\tLoss: 0.003213\n",
      "Train Epoch: 18 [92160/118320 (78%)]\tLoss: 0.003247\n",
      "Train Epoch: 18 [94720/118320 (80%)]\tLoss: 0.003209\n",
      "Train Epoch: 18 [97280/118320 (82%)]\tLoss: 0.003185\n",
      "Train Epoch: 18 [99840/118320 (84%)]\tLoss: 0.003194\n",
      "Train Epoch: 18 [102400/118320 (86%)]\tLoss: 0.003194\n",
      "Train Epoch: 18 [104960/118320 (89%)]\tLoss: 0.003225\n",
      "Train Epoch: 18 [107520/118320 (91%)]\tLoss: 0.003219\n",
      "Train Epoch: 18 [110080/118320 (93%)]\tLoss: 0.003200\n",
      "Train Epoch: 18 [112640/118320 (95%)]\tLoss: 0.003194\n",
      "Train Epoch: 18 [115200/118320 (97%)]\tLoss: 0.003189\n",
      "Train Epoch: 18 [117760/118320 (99%)]\tLoss: 0.003187\n",
      "\n",
      "Test set: Average loss: 0.0032\n",
      "\n",
      "Train Epoch: 19 [0/118320 (0%)]\tLoss: 0.003199\n",
      "Train Epoch: 19 [2560/118320 (2%)]\tLoss: 0.003176\n",
      "Train Epoch: 19 [5120/118320 (4%)]\tLoss: 0.003181\n",
      "Train Epoch: 19 [7680/118320 (6%)]\tLoss: 0.003185\n",
      "Train Epoch: 19 [10240/118320 (9%)]\tLoss: 0.003212\n",
      "Train Epoch: 19 [12800/118320 (11%)]\tLoss: 0.003204\n",
      "Train Epoch: 19 [15360/118320 (13%)]\tLoss: 0.003212\n",
      "Train Epoch: 19 [17920/118320 (15%)]\tLoss: 0.003224\n",
      "Train Epoch: 19 [20480/118320 (17%)]\tLoss: 0.003168\n",
      "Train Epoch: 19 [23040/118320 (19%)]\tLoss: 0.003214\n",
      "Train Epoch: 19 [25600/118320 (22%)]\tLoss: 0.003178\n",
      "Train Epoch: 19 [28160/118320 (24%)]\tLoss: 0.003209\n",
      "Train Epoch: 19 [30720/118320 (26%)]\tLoss: 0.003193\n",
      "Train Epoch: 19 [33280/118320 (28%)]\tLoss: 0.003191\n",
      "Train Epoch: 19 [35840/118320 (30%)]\tLoss: 0.003162\n",
      "Train Epoch: 19 [38400/118320 (32%)]\tLoss: 0.003133\n",
      "Train Epoch: 19 [40960/118320 (35%)]\tLoss: 0.003179\n",
      "Train Epoch: 19 [43520/118320 (37%)]\tLoss: 0.003166\n",
      "Train Epoch: 19 [46080/118320 (39%)]\tLoss: 0.003179\n",
      "Train Epoch: 19 [48640/118320 (41%)]\tLoss: 0.003183\n",
      "Train Epoch: 19 [51200/118320 (43%)]\tLoss: 0.003144\n",
      "Train Epoch: 19 [53760/118320 (45%)]\tLoss: 0.003165\n",
      "Train Epoch: 19 [56320/118320 (48%)]\tLoss: 0.003207\n",
      "Train Epoch: 19 [58880/118320 (50%)]\tLoss: 0.003156\n",
      "Train Epoch: 19 [61440/118320 (52%)]\tLoss: 0.003189\n",
      "Train Epoch: 19 [64000/118320 (54%)]\tLoss: 0.003176\n",
      "Train Epoch: 19 [66560/118320 (56%)]\tLoss: 0.003182\n",
      "Train Epoch: 19 [69120/118320 (58%)]\tLoss: 0.003191\n",
      "Train Epoch: 19 [71680/118320 (60%)]\tLoss: 0.003137\n",
      "Train Epoch: 19 [74240/118320 (63%)]\tLoss: 0.003145\n",
      "Train Epoch: 19 [76800/118320 (65%)]\tLoss: 0.003223\n",
      "Train Epoch: 19 [79360/118320 (67%)]\tLoss: 0.003143\n",
      "Train Epoch: 19 [81920/118320 (69%)]\tLoss: 0.003173\n",
      "Train Epoch: 19 [84480/118320 (71%)]\tLoss: 0.003138\n",
      "Train Epoch: 19 [87040/118320 (73%)]\tLoss: 0.003175\n",
      "Train Epoch: 19 [89600/118320 (76%)]\tLoss: 0.003187\n",
      "Train Epoch: 19 [92160/118320 (78%)]\tLoss: 0.003135\n",
      "Train Epoch: 19 [94720/118320 (80%)]\tLoss: 0.003144\n",
      "Train Epoch: 19 [97280/118320 (82%)]\tLoss: 0.003147\n",
      "Train Epoch: 19 [99840/118320 (84%)]\tLoss: 0.003135\n",
      "Train Epoch: 19 [102400/118320 (86%)]\tLoss: 0.003145\n",
      "Train Epoch: 19 [104960/118320 (89%)]\tLoss: 0.003151\n",
      "Train Epoch: 19 [107520/118320 (91%)]\tLoss: 0.003166\n",
      "Train Epoch: 19 [110080/118320 (93%)]\tLoss: 0.003115\n",
      "Train Epoch: 19 [112640/118320 (95%)]\tLoss: 0.003123\n",
      "Train Epoch: 19 [115200/118320 (97%)]\tLoss: 0.003114\n",
      "Train Epoch: 19 [117760/118320 (99%)]\tLoss: 0.003151\n",
      "\n",
      "Test set: Average loss: 0.0031\n",
      "\n",
      "Train Epoch: 20 [0/118320 (0%)]\tLoss: 0.003159\n",
      "Train Epoch: 20 [2560/118320 (2%)]\tLoss: 0.003148\n",
      "Train Epoch: 20 [5120/118320 (4%)]\tLoss: 0.003129\n",
      "Train Epoch: 20 [7680/118320 (6%)]\tLoss: 0.003146\n",
      "Train Epoch: 20 [10240/118320 (9%)]\tLoss: 0.003107\n",
      "Train Epoch: 20 [12800/118320 (11%)]\tLoss: 0.003090\n",
      "Train Epoch: 20 [15360/118320 (13%)]\tLoss: 0.003144\n",
      "Train Epoch: 20 [17920/118320 (15%)]\tLoss: 0.003089\n",
      "Train Epoch: 20 [20480/118320 (17%)]\tLoss: 0.003102\n",
      "Train Epoch: 20 [23040/118320 (19%)]\tLoss: 0.003090\n",
      "Train Epoch: 20 [25600/118320 (22%)]\tLoss: 0.003122\n",
      "Train Epoch: 20 [28160/118320 (24%)]\tLoss: 0.003114\n",
      "Train Epoch: 20 [30720/118320 (26%)]\tLoss: 0.003068\n",
      "Train Epoch: 20 [33280/118320 (28%)]\tLoss: 0.003110\n",
      "Train Epoch: 20 [35840/118320 (30%)]\tLoss: 0.003092\n",
      "Train Epoch: 20 [38400/118320 (32%)]\tLoss: 0.003011\n",
      "Train Epoch: 20 [40960/118320 (35%)]\tLoss: 0.003076\n",
      "Train Epoch: 20 [43520/118320 (37%)]\tLoss: 0.003109\n",
      "Train Epoch: 20 [46080/118320 (39%)]\tLoss: 0.003096\n",
      "Train Epoch: 20 [48640/118320 (41%)]\tLoss: 0.003099\n",
      "Train Epoch: 20 [51200/118320 (43%)]\tLoss: 0.003074\n",
      "Train Epoch: 20 [53760/118320 (45%)]\tLoss: 0.003038\n",
      "Train Epoch: 20 [56320/118320 (48%)]\tLoss: 0.003080\n",
      "Train Epoch: 20 [58880/118320 (50%)]\tLoss: 0.003041\n",
      "Train Epoch: 20 [61440/118320 (52%)]\tLoss: 0.003083\n",
      "Train Epoch: 20 [64000/118320 (54%)]\tLoss: 0.003119\n",
      "Train Epoch: 20 [66560/118320 (56%)]\tLoss: 0.003050\n",
      "Train Epoch: 20 [69120/118320 (58%)]\tLoss: 0.003064\n",
      "Train Epoch: 20 [71680/118320 (60%)]\tLoss: 0.003057\n",
      "Train Epoch: 20 [74240/118320 (63%)]\tLoss: 0.003027\n",
      "Train Epoch: 20 [76800/118320 (65%)]\tLoss: 0.003066\n",
      "Train Epoch: 20 [79360/118320 (67%)]\tLoss: 0.003060\n",
      "Train Epoch: 20 [81920/118320 (69%)]\tLoss: 0.003055\n",
      "Train Epoch: 20 [84480/118320 (71%)]\tLoss: 0.003015\n",
      "Train Epoch: 20 [87040/118320 (73%)]\tLoss: 0.003017\n",
      "Train Epoch: 20 [89600/118320 (76%)]\tLoss: 0.003048\n",
      "Train Epoch: 20 [92160/118320 (78%)]\tLoss: 0.003024\n",
      "Train Epoch: 20 [94720/118320 (80%)]\tLoss: 0.003019\n",
      "Train Epoch: 20 [97280/118320 (82%)]\tLoss: 0.002998\n",
      "Train Epoch: 20 [99840/118320 (84%)]\tLoss: 0.003028\n",
      "Train Epoch: 20 [102400/118320 (86%)]\tLoss: 0.002970\n",
      "Train Epoch: 20 [104960/118320 (89%)]\tLoss: 0.003016\n",
      "Train Epoch: 20 [107520/118320 (91%)]\tLoss: 0.003012\n",
      "Train Epoch: 20 [110080/118320 (93%)]\tLoss: 0.003034\n",
      "Train Epoch: 20 [112640/118320 (95%)]\tLoss: 0.003018\n",
      "Train Epoch: 20 [115200/118320 (97%)]\tLoss: 0.003007\n",
      "Train Epoch: 20 [117760/118320 (99%)]\tLoss: 0.003006\n",
      "\n",
      "Test set: Average loss: 0.0030\n",
      "\n",
      "Train Epoch: 21 [0/118320 (0%)]\tLoss: 0.002961\n",
      "Train Epoch: 21 [2560/118320 (2%)]\tLoss: 0.002993\n",
      "Train Epoch: 21 [5120/118320 (4%)]\tLoss: 0.002988\n",
      "Train Epoch: 21 [7680/118320 (6%)]\tLoss: 0.002954\n",
      "Train Epoch: 21 [10240/118320 (9%)]\tLoss: 0.002937\n",
      "Train Epoch: 21 [12800/118320 (11%)]\tLoss: 0.002957\n",
      "Train Epoch: 21 [15360/118320 (13%)]\tLoss: 0.002950\n",
      "Train Epoch: 21 [17920/118320 (15%)]\tLoss: 0.002998\n",
      "Train Epoch: 21 [20480/118320 (17%)]\tLoss: 0.002951\n",
      "Train Epoch: 21 [23040/118320 (19%)]\tLoss: 0.002924\n",
      "Train Epoch: 21 [25600/118320 (22%)]\tLoss: 0.002946\n",
      "Train Epoch: 21 [28160/118320 (24%)]\tLoss: 0.002923\n",
      "Train Epoch: 21 [30720/118320 (26%)]\tLoss: 0.002915\n",
      "Train Epoch: 21 [33280/118320 (28%)]\tLoss: 0.002927\n",
      "Train Epoch: 21 [35840/118320 (30%)]\tLoss: 0.002912\n",
      "Train Epoch: 21 [38400/118320 (32%)]\tLoss: 0.002911\n",
      "Train Epoch: 21 [40960/118320 (35%)]\tLoss: 0.002940\n",
      "Train Epoch: 21 [43520/118320 (37%)]\tLoss: 0.002911\n",
      "Train Epoch: 21 [46080/118320 (39%)]\tLoss: 0.002950\n",
      "Train Epoch: 21 [48640/118320 (41%)]\tLoss: 0.002935\n",
      "Train Epoch: 21 [51200/118320 (43%)]\tLoss: 0.002949\n",
      "Train Epoch: 21 [53760/118320 (45%)]\tLoss: 0.002896\n",
      "Train Epoch: 21 [56320/118320 (48%)]\tLoss: 0.002919\n",
      "Train Epoch: 21 [58880/118320 (50%)]\tLoss: 0.002888\n",
      "Train Epoch: 21 [61440/118320 (52%)]\tLoss: 0.002941\n",
      "Train Epoch: 21 [64000/118320 (54%)]\tLoss: 0.002909\n",
      "Train Epoch: 21 [66560/118320 (56%)]\tLoss: 0.002849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 21 [69120/118320 (58%)]\tLoss: 0.002903\n",
      "Train Epoch: 21 [71680/118320 (60%)]\tLoss: 0.002849\n",
      "Train Epoch: 21 [74240/118320 (63%)]\tLoss: 0.002912\n",
      "Train Epoch: 21 [76800/118320 (65%)]\tLoss: 0.002851\n",
      "Train Epoch: 21 [79360/118320 (67%)]\tLoss: 0.002863\n",
      "Train Epoch: 21 [81920/118320 (69%)]\tLoss: 0.002862\n",
      "Train Epoch: 21 [84480/118320 (71%)]\tLoss: 0.002853\n",
      "Train Epoch: 21 [87040/118320 (73%)]\tLoss: 0.002889\n",
      "Train Epoch: 21 [89600/118320 (76%)]\tLoss: 0.002925\n",
      "Train Epoch: 21 [92160/118320 (78%)]\tLoss: 0.002872\n",
      "Train Epoch: 21 [94720/118320 (80%)]\tLoss: 0.002847\n",
      "Train Epoch: 21 [97280/118320 (82%)]\tLoss: 0.002874\n",
      "Train Epoch: 21 [99840/118320 (84%)]\tLoss: 0.002873\n",
      "Train Epoch: 21 [102400/118320 (86%)]\tLoss: 0.002800\n",
      "Train Epoch: 21 [104960/118320 (89%)]\tLoss: 0.002881\n",
      "Train Epoch: 21 [107520/118320 (91%)]\tLoss: 0.002866\n",
      "Train Epoch: 21 [110080/118320 (93%)]\tLoss: 0.002824\n",
      "Train Epoch: 21 [112640/118320 (95%)]\tLoss: 0.002854\n",
      "Train Epoch: 21 [115200/118320 (97%)]\tLoss: 0.002876\n",
      "Train Epoch: 21 [117760/118320 (99%)]\tLoss: 0.002824\n",
      "\n",
      "Test set: Average loss: 0.0028\n",
      "\n",
      "Train Epoch: 22 [0/118320 (0%)]\tLoss: 0.002814\n",
      "Train Epoch: 22 [2560/118320 (2%)]\tLoss: 0.002831\n",
      "Train Epoch: 22 [5120/118320 (4%)]\tLoss: 0.002822\n",
      "Train Epoch: 22 [7680/118320 (6%)]\tLoss: 0.002766\n",
      "Train Epoch: 22 [10240/118320 (9%)]\tLoss: 0.002792\n",
      "Train Epoch: 22 [12800/118320 (11%)]\tLoss: 0.002772\n",
      "Train Epoch: 22 [15360/118320 (13%)]\tLoss: 0.002815\n",
      "Train Epoch: 22 [17920/118320 (15%)]\tLoss: 0.002813\n",
      "Train Epoch: 22 [20480/118320 (17%)]\tLoss: 0.002818\n",
      "Train Epoch: 22 [23040/118320 (19%)]\tLoss: 0.002835\n",
      "Train Epoch: 22 [25600/118320 (22%)]\tLoss: 0.002789\n",
      "Train Epoch: 22 [28160/118320 (24%)]\tLoss: 0.002839\n",
      "Train Epoch: 22 [30720/118320 (26%)]\tLoss: 0.002839\n",
      "Train Epoch: 22 [33280/118320 (28%)]\tLoss: 0.002870\n",
      "Train Epoch: 22 [35840/118320 (30%)]\tLoss: 0.002824\n",
      "Train Epoch: 22 [38400/118320 (32%)]\tLoss: 0.002778\n",
      "Train Epoch: 22 [40960/118320 (35%)]\tLoss: 0.002800\n",
      "Train Epoch: 22 [43520/118320 (37%)]\tLoss: 0.002799\n",
      "Train Epoch: 22 [46080/118320 (39%)]\tLoss: 0.002804\n",
      "Train Epoch: 22 [48640/118320 (41%)]\tLoss: 0.002776\n",
      "Train Epoch: 22 [51200/118320 (43%)]\tLoss: 0.002795\n",
      "Train Epoch: 22 [53760/118320 (45%)]\tLoss: 0.002823\n",
      "Train Epoch: 22 [56320/118320 (48%)]\tLoss: 0.002784\n",
      "Train Epoch: 22 [58880/118320 (50%)]\tLoss: 0.002791\n",
      "Train Epoch: 22 [61440/118320 (52%)]\tLoss: 0.002826\n",
      "Train Epoch: 22 [64000/118320 (54%)]\tLoss: 0.002775\n",
      "Train Epoch: 22 [66560/118320 (56%)]\tLoss: 0.002820\n",
      "Train Epoch: 22 [69120/118320 (58%)]\tLoss: 0.002828\n",
      "Train Epoch: 22 [71680/118320 (60%)]\tLoss: 0.002744\n",
      "Train Epoch: 22 [74240/118320 (63%)]\tLoss: 0.002747\n",
      "Train Epoch: 22 [76800/118320 (65%)]\tLoss: 0.002818\n",
      "Train Epoch: 22 [79360/118320 (67%)]\tLoss: 0.002773\n",
      "Train Epoch: 22 [81920/118320 (69%)]\tLoss: 0.002787\n",
      "Train Epoch: 22 [84480/118320 (71%)]\tLoss: 0.002740\n",
      "Train Epoch: 22 [87040/118320 (73%)]\tLoss: 0.002774\n",
      "Train Epoch: 22 [89600/118320 (76%)]\tLoss: 0.002791\n",
      "Train Epoch: 22 [92160/118320 (78%)]\tLoss: 0.002772\n",
      "Train Epoch: 22 [94720/118320 (80%)]\tLoss: 0.002752\n",
      "Train Epoch: 22 [97280/118320 (82%)]\tLoss: 0.002770\n",
      "Train Epoch: 22 [99840/118320 (84%)]\tLoss: 0.002744\n",
      "Train Epoch: 22 [102400/118320 (86%)]\tLoss: 0.002756\n",
      "Train Epoch: 22 [104960/118320 (89%)]\tLoss: 0.002774\n",
      "Train Epoch: 22 [107520/118320 (91%)]\tLoss: 0.002747\n",
      "Train Epoch: 22 [110080/118320 (93%)]\tLoss: 0.002755\n",
      "Train Epoch: 22 [112640/118320 (95%)]\tLoss: 0.002743\n",
      "Train Epoch: 22 [115200/118320 (97%)]\tLoss: 0.002730\n",
      "Train Epoch: 22 [117760/118320 (99%)]\tLoss: 0.002741\n",
      "\n",
      "Test set: Average loss: 0.0028\n",
      "\n",
      "Train Epoch: 23 [0/118320 (0%)]\tLoss: 0.002670\n",
      "Train Epoch: 23 [2560/118320 (2%)]\tLoss: 0.002783\n",
      "Train Epoch: 23 [5120/118320 (4%)]\tLoss: 0.002752\n",
      "Train Epoch: 23 [7680/118320 (6%)]\tLoss: 0.002729\n",
      "Train Epoch: 23 [10240/118320 (9%)]\tLoss: 0.002789\n",
      "Train Epoch: 23 [12800/118320 (11%)]\tLoss: 0.002728\n",
      "Train Epoch: 23 [15360/118320 (13%)]\tLoss: 0.002698\n",
      "Train Epoch: 23 [17920/118320 (15%)]\tLoss: 0.002739\n",
      "Train Epoch: 23 [20480/118320 (17%)]\tLoss: 0.002702\n",
      "Train Epoch: 23 [23040/118320 (19%)]\tLoss: 0.002765\n",
      "Train Epoch: 23 [25600/118320 (22%)]\tLoss: 0.002738\n",
      "Train Epoch: 23 [28160/118320 (24%)]\tLoss: 0.002769\n",
      "Train Epoch: 23 [30720/118320 (26%)]\tLoss: 0.002766\n",
      "Train Epoch: 23 [33280/118320 (28%)]\tLoss: 0.002698\n",
      "Train Epoch: 23 [35840/118320 (30%)]\tLoss: 0.002739\n",
      "Train Epoch: 23 [38400/118320 (32%)]\tLoss: 0.002741\n",
      "Train Epoch: 23 [40960/118320 (35%)]\tLoss: 0.002749\n",
      "Train Epoch: 23 [43520/118320 (37%)]\tLoss: 0.002713\n",
      "Train Epoch: 23 [46080/118320 (39%)]\tLoss: 0.002743\n",
      "Train Epoch: 23 [48640/118320 (41%)]\tLoss: 0.002742\n",
      "Train Epoch: 23 [51200/118320 (43%)]\tLoss: 0.002712\n",
      "Train Epoch: 23 [53760/118320 (45%)]\tLoss: 0.002780\n",
      "Train Epoch: 23 [56320/118320 (48%)]\tLoss: 0.002687\n",
      "Train Epoch: 23 [58880/118320 (50%)]\tLoss: 0.002685\n",
      "Train Epoch: 23 [61440/118320 (52%)]\tLoss: 0.002658\n",
      "Train Epoch: 23 [64000/118320 (54%)]\tLoss: 0.002756\n",
      "Train Epoch: 23 [66560/118320 (56%)]\tLoss: 0.002708\n",
      "Train Epoch: 23 [69120/118320 (58%)]\tLoss: 0.002719\n",
      "Train Epoch: 23 [71680/118320 (60%)]\tLoss: 0.002733\n",
      "Train Epoch: 23 [74240/118320 (63%)]\tLoss: 0.002758\n",
      "Train Epoch: 23 [76800/118320 (65%)]\tLoss: 0.002717\n",
      "Train Epoch: 23 [79360/118320 (67%)]\tLoss: 0.002721\n",
      "Train Epoch: 23 [81920/118320 (69%)]\tLoss: 0.002711\n",
      "Train Epoch: 23 [84480/118320 (71%)]\tLoss: 0.002692\n",
      "Train Epoch: 23 [87040/118320 (73%)]\tLoss: 0.002699\n",
      "Train Epoch: 23 [89600/118320 (76%)]\tLoss: 0.002666\n",
      "Train Epoch: 23 [92160/118320 (78%)]\tLoss: 0.002716\n",
      "Train Epoch: 23 [94720/118320 (80%)]\tLoss: 0.002632\n",
      "Train Epoch: 23 [97280/118320 (82%)]\tLoss: 0.002723\n",
      "Train Epoch: 23 [99840/118320 (84%)]\tLoss: 0.002642\n",
      "Train Epoch: 23 [102400/118320 (86%)]\tLoss: 0.002773\n",
      "Train Epoch: 23 [104960/118320 (89%)]\tLoss: 0.002716\n",
      "Train Epoch: 23 [107520/118320 (91%)]\tLoss: 0.002703\n",
      "Train Epoch: 23 [110080/118320 (93%)]\tLoss: 0.002728\n",
      "Train Epoch: 23 [112640/118320 (95%)]\tLoss: 0.002744\n",
      "Train Epoch: 23 [115200/118320 (97%)]\tLoss: 0.002723\n",
      "Train Epoch: 23 [117760/118320 (99%)]\tLoss: 0.002702\n",
      "\n",
      "Test set: Average loss: 0.0027\n",
      "\n",
      "Train Epoch: 24 [0/118320 (0%)]\tLoss: 0.002722\n",
      "Train Epoch: 24 [2560/118320 (2%)]\tLoss: 0.002701\n",
      "Train Epoch: 24 [5120/118320 (4%)]\tLoss: 0.002693\n",
      "Train Epoch: 24 [7680/118320 (6%)]\tLoss: 0.002670\n",
      "Train Epoch: 24 [10240/118320 (9%)]\tLoss: 0.002679\n",
      "Train Epoch: 24 [12800/118320 (11%)]\tLoss: 0.002703\n",
      "Train Epoch: 24 [15360/118320 (13%)]\tLoss: 0.002695\n",
      "Train Epoch: 24 [17920/118320 (15%)]\tLoss: 0.002662\n",
      "Train Epoch: 24 [20480/118320 (17%)]\tLoss: 0.002703\n",
      "Train Epoch: 24 [23040/118320 (19%)]\tLoss: 0.002765\n",
      "Train Epoch: 24 [25600/118320 (22%)]\tLoss: 0.002695\n",
      "Train Epoch: 24 [28160/118320 (24%)]\tLoss: 0.002662\n",
      "Train Epoch: 24 [30720/118320 (26%)]\tLoss: 0.002717\n",
      "Train Epoch: 24 [33280/118320 (28%)]\tLoss: 0.002721\n",
      "Train Epoch: 24 [35840/118320 (30%)]\tLoss: 0.002705\n",
      "Train Epoch: 24 [38400/118320 (32%)]\tLoss: 0.002714\n",
      "Train Epoch: 24 [40960/118320 (35%)]\tLoss: 0.002694\n",
      "Train Epoch: 24 [43520/118320 (37%)]\tLoss: 0.002669\n",
      "Train Epoch: 24 [46080/118320 (39%)]\tLoss: 0.002706\n",
      "Train Epoch: 24 [48640/118320 (41%)]\tLoss: 0.002694\n",
      "Train Epoch: 24 [51200/118320 (43%)]\tLoss: 0.002696\n",
      "Train Epoch: 24 [53760/118320 (45%)]\tLoss: 0.002632\n",
      "Train Epoch: 24 [56320/118320 (48%)]\tLoss: 0.002746\n",
      "Train Epoch: 24 [58880/118320 (50%)]\tLoss: 0.002676\n",
      "Train Epoch: 24 [61440/118320 (52%)]\tLoss: 0.002718\n",
      "Train Epoch: 24 [64000/118320 (54%)]\tLoss: 0.002734\n",
      "Train Epoch: 24 [66560/118320 (56%)]\tLoss: 0.002691\n",
      "Train Epoch: 24 [69120/118320 (58%)]\tLoss: 0.002635\n",
      "Train Epoch: 24 [71680/118320 (60%)]\tLoss: 0.002673\n",
      "Train Epoch: 24 [74240/118320 (63%)]\tLoss: 0.002678\n",
      "Train Epoch: 24 [76800/118320 (65%)]\tLoss: 0.002716\n",
      "Train Epoch: 24 [79360/118320 (67%)]\tLoss: 0.002697\n",
      "Train Epoch: 24 [81920/118320 (69%)]\tLoss: 0.002647\n",
      "Train Epoch: 24 [84480/118320 (71%)]\tLoss: 0.002706\n",
      "Train Epoch: 24 [87040/118320 (73%)]\tLoss: 0.002698\n",
      "Train Epoch: 24 [89600/118320 (76%)]\tLoss: 0.002697\n",
      "Train Epoch: 24 [92160/118320 (78%)]\tLoss: 0.002704\n",
      "Train Epoch: 24 [94720/118320 (80%)]\tLoss: 0.002655\n",
      "Train Epoch: 24 [97280/118320 (82%)]\tLoss: 0.002735\n",
      "Train Epoch: 24 [99840/118320 (84%)]\tLoss: 0.002668\n",
      "Train Epoch: 24 [102400/118320 (86%)]\tLoss: 0.002655\n",
      "Train Epoch: 24 [104960/118320 (89%)]\tLoss: 0.002703\n",
      "Train Epoch: 24 [107520/118320 (91%)]\tLoss: 0.002700\n",
      "Train Epoch: 24 [110080/118320 (93%)]\tLoss: 0.002671\n",
      "Train Epoch: 24 [112640/118320 (95%)]\tLoss: 0.002685\n",
      "Train Epoch: 24 [115200/118320 (97%)]\tLoss: 0.002641\n",
      "Train Epoch: 24 [117760/118320 (99%)]\tLoss: 0.002700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0027\n",
      "\n",
      "Train Epoch: 25 [0/118320 (0%)]\tLoss: 0.002595\n",
      "Train Epoch: 25 [2560/118320 (2%)]\tLoss: 0.002644\n",
      "Train Epoch: 25 [5120/118320 (4%)]\tLoss: 0.002683\n",
      "Train Epoch: 25 [7680/118320 (6%)]\tLoss: 0.002672\n",
      "Train Epoch: 25 [10240/118320 (9%)]\tLoss: 0.002670\n",
      "Train Epoch: 25 [12800/118320 (11%)]\tLoss: 0.002711\n",
      "Train Epoch: 25 [15360/118320 (13%)]\tLoss: 0.002705\n",
      "Train Epoch: 25 [17920/118320 (15%)]\tLoss: 0.002677\n",
      "Train Epoch: 25 [20480/118320 (17%)]\tLoss: 0.002690\n",
      "Train Epoch: 25 [23040/118320 (19%)]\tLoss: 0.002619\n",
      "Train Epoch: 25 [25600/118320 (22%)]\tLoss: 0.002661\n",
      "Train Epoch: 25 [28160/118320 (24%)]\tLoss: 0.002691\n",
      "Train Epoch: 25 [30720/118320 (26%)]\tLoss: 0.002674\n",
      "Train Epoch: 25 [33280/118320 (28%)]\tLoss: 0.002693\n",
      "Train Epoch: 25 [35840/118320 (30%)]\tLoss: 0.002681\n",
      "Train Epoch: 25 [38400/118320 (32%)]\tLoss: 0.002748\n",
      "Train Epoch: 25 [40960/118320 (35%)]\tLoss: 0.002682\n",
      "Train Epoch: 25 [43520/118320 (37%)]\tLoss: 0.002623\n",
      "Train Epoch: 25 [46080/118320 (39%)]\tLoss: 0.002629\n",
      "Train Epoch: 25 [48640/118320 (41%)]\tLoss: 0.002712\n",
      "Train Epoch: 25 [51200/118320 (43%)]\tLoss: 0.002653\n",
      "Train Epoch: 25 [53760/118320 (45%)]\tLoss: 0.002700\n",
      "Train Epoch: 25 [56320/118320 (48%)]\tLoss: 0.002674\n",
      "Train Epoch: 25 [58880/118320 (50%)]\tLoss: 0.002641\n",
      "Train Epoch: 25 [61440/118320 (52%)]\tLoss: 0.002696\n",
      "Train Epoch: 25 [64000/118320 (54%)]\tLoss: 0.002657\n",
      "Train Epoch: 25 [66560/118320 (56%)]\tLoss: 0.002702\n",
      "Train Epoch: 25 [69120/118320 (58%)]\tLoss: 0.002704\n",
      "Train Epoch: 25 [71680/118320 (60%)]\tLoss: 0.002663\n",
      "Train Epoch: 25 [74240/118320 (63%)]\tLoss: 0.002654\n",
      "Train Epoch: 25 [76800/118320 (65%)]\tLoss: 0.002679\n",
      "Train Epoch: 25 [79360/118320 (67%)]\tLoss: 0.002634\n",
      "Train Epoch: 25 [81920/118320 (69%)]\tLoss: 0.002636\n",
      "Train Epoch: 25 [84480/118320 (71%)]\tLoss: 0.002656\n",
      "Train Epoch: 25 [87040/118320 (73%)]\tLoss: 0.002690\n",
      "Train Epoch: 25 [89600/118320 (76%)]\tLoss: 0.002619\n",
      "Train Epoch: 25 [92160/118320 (78%)]\tLoss: 0.002604\n",
      "Train Epoch: 25 [94720/118320 (80%)]\tLoss: 0.002676\n",
      "Train Epoch: 25 [97280/118320 (82%)]\tLoss: 0.002665\n",
      "Train Epoch: 25 [99840/118320 (84%)]\tLoss: 0.002698\n",
      "Train Epoch: 25 [102400/118320 (86%)]\tLoss: 0.002692\n",
      "Train Epoch: 25 [104960/118320 (89%)]\tLoss: 0.002642\n",
      "Train Epoch: 25 [107520/118320 (91%)]\tLoss: 0.002674\n",
      "Train Epoch: 25 [110080/118320 (93%)]\tLoss: 0.002701\n",
      "Train Epoch: 25 [112640/118320 (95%)]\tLoss: 0.002684\n",
      "Train Epoch: 25 [115200/118320 (97%)]\tLoss: 0.002692\n",
      "Train Epoch: 25 [117760/118320 (99%)]\tLoss: 0.002666\n",
      "\n",
      "Test set: Average loss: 0.0027\n",
      "\n",
      "Train Epoch: 26 [0/118320 (0%)]\tLoss: 0.002660\n",
      "Train Epoch: 26 [2560/118320 (2%)]\tLoss: 0.002686\n",
      "Train Epoch: 26 [5120/118320 (4%)]\tLoss: 0.002695\n",
      "Train Epoch: 26 [7680/118320 (6%)]\tLoss: 0.002689\n",
      "Train Epoch: 26 [10240/118320 (9%)]\tLoss: 0.002664\n",
      "Train Epoch: 26 [12800/118320 (11%)]\tLoss: 0.002654\n",
      "Train Epoch: 26 [15360/118320 (13%)]\tLoss: 0.002715\n",
      "Train Epoch: 26 [17920/118320 (15%)]\tLoss: 0.002667\n",
      "Train Epoch: 26 [20480/118320 (17%)]\tLoss: 0.002682\n",
      "Train Epoch: 26 [23040/118320 (19%)]\tLoss: 0.002636\n",
      "Train Epoch: 26 [25600/118320 (22%)]\tLoss: 0.002679\n",
      "Train Epoch: 26 [28160/118320 (24%)]\tLoss: 0.002667\n",
      "Train Epoch: 26 [30720/118320 (26%)]\tLoss: 0.002598\n",
      "Train Epoch: 26 [33280/118320 (28%)]\tLoss: 0.002716\n",
      "Train Epoch: 26 [35840/118320 (30%)]\tLoss: 0.002660\n",
      "Train Epoch: 26 [38400/118320 (32%)]\tLoss: 0.002729\n",
      "Train Epoch: 26 [40960/118320 (35%)]\tLoss: 0.002607\n",
      "Train Epoch: 26 [43520/118320 (37%)]\tLoss: 0.002649\n",
      "Train Epoch: 26 [46080/118320 (39%)]\tLoss: 0.002657\n",
      "Train Epoch: 26 [48640/118320 (41%)]\tLoss: 0.002728\n",
      "Train Epoch: 26 [51200/118320 (43%)]\tLoss: 0.002601\n",
      "Train Epoch: 26 [53760/118320 (45%)]\tLoss: 0.002712\n",
      "Train Epoch: 26 [56320/118320 (48%)]\tLoss: 0.002670\n",
      "Train Epoch: 26 [58880/118320 (50%)]\tLoss: 0.002732\n",
      "Train Epoch: 26 [61440/118320 (52%)]\tLoss: 0.002620\n",
      "Train Epoch: 26 [64000/118320 (54%)]\tLoss: 0.002641\n",
      "Train Epoch: 26 [66560/118320 (56%)]\tLoss: 0.002627\n",
      "Train Epoch: 26 [69120/118320 (58%)]\tLoss: 0.002668\n",
      "Train Epoch: 26 [71680/118320 (60%)]\tLoss: 0.002674\n",
      "Train Epoch: 26 [74240/118320 (63%)]\tLoss: 0.002671\n",
      "Train Epoch: 26 [76800/118320 (65%)]\tLoss: 0.002692\n",
      "Train Epoch: 26 [79360/118320 (67%)]\tLoss: 0.002659\n",
      "Train Epoch: 26 [81920/118320 (69%)]\tLoss: 0.002669\n",
      "Train Epoch: 26 [84480/118320 (71%)]\tLoss: 0.002697\n",
      "Train Epoch: 26 [87040/118320 (73%)]\tLoss: 0.002614\n",
      "Train Epoch: 26 [89600/118320 (76%)]\tLoss: 0.002697\n",
      "Train Epoch: 26 [92160/118320 (78%)]\tLoss: 0.002670\n",
      "Train Epoch: 26 [94720/118320 (80%)]\tLoss: 0.002650\n",
      "Train Epoch: 26 [97280/118320 (82%)]\tLoss: 0.002640\n",
      "Train Epoch: 26 [99840/118320 (84%)]\tLoss: 0.002748\n",
      "Train Epoch: 26 [102400/118320 (86%)]\tLoss: 0.002694\n",
      "Train Epoch: 26 [104960/118320 (89%)]\tLoss: 0.002651\n",
      "Train Epoch: 26 [107520/118320 (91%)]\tLoss: 0.002709\n",
      "Train Epoch: 26 [110080/118320 (93%)]\tLoss: 0.002675\n",
      "Train Epoch: 26 [112640/118320 (95%)]\tLoss: 0.002678\n",
      "Train Epoch: 26 [115200/118320 (97%)]\tLoss: 0.002722\n",
      "Train Epoch: 26 [117760/118320 (99%)]\tLoss: 0.002729\n",
      "\n",
      "Test set: Average loss: 0.0027\n",
      "\n",
      "Train Epoch: 27 [0/118320 (0%)]\tLoss: 0.002611\n",
      "Train Epoch: 27 [2560/118320 (2%)]\tLoss: 0.002622\n",
      "Train Epoch: 27 [5120/118320 (4%)]\tLoss: 0.002617\n",
      "Train Epoch: 27 [7680/118320 (6%)]\tLoss: 0.002653\n",
      "Train Epoch: 27 [10240/118320 (9%)]\tLoss: 0.002665\n",
      "Train Epoch: 27 [12800/118320 (11%)]\tLoss: 0.002639\n",
      "Train Epoch: 27 [15360/118320 (13%)]\tLoss: 0.002645\n",
      "Train Epoch: 27 [17920/118320 (15%)]\tLoss: 0.002693\n",
      "Train Epoch: 27 [20480/118320 (17%)]\tLoss: 0.002650\n",
      "Train Epoch: 27 [23040/118320 (19%)]\tLoss: 0.002655\n",
      "Train Epoch: 27 [25600/118320 (22%)]\tLoss: 0.002707\n",
      "Train Epoch: 27 [28160/118320 (24%)]\tLoss: 0.002663\n",
      "Train Epoch: 27 [30720/118320 (26%)]\tLoss: 0.002625\n",
      "Train Epoch: 27 [33280/118320 (28%)]\tLoss: 0.002683\n",
      "Train Epoch: 27 [35840/118320 (30%)]\tLoss: 0.002660\n",
      "Train Epoch: 27 [38400/118320 (32%)]\tLoss: 0.002685\n",
      "Train Epoch: 27 [40960/118320 (35%)]\tLoss: 0.002669\n",
      "Train Epoch: 27 [43520/118320 (37%)]\tLoss: 0.002713\n",
      "Train Epoch: 27 [46080/118320 (39%)]\tLoss: 0.002645\n",
      "Train Epoch: 27 [48640/118320 (41%)]\tLoss: 0.002657\n",
      "Train Epoch: 27 [51200/118320 (43%)]\tLoss: 0.002659\n",
      "Train Epoch: 27 [53760/118320 (45%)]\tLoss: 0.002649\n",
      "Train Epoch: 27 [56320/118320 (48%)]\tLoss: 0.002580\n",
      "Train Epoch: 27 [58880/118320 (50%)]\tLoss: 0.002652\n",
      "Train Epoch: 27 [61440/118320 (52%)]\tLoss: 0.002653\n",
      "Train Epoch: 27 [64000/118320 (54%)]\tLoss: 0.002637\n",
      "Train Epoch: 27 [66560/118320 (56%)]\tLoss: 0.002659\n",
      "Train Epoch: 27 [69120/118320 (58%)]\tLoss: 0.002630\n",
      "Train Epoch: 27 [71680/118320 (60%)]\tLoss: 0.002686\n",
      "Train Epoch: 27 [74240/118320 (63%)]\tLoss: 0.002656\n",
      "Train Epoch: 27 [76800/118320 (65%)]\tLoss: 0.002657\n",
      "Train Epoch: 27 [79360/118320 (67%)]\tLoss: 0.002657\n",
      "Train Epoch: 27 [81920/118320 (69%)]\tLoss: 0.002680\n",
      "Train Epoch: 27 [84480/118320 (71%)]\tLoss: 0.002608\n",
      "Train Epoch: 27 [87040/118320 (73%)]\tLoss: 0.002679\n",
      "Train Epoch: 27 [89600/118320 (76%)]\tLoss: 0.002640\n",
      "Train Epoch: 27 [92160/118320 (78%)]\tLoss: 0.002631\n",
      "Train Epoch: 27 [94720/118320 (80%)]\tLoss: 0.002679\n",
      "Train Epoch: 27 [97280/118320 (82%)]\tLoss: 0.002727\n",
      "Train Epoch: 27 [99840/118320 (84%)]\tLoss: 0.002670\n",
      "Train Epoch: 27 [102400/118320 (86%)]\tLoss: 0.002686\n",
      "Train Epoch: 27 [104960/118320 (89%)]\tLoss: 0.002669\n",
      "Train Epoch: 27 [107520/118320 (91%)]\tLoss: 0.002636\n",
      "Train Epoch: 27 [110080/118320 (93%)]\tLoss: 0.002678\n",
      "Train Epoch: 27 [112640/118320 (95%)]\tLoss: 0.002692\n",
      "Train Epoch: 27 [115200/118320 (97%)]\tLoss: 0.002702\n",
      "Train Epoch: 27 [117760/118320 (99%)]\tLoss: 0.002650\n",
      "\n",
      "Test set: Average loss: 0.0027\n",
      "\n",
      "Train Epoch: 28 [0/118320 (0%)]\tLoss: 0.002600\n",
      "Train Epoch: 28 [2560/118320 (2%)]\tLoss: 0.002659\n",
      "Train Epoch: 28 [5120/118320 (4%)]\tLoss: 0.002687\n",
      "Train Epoch: 28 [7680/118320 (6%)]\tLoss: 0.002596\n",
      "Train Epoch: 28 [10240/118320 (9%)]\tLoss: 0.002631\n",
      "Train Epoch: 28 [12800/118320 (11%)]\tLoss: 0.002660\n",
      "Train Epoch: 28 [15360/118320 (13%)]\tLoss: 0.002682\n",
      "Train Epoch: 28 [17920/118320 (15%)]\tLoss: 0.002679\n",
      "Train Epoch: 28 [20480/118320 (17%)]\tLoss: 0.002653\n",
      "Train Epoch: 28 [23040/118320 (19%)]\tLoss: 0.002659\n",
      "Train Epoch: 28 [25600/118320 (22%)]\tLoss: 0.002659\n",
      "Train Epoch: 28 [28160/118320 (24%)]\tLoss: 0.002708\n",
      "Train Epoch: 28 [30720/118320 (26%)]\tLoss: 0.002597\n",
      "Train Epoch: 28 [33280/118320 (28%)]\tLoss: 0.002623\n",
      "Train Epoch: 28 [35840/118320 (30%)]\tLoss: 0.002686\n",
      "Train Epoch: 28 [38400/118320 (32%)]\tLoss: 0.002673\n",
      "Train Epoch: 28 [40960/118320 (35%)]\tLoss: 0.002688\n",
      "Train Epoch: 28 [43520/118320 (37%)]\tLoss: 0.002614\n",
      "Train Epoch: 28 [46080/118320 (39%)]\tLoss: 0.002615\n",
      "Train Epoch: 28 [48640/118320 (41%)]\tLoss: 0.002619\n",
      "Train Epoch: 28 [51200/118320 (43%)]\tLoss: 0.002650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 28 [53760/118320 (45%)]\tLoss: 0.002672\n",
      "Train Epoch: 28 [56320/118320 (48%)]\tLoss: 0.002667\n",
      "Train Epoch: 28 [58880/118320 (50%)]\tLoss: 0.002677\n",
      "Train Epoch: 28 [61440/118320 (52%)]\tLoss: 0.002616\n",
      "Train Epoch: 28 [64000/118320 (54%)]\tLoss: 0.002602\n",
      "Train Epoch: 28 [66560/118320 (56%)]\tLoss: 0.002696\n",
      "Train Epoch: 28 [69120/118320 (58%)]\tLoss: 0.002628\n",
      "Train Epoch: 28 [71680/118320 (60%)]\tLoss: 0.002691\n",
      "Train Epoch: 28 [74240/118320 (63%)]\tLoss: 0.002610\n",
      "Train Epoch: 28 [76800/118320 (65%)]\tLoss: 0.002681\n",
      "Train Epoch: 28 [79360/118320 (67%)]\tLoss: 0.002663\n",
      "Train Epoch: 28 [81920/118320 (69%)]\tLoss: 0.002681\n",
      "Train Epoch: 28 [84480/118320 (71%)]\tLoss: 0.002669\n",
      "Train Epoch: 28 [87040/118320 (73%)]\tLoss: 0.002654\n",
      "Train Epoch: 28 [89600/118320 (76%)]\tLoss: 0.002687\n",
      "Train Epoch: 28 [92160/118320 (78%)]\tLoss: 0.002650\n",
      "Train Epoch: 28 [94720/118320 (80%)]\tLoss: 0.002657\n",
      "Train Epoch: 28 [97280/118320 (82%)]\tLoss: 0.002663\n",
      "Train Epoch: 28 [99840/118320 (84%)]\tLoss: 0.002655\n",
      "Train Epoch: 28 [102400/118320 (86%)]\tLoss: 0.002641\n",
      "Train Epoch: 28 [104960/118320 (89%)]\tLoss: 0.002646\n",
      "Train Epoch: 28 [107520/118320 (91%)]\tLoss: 0.002650\n",
      "Train Epoch: 28 [110080/118320 (93%)]\tLoss: 0.002658\n",
      "Train Epoch: 28 [112640/118320 (95%)]\tLoss: 0.002614\n",
      "Train Epoch: 28 [115200/118320 (97%)]\tLoss: 0.002668\n",
      "Train Epoch: 28 [117760/118320 (99%)]\tLoss: 0.002611\n",
      "\n",
      "Test set: Average loss: 0.0027\n",
      "\n",
      "Train Epoch: 29 [0/118320 (0%)]\tLoss: 0.002670\n",
      "Train Epoch: 29 [2560/118320 (2%)]\tLoss: 0.002680\n",
      "Train Epoch: 29 [5120/118320 (4%)]\tLoss: 0.002600\n",
      "Train Epoch: 29 [7680/118320 (6%)]\tLoss: 0.002669\n",
      "Train Epoch: 29 [10240/118320 (9%)]\tLoss: 0.002628\n",
      "Train Epoch: 29 [12800/118320 (11%)]\tLoss: 0.002650\n",
      "Train Epoch: 29 [15360/118320 (13%)]\tLoss: 0.002710\n",
      "Train Epoch: 29 [17920/118320 (15%)]\tLoss: 0.002654\n",
      "Train Epoch: 29 [20480/118320 (17%)]\tLoss: 0.002604\n",
      "Train Epoch: 29 [23040/118320 (19%)]\tLoss: 0.002631\n",
      "Train Epoch: 29 [25600/118320 (22%)]\tLoss: 0.002629\n",
      "Train Epoch: 29 [28160/118320 (24%)]\tLoss: 0.002657\n",
      "Train Epoch: 29 [30720/118320 (26%)]\tLoss: 0.002663\n",
      "Train Epoch: 29 [33280/118320 (28%)]\tLoss: 0.002672\n",
      "Train Epoch: 29 [35840/118320 (30%)]\tLoss: 0.002643\n",
      "Train Epoch: 29 [38400/118320 (32%)]\tLoss: 0.002702\n",
      "Train Epoch: 29 [40960/118320 (35%)]\tLoss: 0.002703\n",
      "Train Epoch: 29 [43520/118320 (37%)]\tLoss: 0.002648\n",
      "Train Epoch: 29 [46080/118320 (39%)]\tLoss: 0.002627\n",
      "Train Epoch: 29 [48640/118320 (41%)]\tLoss: 0.002616\n",
      "Train Epoch: 29 [51200/118320 (43%)]\tLoss: 0.002654\n",
      "Train Epoch: 29 [53760/118320 (45%)]\tLoss: 0.002686\n",
      "Train Epoch: 29 [56320/118320 (48%)]\tLoss: 0.002598\n",
      "Train Epoch: 29 [58880/118320 (50%)]\tLoss: 0.002678\n",
      "Train Epoch: 29 [61440/118320 (52%)]\tLoss: 0.002686\n",
      "Train Epoch: 29 [64000/118320 (54%)]\tLoss: 0.002670\n",
      "Train Epoch: 29 [66560/118320 (56%)]\tLoss: 0.002639\n",
      "Train Epoch: 29 [69120/118320 (58%)]\tLoss: 0.002669\n",
      "Train Epoch: 29 [71680/118320 (60%)]\tLoss: 0.002662\n",
      "Train Epoch: 29 [74240/118320 (63%)]\tLoss: 0.002702\n",
      "Train Epoch: 29 [76800/118320 (65%)]\tLoss: 0.002675\n",
      "Train Epoch: 29 [79360/118320 (67%)]\tLoss: 0.002683\n",
      "Train Epoch: 29 [81920/118320 (69%)]\tLoss: 0.002667\n",
      "Train Epoch: 29 [84480/118320 (71%)]\tLoss: 0.002619\n",
      "Train Epoch: 29 [87040/118320 (73%)]\tLoss: 0.002669\n",
      "Train Epoch: 29 [89600/118320 (76%)]\tLoss: 0.002642\n",
      "Train Epoch: 29 [92160/118320 (78%)]\tLoss: 0.002627\n",
      "Train Epoch: 29 [94720/118320 (80%)]\tLoss: 0.002674\n",
      "Train Epoch: 29 [97280/118320 (82%)]\tLoss: 0.002586\n",
      "Train Epoch: 29 [99840/118320 (84%)]\tLoss: 0.002640\n",
      "Train Epoch: 29 [102400/118320 (86%)]\tLoss: 0.002668\n",
      "Train Epoch: 29 [104960/118320 (89%)]\tLoss: 0.002630\n",
      "Train Epoch: 29 [107520/118320 (91%)]\tLoss: 0.002621\n",
      "Train Epoch: 29 [110080/118320 (93%)]\tLoss: 0.002650\n",
      "Train Epoch: 29 [112640/118320 (95%)]\tLoss: 0.002642\n",
      "Train Epoch: 29 [115200/118320 (97%)]\tLoss: 0.002650\n",
      "Train Epoch: 29 [117760/118320 (99%)]\tLoss: 0.002616\n",
      "\n",
      "Test set: Average loss: 0.0027\n",
      "\n",
      "Train Epoch: 30 [0/118320 (0%)]\tLoss: 0.002639\n",
      "Train Epoch: 30 [2560/118320 (2%)]\tLoss: 0.002659\n",
      "Train Epoch: 30 [5120/118320 (4%)]\tLoss: 0.002666\n",
      "Train Epoch: 30 [7680/118320 (6%)]\tLoss: 0.002601\n",
      "Train Epoch: 30 [10240/118320 (9%)]\tLoss: 0.002631\n",
      "Train Epoch: 30 [12800/118320 (11%)]\tLoss: 0.002626\n",
      "Train Epoch: 30 [15360/118320 (13%)]\tLoss: 0.002644\n",
      "Train Epoch: 30 [17920/118320 (15%)]\tLoss: 0.002658\n",
      "Train Epoch: 30 [20480/118320 (17%)]\tLoss: 0.002607\n",
      "Train Epoch: 30 [23040/118320 (19%)]\tLoss: 0.002647\n",
      "Train Epoch: 30 [25600/118320 (22%)]\tLoss: 0.002659\n",
      "Train Epoch: 30 [28160/118320 (24%)]\tLoss: 0.002656\n",
      "Train Epoch: 30 [30720/118320 (26%)]\tLoss: 0.002679\n",
      "Train Epoch: 30 [33280/118320 (28%)]\tLoss: 0.002615\n",
      "Train Epoch: 30 [35840/118320 (30%)]\tLoss: 0.002611\n",
      "Train Epoch: 30 [38400/118320 (32%)]\tLoss: 0.002615\n",
      "Train Epoch: 30 [40960/118320 (35%)]\tLoss: 0.002671\n",
      "Train Epoch: 30 [43520/118320 (37%)]\tLoss: 0.002661\n",
      "Train Epoch: 30 [46080/118320 (39%)]\tLoss: 0.002640\n",
      "Train Epoch: 30 [48640/118320 (41%)]\tLoss: 0.002668\n",
      "Train Epoch: 30 [51200/118320 (43%)]\tLoss: 0.002609\n",
      "Train Epoch: 30 [53760/118320 (45%)]\tLoss: 0.002644\n",
      "Train Epoch: 30 [56320/118320 (48%)]\tLoss: 0.002649\n",
      "Train Epoch: 30 [58880/118320 (50%)]\tLoss: 0.002608\n",
      "Train Epoch: 30 [61440/118320 (52%)]\tLoss: 0.002606\n",
      "Train Epoch: 30 [64000/118320 (54%)]\tLoss: 0.002636\n",
      "Train Epoch: 30 [66560/118320 (56%)]\tLoss: 0.002616\n",
      "Train Epoch: 30 [69120/118320 (58%)]\tLoss: 0.002658\n",
      "Train Epoch: 30 [71680/118320 (60%)]\tLoss: 0.002628\n",
      "Train Epoch: 30 [74240/118320 (63%)]\tLoss: 0.002662\n",
      "Train Epoch: 30 [76800/118320 (65%)]\tLoss: 0.002620\n",
      "Train Epoch: 30 [79360/118320 (67%)]\tLoss: 0.002677\n",
      "Train Epoch: 30 [81920/118320 (69%)]\tLoss: 0.002718\n",
      "Train Epoch: 30 [84480/118320 (71%)]\tLoss: 0.002653\n",
      "Train Epoch: 30 [87040/118320 (73%)]\tLoss: 0.002616\n",
      "Train Epoch: 30 [89600/118320 (76%)]\tLoss: 0.002701\n",
      "Train Epoch: 30 [92160/118320 (78%)]\tLoss: 0.002615\n",
      "Train Epoch: 30 [94720/118320 (80%)]\tLoss: 0.002629\n",
      "Train Epoch: 30 [97280/118320 (82%)]\tLoss: 0.002659\n",
      "Train Epoch: 30 [99840/118320 (84%)]\tLoss: 0.002686\n",
      "Train Epoch: 30 [102400/118320 (86%)]\tLoss: 0.002666\n",
      "Train Epoch: 30 [104960/118320 (89%)]\tLoss: 0.002639\n",
      "Train Epoch: 30 [107520/118320 (91%)]\tLoss: 0.002621\n",
      "Train Epoch: 30 [110080/118320 (93%)]\tLoss: 0.002657\n",
      "Train Epoch: 30 [112640/118320 (95%)]\tLoss: 0.002604\n",
      "Train Epoch: 30 [115200/118320 (97%)]\tLoss: 0.002636\n",
      "Train Epoch: 30 [117760/118320 (99%)]\tLoss: 0.002646\n",
      "\n",
      "Test set: Average loss: 0.0027\n",
      "\n",
      "Train Epoch: 31 [0/118320 (0%)]\tLoss: 0.002703\n",
      "Train Epoch: 31 [2560/118320 (2%)]\tLoss: 0.002637\n",
      "Train Epoch: 31 [5120/118320 (4%)]\tLoss: 0.002679\n",
      "Train Epoch: 31 [7680/118320 (6%)]\tLoss: 0.002663\n",
      "Train Epoch: 31 [10240/118320 (9%)]\tLoss: 0.002679\n",
      "Train Epoch: 31 [12800/118320 (11%)]\tLoss: 0.002604\n",
      "Train Epoch: 31 [15360/118320 (13%)]\tLoss: 0.002644\n",
      "Train Epoch: 31 [17920/118320 (15%)]\tLoss: 0.002632\n",
      "Train Epoch: 31 [20480/118320 (17%)]\tLoss: 0.002630\n",
      "Train Epoch: 31 [23040/118320 (19%)]\tLoss: 0.002603\n",
      "Train Epoch: 31 [25600/118320 (22%)]\tLoss: 0.002626\n",
      "Train Epoch: 31 [28160/118320 (24%)]\tLoss: 0.002686\n",
      "Train Epoch: 31 [30720/118320 (26%)]\tLoss: 0.002612\n",
      "Train Epoch: 31 [33280/118320 (28%)]\tLoss: 0.002626\n",
      "Train Epoch: 31 [35840/118320 (30%)]\tLoss: 0.002639\n",
      "Train Epoch: 31 [38400/118320 (32%)]\tLoss: 0.002614\n",
      "Train Epoch: 31 [40960/118320 (35%)]\tLoss: 0.002610\n",
      "Train Epoch: 31 [43520/118320 (37%)]\tLoss: 0.002689\n",
      "Train Epoch: 31 [46080/118320 (39%)]\tLoss: 0.002611\n",
      "Train Epoch: 31 [48640/118320 (41%)]\tLoss: 0.002614\n",
      "Train Epoch: 31 [51200/118320 (43%)]\tLoss: 0.002592\n",
      "Train Epoch: 31 [53760/118320 (45%)]\tLoss: 0.002618\n",
      "Train Epoch: 31 [56320/118320 (48%)]\tLoss: 0.002603\n",
      "Train Epoch: 31 [58880/118320 (50%)]\tLoss: 0.002634\n",
      "Train Epoch: 31 [61440/118320 (52%)]\tLoss: 0.002691\n",
      "Train Epoch: 31 [64000/118320 (54%)]\tLoss: 0.002699\n",
      "Train Epoch: 31 [66560/118320 (56%)]\tLoss: 0.002594\n",
      "Train Epoch: 31 [69120/118320 (58%)]\tLoss: 0.002638\n",
      "Train Epoch: 31 [71680/118320 (60%)]\tLoss: 0.002623\n",
      "Train Epoch: 31 [74240/118320 (63%)]\tLoss: 0.002709\n",
      "Train Epoch: 31 [76800/118320 (65%)]\tLoss: 0.002671\n",
      "Train Epoch: 31 [79360/118320 (67%)]\tLoss: 0.002656\n",
      "Train Epoch: 31 [81920/118320 (69%)]\tLoss: 0.002678\n",
      "Train Epoch: 31 [84480/118320 (71%)]\tLoss: 0.002643\n",
      "Train Epoch: 31 [87040/118320 (73%)]\tLoss: 0.002665\n",
      "Train Epoch: 31 [89600/118320 (76%)]\tLoss: 0.002617\n",
      "Train Epoch: 31 [92160/118320 (78%)]\tLoss: 0.002652\n",
      "Train Epoch: 31 [94720/118320 (80%)]\tLoss: 0.002652\n",
      "Train Epoch: 31 [97280/118320 (82%)]\tLoss: 0.002612\n",
      "Train Epoch: 31 [99840/118320 (84%)]\tLoss: 0.002627\n",
      "Train Epoch: 31 [102400/118320 (86%)]\tLoss: 0.002585\n",
      "Train Epoch: 31 [104960/118320 (89%)]\tLoss: 0.002629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 31 [107520/118320 (91%)]\tLoss: 0.002619\n",
      "Train Epoch: 31 [110080/118320 (93%)]\tLoss: 0.002651\n",
      "Train Epoch: 31 [112640/118320 (95%)]\tLoss: 0.002616\n",
      "Train Epoch: 31 [115200/118320 (97%)]\tLoss: 0.002700\n",
      "Train Epoch: 31 [117760/118320 (99%)]\tLoss: 0.002684\n",
      "\n",
      "Test set: Average loss: 0.0026\n",
      "\n",
      "Train Epoch: 32 [0/118320 (0%)]\tLoss: 0.002623\n",
      "Train Epoch: 32 [2560/118320 (2%)]\tLoss: 0.002633\n",
      "Train Epoch: 32 [5120/118320 (4%)]\tLoss: 0.002648\n",
      "Train Epoch: 32 [7680/118320 (6%)]\tLoss: 0.002607\n",
      "Train Epoch: 32 [10240/118320 (9%)]\tLoss: 0.002667\n",
      "Train Epoch: 32 [12800/118320 (11%)]\tLoss: 0.002583\n",
      "Train Epoch: 32 [15360/118320 (13%)]\tLoss: 0.002644\n",
      "Train Epoch: 32 [17920/118320 (15%)]\tLoss: 0.002658\n",
      "Train Epoch: 32 [20480/118320 (17%)]\tLoss: 0.002640\n",
      "Train Epoch: 32 [23040/118320 (19%)]\tLoss: 0.002664\n",
      "Train Epoch: 32 [25600/118320 (22%)]\tLoss: 0.002660\n",
      "Train Epoch: 32 [28160/118320 (24%)]\tLoss: 0.002611\n",
      "Train Epoch: 32 [30720/118320 (26%)]\tLoss: 0.002633\n",
      "Train Epoch: 32 [33280/118320 (28%)]\tLoss: 0.002640\n",
      "Train Epoch: 32 [35840/118320 (30%)]\tLoss: 0.002637\n",
      "Train Epoch: 32 [38400/118320 (32%)]\tLoss: 0.002682\n",
      "Train Epoch: 32 [40960/118320 (35%)]\tLoss: 0.002680\n",
      "Train Epoch: 32 [43520/118320 (37%)]\tLoss: 0.002606\n",
      "Train Epoch: 32 [46080/118320 (39%)]\tLoss: 0.002690\n",
      "Train Epoch: 32 [48640/118320 (41%)]\tLoss: 0.002591\n",
      "Train Epoch: 32 [51200/118320 (43%)]\tLoss: 0.002715\n",
      "Train Epoch: 32 [53760/118320 (45%)]\tLoss: 0.002663\n",
      "Train Epoch: 32 [56320/118320 (48%)]\tLoss: 0.002620\n",
      "Train Epoch: 32 [58880/118320 (50%)]\tLoss: 0.002661\n",
      "Train Epoch: 32 [61440/118320 (52%)]\tLoss: 0.002664\n",
      "Train Epoch: 32 [64000/118320 (54%)]\tLoss: 0.002665\n",
      "Train Epoch: 32 [66560/118320 (56%)]\tLoss: 0.002633\n",
      "Train Epoch: 32 [69120/118320 (58%)]\tLoss: 0.002628\n",
      "Train Epoch: 32 [71680/118320 (60%)]\tLoss: 0.002630\n",
      "Train Epoch: 32 [74240/118320 (63%)]\tLoss: 0.002666\n",
      "Train Epoch: 32 [76800/118320 (65%)]\tLoss: 0.002603\n",
      "Train Epoch: 32 [79360/118320 (67%)]\tLoss: 0.002609\n",
      "Train Epoch: 32 [81920/118320 (69%)]\tLoss: 0.002675\n",
      "Train Epoch: 32 [84480/118320 (71%)]\tLoss: 0.002578\n",
      "Train Epoch: 32 [87040/118320 (73%)]\tLoss: 0.002633\n",
      "Train Epoch: 32 [89600/118320 (76%)]\tLoss: 0.002599\n",
      "Train Epoch: 32 [92160/118320 (78%)]\tLoss: 0.002668\n",
      "Train Epoch: 32 [94720/118320 (80%)]\tLoss: 0.002605\n",
      "Train Epoch: 32 [97280/118320 (82%)]\tLoss: 0.002646\n",
      "Train Epoch: 32 [99840/118320 (84%)]\tLoss: 0.002626\n",
      "Train Epoch: 32 [102400/118320 (86%)]\tLoss: 0.002628\n",
      "Train Epoch: 32 [104960/118320 (89%)]\tLoss: 0.002666\n",
      "Train Epoch: 32 [107520/118320 (91%)]\tLoss: 0.002639\n",
      "Train Epoch: 32 [110080/118320 (93%)]\tLoss: 0.002629\n",
      "Train Epoch: 32 [112640/118320 (95%)]\tLoss: 0.002572\n",
      "Train Epoch: 32 [115200/118320 (97%)]\tLoss: 0.002607\n",
      "Train Epoch: 32 [117760/118320 (99%)]\tLoss: 0.002650\n",
      "\n",
      "Test set: Average loss: 0.0026\n",
      "\n",
      "Train Epoch: 33 [0/118320 (0%)]\tLoss: 0.002642\n",
      "Train Epoch: 33 [2560/118320 (2%)]\tLoss: 0.002570\n",
      "Train Epoch: 33 [5120/118320 (4%)]\tLoss: 0.002662\n",
      "Train Epoch: 33 [7680/118320 (6%)]\tLoss: 0.002619\n",
      "Train Epoch: 33 [10240/118320 (9%)]\tLoss: 0.002652\n",
      "Train Epoch: 33 [12800/118320 (11%)]\tLoss: 0.002642\n",
      "Train Epoch: 33 [15360/118320 (13%)]\tLoss: 0.002658\n",
      "Train Epoch: 33 [17920/118320 (15%)]\tLoss: 0.002666\n",
      "Train Epoch: 33 [20480/118320 (17%)]\tLoss: 0.002637\n",
      "Train Epoch: 33 [23040/118320 (19%)]\tLoss: 0.002600\n",
      "Train Epoch: 33 [25600/118320 (22%)]\tLoss: 0.002631\n",
      "Train Epoch: 33 [28160/118320 (24%)]\tLoss: 0.002627\n",
      "Train Epoch: 33 [30720/118320 (26%)]\tLoss: 0.002603\n",
      "Train Epoch: 33 [33280/118320 (28%)]\tLoss: 0.002618\n",
      "Train Epoch: 33 [35840/118320 (30%)]\tLoss: 0.002655\n",
      "Train Epoch: 33 [38400/118320 (32%)]\tLoss: 0.002672\n",
      "Train Epoch: 33 [40960/118320 (35%)]\tLoss: 0.002676\n",
      "Train Epoch: 33 [43520/118320 (37%)]\tLoss: 0.002624\n",
      "Train Epoch: 33 [46080/118320 (39%)]\tLoss: 0.002621\n",
      "Train Epoch: 33 [48640/118320 (41%)]\tLoss: 0.002634\n",
      "Train Epoch: 33 [51200/118320 (43%)]\tLoss: 0.002667\n",
      "Train Epoch: 33 [53760/118320 (45%)]\tLoss: 0.002670\n",
      "Train Epoch: 33 [56320/118320 (48%)]\tLoss: 0.002678\n",
      "Train Epoch: 33 [58880/118320 (50%)]\tLoss: 0.002628\n",
      "Train Epoch: 33 [61440/118320 (52%)]\tLoss: 0.002697\n",
      "Train Epoch: 33 [64000/118320 (54%)]\tLoss: 0.002674\n",
      "Train Epoch: 33 [66560/118320 (56%)]\tLoss: 0.002610\n",
      "Train Epoch: 33 [69120/118320 (58%)]\tLoss: 0.002568\n",
      "Train Epoch: 33 [71680/118320 (60%)]\tLoss: 0.002670\n",
      "Train Epoch: 33 [74240/118320 (63%)]\tLoss: 0.002667\n",
      "Train Epoch: 33 [76800/118320 (65%)]\tLoss: 0.002583\n",
      "Train Epoch: 33 [79360/118320 (67%)]\tLoss: 0.002604\n",
      "Train Epoch: 33 [81920/118320 (69%)]\tLoss: 0.002655\n",
      "Train Epoch: 33 [84480/118320 (71%)]\tLoss: 0.002638\n",
      "Train Epoch: 33 [87040/118320 (73%)]\tLoss: 0.002662\n",
      "Train Epoch: 33 [89600/118320 (76%)]\tLoss: 0.002677\n",
      "Train Epoch: 33 [92160/118320 (78%)]\tLoss: 0.002629\n",
      "Train Epoch: 33 [94720/118320 (80%)]\tLoss: 0.002644\n",
      "Train Epoch: 33 [97280/118320 (82%)]\tLoss: 0.002607\n",
      "Train Epoch: 33 [99840/118320 (84%)]\tLoss: 0.002629\n",
      "Train Epoch: 33 [102400/118320 (86%)]\tLoss: 0.002665\n",
      "Train Epoch: 33 [104960/118320 (89%)]\tLoss: 0.002651\n",
      "Train Epoch: 33 [107520/118320 (91%)]\tLoss: 0.002645\n",
      "Train Epoch: 33 [110080/118320 (93%)]\tLoss: 0.002656\n",
      "Train Epoch: 33 [112640/118320 (95%)]\tLoss: 0.002595\n",
      "Train Epoch: 33 [115200/118320 (97%)]\tLoss: 0.002602\n",
      "Train Epoch: 33 [117760/118320 (99%)]\tLoss: 0.002657\n",
      "\n",
      "Test set: Average loss: 0.0026\n",
      "\n",
      "Train Epoch: 34 [0/118320 (0%)]\tLoss: 0.002657\n",
      "Train Epoch: 34 [2560/118320 (2%)]\tLoss: 0.002694\n",
      "Train Epoch: 34 [5120/118320 (4%)]\tLoss: 0.002593\n",
      "Train Epoch: 34 [7680/118320 (6%)]\tLoss: 0.002597\n",
      "Train Epoch: 34 [10240/118320 (9%)]\tLoss: 0.002622\n",
      "Train Epoch: 34 [12800/118320 (11%)]\tLoss: 0.002687\n",
      "Train Epoch: 34 [15360/118320 (13%)]\tLoss: 0.002680\n",
      "Train Epoch: 34 [17920/118320 (15%)]\tLoss: 0.002601\n",
      "Train Epoch: 34 [20480/118320 (17%)]\tLoss: 0.002607\n",
      "Train Epoch: 34 [23040/118320 (19%)]\tLoss: 0.002604\n",
      "Train Epoch: 34 [25600/118320 (22%)]\tLoss: 0.002599\n",
      "Train Epoch: 34 [28160/118320 (24%)]\tLoss: 0.002674\n",
      "Train Epoch: 34 [30720/118320 (26%)]\tLoss: 0.002654\n",
      "Train Epoch: 34 [33280/118320 (28%)]\tLoss: 0.002675\n",
      "Train Epoch: 34 [35840/118320 (30%)]\tLoss: 0.002601\n",
      "Train Epoch: 34 [38400/118320 (32%)]\tLoss: 0.002655\n",
      "Train Epoch: 34 [40960/118320 (35%)]\tLoss: 0.002588\n",
      "Train Epoch: 34 [43520/118320 (37%)]\tLoss: 0.002659\n",
      "Train Epoch: 34 [46080/118320 (39%)]\tLoss: 0.002632\n",
      "Train Epoch: 34 [48640/118320 (41%)]\tLoss: 0.002603\n",
      "Train Epoch: 34 [51200/118320 (43%)]\tLoss: 0.002625\n",
      "Train Epoch: 34 [53760/118320 (45%)]\tLoss: 0.002607\n",
      "Train Epoch: 34 [56320/118320 (48%)]\tLoss: 0.002638\n",
      "Train Epoch: 34 [58880/118320 (50%)]\tLoss: 0.002636\n",
      "Train Epoch: 34 [61440/118320 (52%)]\tLoss: 0.002622\n",
      "Train Epoch: 34 [64000/118320 (54%)]\tLoss: 0.002600\n",
      "Train Epoch: 34 [66560/118320 (56%)]\tLoss: 0.002686\n",
      "Train Epoch: 34 [69120/118320 (58%)]\tLoss: 0.002615\n",
      "Train Epoch: 34 [71680/118320 (60%)]\tLoss: 0.002555\n",
      "Train Epoch: 34 [74240/118320 (63%)]\tLoss: 0.002603\n",
      "Train Epoch: 34 [76800/118320 (65%)]\tLoss: 0.002663\n",
      "Train Epoch: 34 [79360/118320 (67%)]\tLoss: 0.002687\n",
      "Train Epoch: 34 [81920/118320 (69%)]\tLoss: 0.002622\n",
      "Train Epoch: 34 [84480/118320 (71%)]\tLoss: 0.002637\n",
      "Train Epoch: 34 [87040/118320 (73%)]\tLoss: 0.002632\n",
      "Train Epoch: 34 [89600/118320 (76%)]\tLoss: 0.002662\n",
      "Train Epoch: 34 [92160/118320 (78%)]\tLoss: 0.002636\n",
      "Train Epoch: 34 [94720/118320 (80%)]\tLoss: 0.002599\n",
      "Train Epoch: 34 [97280/118320 (82%)]\tLoss: 0.002620\n",
      "Train Epoch: 34 [99840/118320 (84%)]\tLoss: 0.002662\n",
      "Train Epoch: 34 [102400/118320 (86%)]\tLoss: 0.002642\n",
      "Train Epoch: 34 [104960/118320 (89%)]\tLoss: 0.002613\n",
      "Train Epoch: 34 [107520/118320 (91%)]\tLoss: 0.002611\n",
      "Train Epoch: 34 [110080/118320 (93%)]\tLoss: 0.002635\n",
      "Train Epoch: 34 [112640/118320 (95%)]\tLoss: 0.002656\n",
      "Train Epoch: 34 [115200/118320 (97%)]\tLoss: 0.002616\n",
      "Train Epoch: 34 [117760/118320 (99%)]\tLoss: 0.002664\n",
      "\n",
      "Test set: Average loss: 0.0026\n",
      "\n",
      "Train Epoch: 35 [0/118320 (0%)]\tLoss: 0.002593\n",
      "Train Epoch: 35 [2560/118320 (2%)]\tLoss: 0.002642\n",
      "Train Epoch: 35 [5120/118320 (4%)]\tLoss: 0.002631\n",
      "Train Epoch: 35 [7680/118320 (6%)]\tLoss: 0.002639\n",
      "Train Epoch: 35 [10240/118320 (9%)]\tLoss: 0.002661\n",
      "Train Epoch: 35 [12800/118320 (11%)]\tLoss: 0.002629\n",
      "Train Epoch: 35 [15360/118320 (13%)]\tLoss: 0.002684\n",
      "Train Epoch: 35 [17920/118320 (15%)]\tLoss: 0.002625\n",
      "Train Epoch: 35 [20480/118320 (17%)]\tLoss: 0.002634\n",
      "Train Epoch: 35 [23040/118320 (19%)]\tLoss: 0.002640\n",
      "Train Epoch: 35 [25600/118320 (22%)]\tLoss: 0.002648\n",
      "Train Epoch: 35 [28160/118320 (24%)]\tLoss: 0.002621\n",
      "Train Epoch: 35 [30720/118320 (26%)]\tLoss: 0.002577\n",
      "Train Epoch: 35 [33280/118320 (28%)]\tLoss: 0.002681\n",
      "Train Epoch: 35 [35840/118320 (30%)]\tLoss: 0.002619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 35 [38400/118320 (32%)]\tLoss: 0.002602\n",
      "Train Epoch: 35 [40960/118320 (35%)]\tLoss: 0.002625\n",
      "Train Epoch: 35 [43520/118320 (37%)]\tLoss: 0.002630\n",
      "Train Epoch: 35 [46080/118320 (39%)]\tLoss: 0.002600\n",
      "Train Epoch: 35 [48640/118320 (41%)]\tLoss: 0.002622\n",
      "Train Epoch: 35 [51200/118320 (43%)]\tLoss: 0.002617\n",
      "Train Epoch: 35 [53760/118320 (45%)]\tLoss: 0.002654\n",
      "Train Epoch: 35 [56320/118320 (48%)]\tLoss: 0.002671\n",
      "Train Epoch: 35 [58880/118320 (50%)]\tLoss: 0.002639\n",
      "Train Epoch: 35 [61440/118320 (52%)]\tLoss: 0.002571\n",
      "Train Epoch: 35 [64000/118320 (54%)]\tLoss: 0.002607\n",
      "Train Epoch: 35 [66560/118320 (56%)]\tLoss: 0.002586\n",
      "Train Epoch: 35 [69120/118320 (58%)]\tLoss: 0.002653\n",
      "Train Epoch: 35 [71680/118320 (60%)]\tLoss: 0.002614\n",
      "Train Epoch: 35 [74240/118320 (63%)]\tLoss: 0.002624\n",
      "Train Epoch: 35 [76800/118320 (65%)]\tLoss: 0.002581\n",
      "Train Epoch: 35 [79360/118320 (67%)]\tLoss: 0.002640\n",
      "Train Epoch: 35 [81920/118320 (69%)]\tLoss: 0.002588\n",
      "Train Epoch: 35 [84480/118320 (71%)]\tLoss: 0.002667\n",
      "Train Epoch: 35 [87040/118320 (73%)]\tLoss: 0.002668\n",
      "Train Epoch: 35 [89600/118320 (76%)]\tLoss: 0.002602\n",
      "Train Epoch: 35 [92160/118320 (78%)]\tLoss: 0.002648\n",
      "Train Epoch: 35 [94720/118320 (80%)]\tLoss: 0.002619\n",
      "Train Epoch: 35 [97280/118320 (82%)]\tLoss: 0.002573\n",
      "Train Epoch: 35 [99840/118320 (84%)]\tLoss: 0.002608\n",
      "Train Epoch: 35 [102400/118320 (86%)]\tLoss: 0.002589\n",
      "Train Epoch: 35 [104960/118320 (89%)]\tLoss: 0.002705\n",
      "Train Epoch: 35 [107520/118320 (91%)]\tLoss: 0.002654\n",
      "Train Epoch: 35 [110080/118320 (93%)]\tLoss: 0.002585\n",
      "Train Epoch: 35 [112640/118320 (95%)]\tLoss: 0.002650\n",
      "Train Epoch: 35 [115200/118320 (97%)]\tLoss: 0.002637\n",
      "Train Epoch: 35 [117760/118320 (99%)]\tLoss: 0.002677\n",
      "\n",
      "Test set: Average loss: 0.0026\n",
      "\n",
      "Train Epoch: 36 [0/118320 (0%)]\tLoss: 0.002677\n",
      "Train Epoch: 36 [2560/118320 (2%)]\tLoss: 0.002678\n",
      "Train Epoch: 36 [5120/118320 (4%)]\tLoss: 0.002597\n",
      "Train Epoch: 36 [7680/118320 (6%)]\tLoss: 0.002677\n",
      "Train Epoch: 36 [10240/118320 (9%)]\tLoss: 0.002640\n",
      "Train Epoch: 36 [12800/118320 (11%)]\tLoss: 0.002594\n",
      "Train Epoch: 36 [15360/118320 (13%)]\tLoss: 0.002631\n",
      "Train Epoch: 36 [17920/118320 (15%)]\tLoss: 0.002653\n",
      "Train Epoch: 36 [20480/118320 (17%)]\tLoss: 0.002655\n",
      "Train Epoch: 36 [23040/118320 (19%)]\tLoss: 0.002594\n",
      "Train Epoch: 36 [25600/118320 (22%)]\tLoss: 0.002654\n",
      "Train Epoch: 36 [28160/118320 (24%)]\tLoss: 0.002633\n",
      "Train Epoch: 36 [30720/118320 (26%)]\tLoss: 0.002667\n",
      "Train Epoch: 36 [33280/118320 (28%)]\tLoss: 0.002603\n",
      "Train Epoch: 36 [35840/118320 (30%)]\tLoss: 0.002629\n",
      "Train Epoch: 36 [38400/118320 (32%)]\tLoss: 0.002599\n",
      "Train Epoch: 36 [40960/118320 (35%)]\tLoss: 0.002617\n",
      "Train Epoch: 36 [43520/118320 (37%)]\tLoss: 0.002674\n",
      "Train Epoch: 36 [46080/118320 (39%)]\tLoss: 0.002611\n",
      "Train Epoch: 36 [48640/118320 (41%)]\tLoss: 0.002588\n",
      "Train Epoch: 36 [51200/118320 (43%)]\tLoss: 0.002548\n",
      "Train Epoch: 36 [53760/118320 (45%)]\tLoss: 0.002611\n",
      "Train Epoch: 36 [56320/118320 (48%)]\tLoss: 0.002619\n",
      "Train Epoch: 36 [58880/118320 (50%)]\tLoss: 0.002629\n",
      "Train Epoch: 36 [61440/118320 (52%)]\tLoss: 0.002619\n",
      "Train Epoch: 36 [64000/118320 (54%)]\tLoss: 0.002569\n",
      "Train Epoch: 36 [66560/118320 (56%)]\tLoss: 0.002663\n",
      "Train Epoch: 36 [69120/118320 (58%)]\tLoss: 0.002617\n",
      "Train Epoch: 36 [71680/118320 (60%)]\tLoss: 0.002595\n",
      "Train Epoch: 36 [74240/118320 (63%)]\tLoss: 0.002591\n",
      "Train Epoch: 36 [76800/118320 (65%)]\tLoss: 0.002577\n",
      "Train Epoch: 36 [79360/118320 (67%)]\tLoss: 0.002634\n",
      "Train Epoch: 36 [81920/118320 (69%)]\tLoss: 0.002621\n",
      "Train Epoch: 36 [84480/118320 (71%)]\tLoss: 0.002651\n",
      "Train Epoch: 36 [87040/118320 (73%)]\tLoss: 0.002654\n",
      "Train Epoch: 36 [89600/118320 (76%)]\tLoss: 0.002582\n",
      "Train Epoch: 36 [92160/118320 (78%)]\tLoss: 0.002612\n",
      "Train Epoch: 36 [94720/118320 (80%)]\tLoss: 0.002686\n",
      "Train Epoch: 36 [97280/118320 (82%)]\tLoss: 0.002606\n",
      "Train Epoch: 36 [99840/118320 (84%)]\tLoss: 0.002641\n",
      "Train Epoch: 36 [102400/118320 (86%)]\tLoss: 0.002649\n",
      "Train Epoch: 36 [104960/118320 (89%)]\tLoss: 0.002655\n",
      "Train Epoch: 36 [107520/118320 (91%)]\tLoss: 0.002621\n",
      "Train Epoch: 36 [110080/118320 (93%)]\tLoss: 0.002559\n",
      "Train Epoch: 36 [112640/118320 (95%)]\tLoss: 0.002575\n",
      "Train Epoch: 36 [115200/118320 (97%)]\tLoss: 0.002607\n",
      "Train Epoch: 36 [117760/118320 (99%)]\tLoss: 0.002619\n",
      "\n",
      "Test set: Average loss: 0.0026\n",
      "\n",
      "Train Epoch: 37 [0/118320 (0%)]\tLoss: 0.002626\n",
      "Train Epoch: 37 [2560/118320 (2%)]\tLoss: 0.002623\n",
      "Train Epoch: 37 [5120/118320 (4%)]\tLoss: 0.002687\n",
      "Train Epoch: 37 [7680/118320 (6%)]\tLoss: 0.002586\n",
      "Train Epoch: 37 [10240/118320 (9%)]\tLoss: 0.002616\n",
      "Train Epoch: 37 [12800/118320 (11%)]\tLoss: 0.002628\n",
      "Train Epoch: 37 [15360/118320 (13%)]\tLoss: 0.002615\n",
      "Train Epoch: 37 [17920/118320 (15%)]\tLoss: 0.002640\n",
      "Train Epoch: 37 [20480/118320 (17%)]\tLoss: 0.002634\n",
      "Train Epoch: 37 [23040/118320 (19%)]\tLoss: 0.002665\n",
      "Train Epoch: 37 [25600/118320 (22%)]\tLoss: 0.002546\n",
      "Train Epoch: 37 [28160/118320 (24%)]\tLoss: 0.002618\n",
      "Train Epoch: 37 [30720/118320 (26%)]\tLoss: 0.002597\n",
      "Train Epoch: 37 [33280/118320 (28%)]\tLoss: 0.002582\n",
      "Train Epoch: 37 [35840/118320 (30%)]\tLoss: 0.002631\n",
      "Train Epoch: 37 [38400/118320 (32%)]\tLoss: 0.002657\n",
      "Train Epoch: 37 [40960/118320 (35%)]\tLoss: 0.002624\n",
      "Train Epoch: 37 [43520/118320 (37%)]\tLoss: 0.002606\n",
      "Train Epoch: 37 [46080/118320 (39%)]\tLoss: 0.002618\n",
      "Train Epoch: 37 [48640/118320 (41%)]\tLoss: 0.002609\n",
      "Train Epoch: 37 [51200/118320 (43%)]\tLoss: 0.002653\n",
      "Train Epoch: 37 [53760/118320 (45%)]\tLoss: 0.002565\n",
      "Train Epoch: 37 [56320/118320 (48%)]\tLoss: 0.002659\n",
      "Train Epoch: 37 [58880/118320 (50%)]\tLoss: 0.002592\n",
      "Train Epoch: 37 [61440/118320 (52%)]\tLoss: 0.002591\n",
      "Train Epoch: 37 [64000/118320 (54%)]\tLoss: 0.002674\n",
      "Train Epoch: 37 [66560/118320 (56%)]\tLoss: 0.002616\n",
      "Train Epoch: 37 [69120/118320 (58%)]\tLoss: 0.002622\n",
      "Train Epoch: 37 [71680/118320 (60%)]\tLoss: 0.002693\n",
      "Train Epoch: 37 [74240/118320 (63%)]\tLoss: 0.002613\n",
      "Train Epoch: 37 [76800/118320 (65%)]\tLoss: 0.002589\n",
      "Train Epoch: 37 [79360/118320 (67%)]\tLoss: 0.002597\n",
      "Train Epoch: 37 [81920/118320 (69%)]\tLoss: 0.002626\n",
      "Train Epoch: 37 [84480/118320 (71%)]\tLoss: 0.002557\n",
      "Train Epoch: 37 [87040/118320 (73%)]\tLoss: 0.002696\n",
      "Train Epoch: 37 [89600/118320 (76%)]\tLoss: 0.002612\n",
      "Train Epoch: 37 [92160/118320 (78%)]\tLoss: 0.002641\n",
      "Train Epoch: 37 [94720/118320 (80%)]\tLoss: 0.002655\n",
      "Train Epoch: 37 [97280/118320 (82%)]\tLoss: 0.002646\n",
      "Train Epoch: 37 [99840/118320 (84%)]\tLoss: 0.002589\n",
      "Train Epoch: 37 [102400/118320 (86%)]\tLoss: 0.002653\n",
      "Train Epoch: 37 [104960/118320 (89%)]\tLoss: 0.002632\n",
      "Train Epoch: 37 [107520/118320 (91%)]\tLoss: 0.002610\n",
      "Train Epoch: 37 [110080/118320 (93%)]\tLoss: 0.002591\n",
      "Train Epoch: 37 [112640/118320 (95%)]\tLoss: 0.002626\n",
      "Train Epoch: 37 [115200/118320 (97%)]\tLoss: 0.002629\n",
      "Train Epoch: 37 [117760/118320 (99%)]\tLoss: 0.002575\n",
      "\n",
      "Test set: Average loss: 0.0026\n",
      "\n",
      "Train Epoch: 38 [0/118320 (0%)]\tLoss: 0.002580\n",
      "Train Epoch: 38 [2560/118320 (2%)]\tLoss: 0.002602\n",
      "Train Epoch: 38 [5120/118320 (4%)]\tLoss: 0.002642\n",
      "Train Epoch: 38 [7680/118320 (6%)]\tLoss: 0.002663\n",
      "Train Epoch: 38 [10240/118320 (9%)]\tLoss: 0.002571\n",
      "Train Epoch: 38 [12800/118320 (11%)]\tLoss: 0.002656\n",
      "Train Epoch: 38 [15360/118320 (13%)]\tLoss: 0.002597\n",
      "Train Epoch: 38 [17920/118320 (15%)]\tLoss: 0.002696\n",
      "Train Epoch: 38 [20480/118320 (17%)]\tLoss: 0.002569\n",
      "Train Epoch: 38 [23040/118320 (19%)]\tLoss: 0.002566\n",
      "Train Epoch: 38 [25600/118320 (22%)]\tLoss: 0.002614\n",
      "Train Epoch: 38 [28160/118320 (24%)]\tLoss: 0.002665\n",
      "Train Epoch: 38 [30720/118320 (26%)]\tLoss: 0.002641\n",
      "Train Epoch: 38 [33280/118320 (28%)]\tLoss: 0.002618\n",
      "Train Epoch: 38 [35840/118320 (30%)]\tLoss: 0.002567\n",
      "Train Epoch: 38 [38400/118320 (32%)]\tLoss: 0.002613\n",
      "Train Epoch: 38 [40960/118320 (35%)]\tLoss: 0.002611\n",
      "Train Epoch: 38 [43520/118320 (37%)]\tLoss: 0.002525\n",
      "Train Epoch: 38 [46080/118320 (39%)]\tLoss: 0.002586\n",
      "Train Epoch: 38 [48640/118320 (41%)]\tLoss: 0.002610\n",
      "Train Epoch: 38 [51200/118320 (43%)]\tLoss: 0.002630\n",
      "Train Epoch: 38 [53760/118320 (45%)]\tLoss: 0.002622\n",
      "Train Epoch: 38 [56320/118320 (48%)]\tLoss: 0.002554\n",
      "Train Epoch: 38 [58880/118320 (50%)]\tLoss: 0.002607\n",
      "Train Epoch: 38 [61440/118320 (52%)]\tLoss: 0.002605\n",
      "Train Epoch: 38 [64000/118320 (54%)]\tLoss: 0.002592\n",
      "Train Epoch: 38 [66560/118320 (56%)]\tLoss: 0.002611\n",
      "Train Epoch: 38 [69120/118320 (58%)]\tLoss: 0.002606\n",
      "Train Epoch: 38 [71680/118320 (60%)]\tLoss: 0.002538\n",
      "Train Epoch: 38 [74240/118320 (63%)]\tLoss: 0.002634\n",
      "Train Epoch: 38 [76800/118320 (65%)]\tLoss: 0.002603\n",
      "Train Epoch: 38 [79360/118320 (67%)]\tLoss: 0.002586\n",
      "Train Epoch: 38 [81920/118320 (69%)]\tLoss: 0.002575\n",
      "Train Epoch: 38 [84480/118320 (71%)]\tLoss: 0.002555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 38 [87040/118320 (73%)]\tLoss: 0.002632\n",
      "Train Epoch: 38 [89600/118320 (76%)]\tLoss: 0.002563\n",
      "Train Epoch: 38 [92160/118320 (78%)]\tLoss: 0.002566\n",
      "Train Epoch: 38 [94720/118320 (80%)]\tLoss: 0.002576\n",
      "Train Epoch: 38 [97280/118320 (82%)]\tLoss: 0.002641\n",
      "Train Epoch: 38 [99840/118320 (84%)]\tLoss: 0.002613\n",
      "Train Epoch: 38 [102400/118320 (86%)]\tLoss: 0.002572\n",
      "Train Epoch: 38 [104960/118320 (89%)]\tLoss: 0.002588\n",
      "Train Epoch: 38 [107520/118320 (91%)]\tLoss: 0.002611\n",
      "Train Epoch: 38 [110080/118320 (93%)]\tLoss: 0.002555\n",
      "Train Epoch: 38 [112640/118320 (95%)]\tLoss: 0.002599\n",
      "Train Epoch: 38 [115200/118320 (97%)]\tLoss: 0.002593\n",
      "Train Epoch: 38 [117760/118320 (99%)]\tLoss: 0.002599\n",
      "\n",
      "Test set: Average loss: 0.0026\n",
      "\n",
      "Train Epoch: 39 [0/118320 (0%)]\tLoss: 0.002541\n",
      "Train Epoch: 39 [2560/118320 (2%)]\tLoss: 0.002575\n",
      "Train Epoch: 39 [5120/118320 (4%)]\tLoss: 0.002580\n",
      "Train Epoch: 39 [7680/118320 (6%)]\tLoss: 0.002567\n",
      "Train Epoch: 39 [10240/118320 (9%)]\tLoss: 0.002534\n",
      "Train Epoch: 39 [12800/118320 (11%)]\tLoss: 0.002603\n",
      "Train Epoch: 39 [15360/118320 (13%)]\tLoss: 0.002582\n",
      "Train Epoch: 39 [17920/118320 (15%)]\tLoss: 0.002525\n",
      "Train Epoch: 39 [20480/118320 (17%)]\tLoss: 0.002601\n",
      "Train Epoch: 39 [23040/118320 (19%)]\tLoss: 0.002565\n",
      "Train Epoch: 39 [25600/118320 (22%)]\tLoss: 0.002574\n",
      "Train Epoch: 39 [28160/118320 (24%)]\tLoss: 0.002555\n",
      "Train Epoch: 39 [30720/118320 (26%)]\tLoss: 0.002580\n",
      "Train Epoch: 39 [33280/118320 (28%)]\tLoss: 0.002543\n",
      "Train Epoch: 39 [35840/118320 (30%)]\tLoss: 0.002547\n",
      "Train Epoch: 39 [38400/118320 (32%)]\tLoss: 0.002558\n",
      "Train Epoch: 39 [40960/118320 (35%)]\tLoss: 0.002574\n",
      "Train Epoch: 39 [43520/118320 (37%)]\tLoss: 0.002495\n",
      "Train Epoch: 39 [46080/118320 (39%)]\tLoss: 0.002520\n",
      "Train Epoch: 39 [48640/118320 (41%)]\tLoss: 0.002588\n",
      "Train Epoch: 39 [51200/118320 (43%)]\tLoss: 0.002596\n",
      "Train Epoch: 39 [53760/118320 (45%)]\tLoss: 0.002597\n",
      "Train Epoch: 39 [56320/118320 (48%)]\tLoss: 0.002598\n",
      "Train Epoch: 39 [58880/118320 (50%)]\tLoss: 0.002483\n",
      "Train Epoch: 39 [61440/118320 (52%)]\tLoss: 0.002575\n",
      "Train Epoch: 39 [64000/118320 (54%)]\tLoss: 0.002546\n",
      "Train Epoch: 39 [66560/118320 (56%)]\tLoss: 0.002503\n",
      "Train Epoch: 39 [69120/118320 (58%)]\tLoss: 0.002584\n",
      "Train Epoch: 39 [71680/118320 (60%)]\tLoss: 0.002509\n",
      "Train Epoch: 39 [74240/118320 (63%)]\tLoss: 0.002518\n",
      "Train Epoch: 39 [76800/118320 (65%)]\tLoss: 0.002514\n",
      "Train Epoch: 39 [79360/118320 (67%)]\tLoss: 0.002492\n",
      "Train Epoch: 39 [81920/118320 (69%)]\tLoss: 0.002553\n",
      "Train Epoch: 39 [84480/118320 (71%)]\tLoss: 0.002542\n",
      "Train Epoch: 39 [87040/118320 (73%)]\tLoss: 0.002509\n",
      "Train Epoch: 39 [89600/118320 (76%)]\tLoss: 0.002502\n",
      "Train Epoch: 39 [92160/118320 (78%)]\tLoss: 0.002504\n",
      "Train Epoch: 39 [94720/118320 (80%)]\tLoss: 0.002488\n",
      "Train Epoch: 39 [97280/118320 (82%)]\tLoss: 0.002479\n",
      "Train Epoch: 39 [99840/118320 (84%)]\tLoss: 0.002503\n",
      "Train Epoch: 39 [102400/118320 (86%)]\tLoss: 0.002526\n",
      "Train Epoch: 39 [104960/118320 (89%)]\tLoss: 0.002504\n",
      "Train Epoch: 39 [107520/118320 (91%)]\tLoss: 0.002483\n",
      "Train Epoch: 39 [110080/118320 (93%)]\tLoss: 0.002436\n",
      "Train Epoch: 39 [112640/118320 (95%)]\tLoss: 0.002482\n",
      "Train Epoch: 39 [115200/118320 (97%)]\tLoss: 0.002446\n",
      "Train Epoch: 39 [117760/118320 (99%)]\tLoss: 0.002507\n",
      "\n",
      "Test set: Average loss: 0.0025\n",
      "\n",
      "Train Epoch: 40 [0/118320 (0%)]\tLoss: 0.002503\n",
      "Train Epoch: 40 [2560/118320 (2%)]\tLoss: 0.002494\n",
      "Train Epoch: 40 [5120/118320 (4%)]\tLoss: 0.002460\n",
      "Train Epoch: 40 [7680/118320 (6%)]\tLoss: 0.002489\n",
      "Train Epoch: 40 [10240/118320 (9%)]\tLoss: 0.002395\n",
      "Train Epoch: 40 [12800/118320 (11%)]\tLoss: 0.002466\n",
      "Train Epoch: 40 [15360/118320 (13%)]\tLoss: 0.002448\n",
      "Train Epoch: 40 [17920/118320 (15%)]\tLoss: 0.002423\n",
      "Train Epoch: 40 [20480/118320 (17%)]\tLoss: 0.002413\n",
      "Train Epoch: 40 [23040/118320 (19%)]\tLoss: 0.002430\n",
      "Train Epoch: 40 [25600/118320 (22%)]\tLoss: 0.002438\n",
      "Train Epoch: 40 [28160/118320 (24%)]\tLoss: 0.002421\n",
      "Train Epoch: 40 [30720/118320 (26%)]\tLoss: 0.002425\n",
      "Train Epoch: 40 [33280/118320 (28%)]\tLoss: 0.002411\n",
      "Train Epoch: 40 [35840/118320 (30%)]\tLoss: 0.002411\n",
      "Train Epoch: 40 [38400/118320 (32%)]\tLoss: 0.002411\n",
      "Train Epoch: 40 [40960/118320 (35%)]\tLoss: 0.002397\n",
      "Train Epoch: 40 [43520/118320 (37%)]\tLoss: 0.002352\n",
      "Train Epoch: 40 [46080/118320 (39%)]\tLoss: 0.002369\n",
      "Train Epoch: 40 [48640/118320 (41%)]\tLoss: 0.002361\n",
      "Train Epoch: 40 [51200/118320 (43%)]\tLoss: 0.002391\n",
      "Train Epoch: 40 [53760/118320 (45%)]\tLoss: 0.002374\n",
      "Train Epoch: 40 [56320/118320 (48%)]\tLoss: 0.002337\n",
      "Train Epoch: 40 [58880/118320 (50%)]\tLoss: 0.002338\n",
      "Train Epoch: 40 [61440/118320 (52%)]\tLoss: 0.002363\n",
      "Train Epoch: 40 [64000/118320 (54%)]\tLoss: 0.002345\n",
      "Train Epoch: 40 [66560/118320 (56%)]\tLoss: 0.002338\n",
      "Train Epoch: 40 [69120/118320 (58%)]\tLoss: 0.002269\n",
      "Train Epoch: 40 [71680/118320 (60%)]\tLoss: 0.002354\n",
      "Train Epoch: 40 [74240/118320 (63%)]\tLoss: 0.002339\n",
      "Train Epoch: 40 [76800/118320 (65%)]\tLoss: 0.002342\n",
      "Train Epoch: 40 [79360/118320 (67%)]\tLoss: 0.002331\n",
      "Train Epoch: 40 [81920/118320 (69%)]\tLoss: 0.002268\n",
      "Train Epoch: 40 [84480/118320 (71%)]\tLoss: 0.002300\n",
      "Train Epoch: 40 [87040/118320 (73%)]\tLoss: 0.002267\n",
      "Train Epoch: 40 [89600/118320 (76%)]\tLoss: 0.002259\n",
      "Train Epoch: 40 [92160/118320 (78%)]\tLoss: 0.002292\n",
      "Train Epoch: 40 [94720/118320 (80%)]\tLoss: 0.002295\n",
      "Train Epoch: 40 [97280/118320 (82%)]\tLoss: 0.002244\n",
      "Train Epoch: 40 [99840/118320 (84%)]\tLoss: 0.002262\n",
      "Train Epoch: 40 [102400/118320 (86%)]\tLoss: 0.002231\n",
      "Train Epoch: 40 [104960/118320 (89%)]\tLoss: 0.002223\n",
      "Train Epoch: 40 [107520/118320 (91%)]\tLoss: 0.002228\n",
      "Train Epoch: 40 [110080/118320 (93%)]\tLoss: 0.002248\n",
      "Train Epoch: 40 [112640/118320 (95%)]\tLoss: 0.002280\n",
      "Train Epoch: 40 [115200/118320 (97%)]\tLoss: 0.002271\n",
      "Train Epoch: 40 [117760/118320 (99%)]\tLoss: 0.002243\n",
      "\n",
      "Test set: Average loss: 0.0022\n",
      "\n",
      "Train Epoch: 41 [0/118320 (0%)]\tLoss: 0.002241\n",
      "Train Epoch: 41 [2560/118320 (2%)]\tLoss: 0.002206\n",
      "Train Epoch: 41 [5120/118320 (4%)]\tLoss: 0.002222\n",
      "Train Epoch: 41 [7680/118320 (6%)]\tLoss: 0.002192\n",
      "Train Epoch: 41 [10240/118320 (9%)]\tLoss: 0.002221\n",
      "Train Epoch: 41 [12800/118320 (11%)]\tLoss: 0.002231\n",
      "Train Epoch: 41 [15360/118320 (13%)]\tLoss: 0.002195\n",
      "Train Epoch: 41 [17920/118320 (15%)]\tLoss: 0.002165\n",
      "Train Epoch: 41 [20480/118320 (17%)]\tLoss: 0.002212\n",
      "Train Epoch: 41 [23040/118320 (19%)]\tLoss: 0.002253\n",
      "Train Epoch: 41 [25600/118320 (22%)]\tLoss: 0.002214\n",
      "Train Epoch: 41 [28160/118320 (24%)]\tLoss: 0.002207\n",
      "Train Epoch: 41 [30720/118320 (26%)]\tLoss: 0.002154\n",
      "Train Epoch: 41 [33280/118320 (28%)]\tLoss: 0.002237\n",
      "Train Epoch: 41 [35840/118320 (30%)]\tLoss: 0.002188\n",
      "Train Epoch: 41 [38400/118320 (32%)]\tLoss: 0.002189\n",
      "Train Epoch: 41 [40960/118320 (35%)]\tLoss: 0.002152\n",
      "Train Epoch: 41 [43520/118320 (37%)]\tLoss: 0.002175\n",
      "Train Epoch: 41 [46080/118320 (39%)]\tLoss: 0.002150\n",
      "Train Epoch: 41 [48640/118320 (41%)]\tLoss: 0.002166\n",
      "Train Epoch: 41 [51200/118320 (43%)]\tLoss: 0.002139\n",
      "Train Epoch: 41 [53760/118320 (45%)]\tLoss: 0.002150\n",
      "Train Epoch: 41 [56320/118320 (48%)]\tLoss: 0.002117\n",
      "Train Epoch: 41 [58880/118320 (50%)]\tLoss: 0.002156\n",
      "Train Epoch: 41 [61440/118320 (52%)]\tLoss: 0.002146\n",
      "Train Epoch: 41 [64000/118320 (54%)]\tLoss: 0.002179\n",
      "Train Epoch: 41 [66560/118320 (56%)]\tLoss: 0.002149\n",
      "Train Epoch: 41 [69120/118320 (58%)]\tLoss: 0.002167\n",
      "Train Epoch: 41 [71680/118320 (60%)]\tLoss: 0.002160\n",
      "Train Epoch: 41 [74240/118320 (63%)]\tLoss: 0.002157\n",
      "Train Epoch: 41 [76800/118320 (65%)]\tLoss: 0.002151\n",
      "Train Epoch: 41 [79360/118320 (67%)]\tLoss: 0.002108\n",
      "Train Epoch: 41 [81920/118320 (69%)]\tLoss: 0.002174\n",
      "Train Epoch: 41 [84480/118320 (71%)]\tLoss: 0.002154\n",
      "Train Epoch: 41 [87040/118320 (73%)]\tLoss: 0.002157\n",
      "Train Epoch: 41 [89600/118320 (76%)]\tLoss: 0.002126\n",
      "Train Epoch: 41 [92160/118320 (78%)]\tLoss: 0.002122\n",
      "Train Epoch: 41 [94720/118320 (80%)]\tLoss: 0.002180\n",
      "Train Epoch: 41 [97280/118320 (82%)]\tLoss: 0.002122\n",
      "Train Epoch: 41 [99840/118320 (84%)]\tLoss: 0.002130\n",
      "Train Epoch: 41 [102400/118320 (86%)]\tLoss: 0.002069\n",
      "Train Epoch: 41 [104960/118320 (89%)]\tLoss: 0.002093\n",
      "Train Epoch: 41 [107520/118320 (91%)]\tLoss: 0.002084\n",
      "Train Epoch: 41 [110080/118320 (93%)]\tLoss: 0.002149\n",
      "Train Epoch: 41 [112640/118320 (95%)]\tLoss: 0.002075\n",
      "Train Epoch: 41 [115200/118320 (97%)]\tLoss: 0.002110\n",
      "Train Epoch: 41 [117760/118320 (99%)]\tLoss: 0.002095\n",
      "\n",
      "Test set: Average loss: 0.0021\n",
      "\n",
      "Train Epoch: 42 [0/118320 (0%)]\tLoss: 0.002089\n",
      "Train Epoch: 42 [2560/118320 (2%)]\tLoss: 0.002131\n",
      "Train Epoch: 42 [5120/118320 (4%)]\tLoss: 0.002109\n",
      "Train Epoch: 42 [7680/118320 (6%)]\tLoss: 0.002063\n",
      "Train Epoch: 42 [10240/118320 (9%)]\tLoss: 0.002161\n",
      "Train Epoch: 42 [12800/118320 (11%)]\tLoss: 0.002122\n",
      "Train Epoch: 42 [15360/118320 (13%)]\tLoss: 0.002116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 42 [17920/118320 (15%)]\tLoss: 0.002140\n",
      "Train Epoch: 42 [20480/118320 (17%)]\tLoss: 0.002106\n",
      "Train Epoch: 42 [23040/118320 (19%)]\tLoss: 0.002074\n",
      "Train Epoch: 42 [25600/118320 (22%)]\tLoss: 0.002098\n",
      "Train Epoch: 42 [28160/118320 (24%)]\tLoss: 0.002057\n",
      "Train Epoch: 42 [30720/118320 (26%)]\tLoss: 0.002095\n",
      "Train Epoch: 42 [33280/118320 (28%)]\tLoss: 0.002096\n",
      "Train Epoch: 42 [35840/118320 (30%)]\tLoss: 0.002120\n",
      "Train Epoch: 42 [38400/118320 (32%)]\tLoss: 0.002098\n",
      "Train Epoch: 42 [40960/118320 (35%)]\tLoss: 0.002113\n",
      "Train Epoch: 42 [43520/118320 (37%)]\tLoss: 0.002071\n",
      "Train Epoch: 42 [46080/118320 (39%)]\tLoss: 0.002076\n",
      "Train Epoch: 42 [48640/118320 (41%)]\tLoss: 0.002072\n",
      "Train Epoch: 42 [51200/118320 (43%)]\tLoss: 0.002079\n",
      "Train Epoch: 42 [53760/118320 (45%)]\tLoss: 0.002114\n",
      "Train Epoch: 42 [56320/118320 (48%)]\tLoss: 0.002054\n",
      "Train Epoch: 42 [58880/118320 (50%)]\tLoss: 0.002085\n",
      "Train Epoch: 42 [61440/118320 (52%)]\tLoss: 0.002076\n",
      "Train Epoch: 42 [64000/118320 (54%)]\tLoss: 0.002113\n",
      "Train Epoch: 42 [66560/118320 (56%)]\tLoss: 0.002124\n",
      "Train Epoch: 42 [69120/118320 (58%)]\tLoss: 0.002068\n",
      "Train Epoch: 42 [71680/118320 (60%)]\tLoss: 0.002061\n",
      "Train Epoch: 42 [74240/118320 (63%)]\tLoss: 0.002102\n",
      "Train Epoch: 42 [76800/118320 (65%)]\tLoss: 0.002106\n",
      "Train Epoch: 42 [79360/118320 (67%)]\tLoss: 0.002072\n",
      "Train Epoch: 42 [81920/118320 (69%)]\tLoss: 0.002053\n",
      "Train Epoch: 42 [84480/118320 (71%)]\tLoss: 0.002148\n",
      "Train Epoch: 42 [87040/118320 (73%)]\tLoss: 0.002051\n",
      "Train Epoch: 42 [89600/118320 (76%)]\tLoss: 0.002091\n",
      "Train Epoch: 42 [92160/118320 (78%)]\tLoss: 0.002076\n",
      "Train Epoch: 42 [94720/118320 (80%)]\tLoss: 0.002090\n",
      "Train Epoch: 42 [97280/118320 (82%)]\tLoss: 0.002060\n",
      "Train Epoch: 42 [99840/118320 (84%)]\tLoss: 0.002102\n",
      "Train Epoch: 42 [102400/118320 (86%)]\tLoss: 0.002090\n",
      "Train Epoch: 42 [104960/118320 (89%)]\tLoss: 0.002067\n",
      "Train Epoch: 42 [107520/118320 (91%)]\tLoss: 0.002096\n",
      "Train Epoch: 42 [110080/118320 (93%)]\tLoss: 0.002084\n",
      "Train Epoch: 42 [112640/118320 (95%)]\tLoss: 0.002120\n",
      "Train Epoch: 42 [115200/118320 (97%)]\tLoss: 0.002042\n",
      "Train Epoch: 42 [117760/118320 (99%)]\tLoss: 0.002085\n",
      "\n",
      "Test set: Average loss: 0.0021\n",
      "\n",
      "Train Epoch: 43 [0/118320 (0%)]\tLoss: 0.002111\n",
      "Train Epoch: 43 [2560/118320 (2%)]\tLoss: 0.002073\n",
      "Train Epoch: 43 [5120/118320 (4%)]\tLoss: 0.002114\n",
      "Train Epoch: 43 [7680/118320 (6%)]\tLoss: 0.002071\n",
      "Train Epoch: 43 [10240/118320 (9%)]\tLoss: 0.002086\n",
      "Train Epoch: 43 [12800/118320 (11%)]\tLoss: 0.002089\n",
      "Train Epoch: 43 [15360/118320 (13%)]\tLoss: 0.002076\n",
      "Train Epoch: 43 [17920/118320 (15%)]\tLoss: 0.002100\n",
      "Train Epoch: 43 [20480/118320 (17%)]\tLoss: 0.002073\n",
      "Train Epoch: 43 [23040/118320 (19%)]\tLoss: 0.002090\n",
      "Train Epoch: 43 [25600/118320 (22%)]\tLoss: 0.002090\n",
      "Train Epoch: 43 [28160/118320 (24%)]\tLoss: 0.002081\n",
      "Train Epoch: 43 [30720/118320 (26%)]\tLoss: 0.002098\n",
      "Train Epoch: 43 [33280/118320 (28%)]\tLoss: 0.002037\n",
      "Train Epoch: 43 [35840/118320 (30%)]\tLoss: 0.002062\n",
      "Train Epoch: 43 [38400/118320 (32%)]\tLoss: 0.002065\n",
      "Train Epoch: 43 [40960/118320 (35%)]\tLoss: 0.002060\n",
      "Train Epoch: 43 [43520/118320 (37%)]\tLoss: 0.002069\n",
      "Train Epoch: 43 [46080/118320 (39%)]\tLoss: 0.002042\n",
      "Train Epoch: 43 [48640/118320 (41%)]\tLoss: 0.002072\n",
      "Train Epoch: 43 [51200/118320 (43%)]\tLoss: 0.002036\n",
      "Train Epoch: 43 [53760/118320 (45%)]\tLoss: 0.002136\n",
      "Train Epoch: 43 [56320/118320 (48%)]\tLoss: 0.002079\n",
      "Train Epoch: 43 [58880/118320 (50%)]\tLoss: 0.002096\n",
      "Train Epoch: 43 [61440/118320 (52%)]\tLoss: 0.002042\n",
      "Train Epoch: 43 [64000/118320 (54%)]\tLoss: 0.002086\n",
      "Train Epoch: 43 [66560/118320 (56%)]\tLoss: 0.002073\n",
      "Train Epoch: 43 [69120/118320 (58%)]\tLoss: 0.002021\n",
      "Train Epoch: 43 [71680/118320 (60%)]\tLoss: 0.002055\n",
      "Train Epoch: 43 [74240/118320 (63%)]\tLoss: 0.002041\n",
      "Train Epoch: 43 [76800/118320 (65%)]\tLoss: 0.002092\n",
      "Train Epoch: 43 [79360/118320 (67%)]\tLoss: 0.002060\n",
      "Train Epoch: 43 [81920/118320 (69%)]\tLoss: 0.002085\n",
      "Train Epoch: 43 [84480/118320 (71%)]\tLoss: 0.002026\n",
      "Train Epoch: 43 [87040/118320 (73%)]\tLoss: 0.002116\n",
      "Train Epoch: 43 [89600/118320 (76%)]\tLoss: 0.002075\n",
      "Train Epoch: 43 [92160/118320 (78%)]\tLoss: 0.002076\n",
      "Train Epoch: 43 [94720/118320 (80%)]\tLoss: 0.002042\n",
      "Train Epoch: 43 [97280/118320 (82%)]\tLoss: 0.002050\n",
      "Train Epoch: 43 [99840/118320 (84%)]\tLoss: 0.002037\n",
      "Train Epoch: 43 [102400/118320 (86%)]\tLoss: 0.002053\n",
      "Train Epoch: 43 [104960/118320 (89%)]\tLoss: 0.002048\n",
      "Train Epoch: 43 [107520/118320 (91%)]\tLoss: 0.002041\n",
      "Train Epoch: 43 [110080/118320 (93%)]\tLoss: 0.002061\n",
      "Train Epoch: 43 [112640/118320 (95%)]\tLoss: 0.002070\n",
      "Train Epoch: 43 [115200/118320 (97%)]\tLoss: 0.002079\n",
      "Train Epoch: 43 [117760/118320 (99%)]\tLoss: 0.002073\n",
      "\n",
      "Test set: Average loss: 0.0021\n",
      "\n",
      "Train Epoch: 44 [0/118320 (0%)]\tLoss: 0.002050\n",
      "Train Epoch: 44 [2560/118320 (2%)]\tLoss: 0.002048\n",
      "Train Epoch: 44 [5120/118320 (4%)]\tLoss: 0.002077\n",
      "Train Epoch: 44 [7680/118320 (6%)]\tLoss: 0.002082\n",
      "Train Epoch: 44 [10240/118320 (9%)]\tLoss: 0.002095\n",
      "Train Epoch: 44 [12800/118320 (11%)]\tLoss: 0.002057\n",
      "Train Epoch: 44 [15360/118320 (13%)]\tLoss: 0.002019\n",
      "Train Epoch: 44 [17920/118320 (15%)]\tLoss: 0.002033\n",
      "Train Epoch: 44 [20480/118320 (17%)]\tLoss: 0.002042\n",
      "Train Epoch: 44 [23040/118320 (19%)]\tLoss: 0.002022\n",
      "Train Epoch: 44 [25600/118320 (22%)]\tLoss: 0.002072\n",
      "Train Epoch: 44 [28160/118320 (24%)]\tLoss: 0.002051\n",
      "Train Epoch: 44 [30720/118320 (26%)]\tLoss: 0.002049\n",
      "Train Epoch: 44 [33280/118320 (28%)]\tLoss: 0.002065\n",
      "Train Epoch: 44 [35840/118320 (30%)]\tLoss: 0.002037\n",
      "Train Epoch: 44 [38400/118320 (32%)]\tLoss: 0.002073\n",
      "Train Epoch: 44 [40960/118320 (35%)]\tLoss: 0.002043\n",
      "Train Epoch: 44 [43520/118320 (37%)]\tLoss: 0.002084\n",
      "Train Epoch: 44 [46080/118320 (39%)]\tLoss: 0.002060\n",
      "Train Epoch: 44 [48640/118320 (41%)]\tLoss: 0.002051\n",
      "Train Epoch: 44 [51200/118320 (43%)]\tLoss: 0.002092\n",
      "Train Epoch: 44 [53760/118320 (45%)]\tLoss: 0.002046\n",
      "Train Epoch: 44 [56320/118320 (48%)]\tLoss: 0.002010\n",
      "Train Epoch: 44 [58880/118320 (50%)]\tLoss: 0.002067\n",
      "Train Epoch: 44 [61440/118320 (52%)]\tLoss: 0.002101\n",
      "Train Epoch: 44 [64000/118320 (54%)]\tLoss: 0.002075\n",
      "Train Epoch: 44 [66560/118320 (56%)]\tLoss: 0.002070\n",
      "Train Epoch: 44 [69120/118320 (58%)]\tLoss: 0.002071\n",
      "Train Epoch: 44 [71680/118320 (60%)]\tLoss: 0.002109\n",
      "Train Epoch: 44 [74240/118320 (63%)]\tLoss: 0.002042\n",
      "Train Epoch: 44 [76800/118320 (65%)]\tLoss: 0.002084\n",
      "Train Epoch: 44 [79360/118320 (67%)]\tLoss: 0.002025\n",
      "Train Epoch: 44 [81920/118320 (69%)]\tLoss: 0.002011\n",
      "Train Epoch: 44 [84480/118320 (71%)]\tLoss: 0.002078\n",
      "Train Epoch: 44 [87040/118320 (73%)]\tLoss: 0.002087\n",
      "Train Epoch: 44 [89600/118320 (76%)]\tLoss: 0.002068\n",
      "Train Epoch: 44 [92160/118320 (78%)]\tLoss: 0.002044\n",
      "Train Epoch: 44 [94720/118320 (80%)]\tLoss: 0.002074\n",
      "Train Epoch: 44 [97280/118320 (82%)]\tLoss: 0.002050\n",
      "Train Epoch: 44 [99840/118320 (84%)]\tLoss: 0.002079\n",
      "Train Epoch: 44 [102400/118320 (86%)]\tLoss: 0.002043\n",
      "Train Epoch: 44 [104960/118320 (89%)]\tLoss: 0.002080\n",
      "Train Epoch: 44 [107520/118320 (91%)]\tLoss: 0.002015\n",
      "Train Epoch: 44 [110080/118320 (93%)]\tLoss: 0.002040\n",
      "Train Epoch: 44 [112640/118320 (95%)]\tLoss: 0.002018\n",
      "Train Epoch: 44 [115200/118320 (97%)]\tLoss: 0.002068\n",
      "Train Epoch: 44 [117760/118320 (99%)]\tLoss: 0.002100\n",
      "\n",
      "Test set: Average loss: 0.0021\n",
      "\n",
      "Train Epoch: 45 [0/118320 (0%)]\tLoss: 0.002025\n",
      "Train Epoch: 45 [2560/118320 (2%)]\tLoss: 0.002077\n",
      "Train Epoch: 45 [5120/118320 (4%)]\tLoss: 0.002056\n",
      "Train Epoch: 45 [7680/118320 (6%)]\tLoss: 0.002056\n",
      "Train Epoch: 45 [10240/118320 (9%)]\tLoss: 0.002036\n",
      "Train Epoch: 45 [12800/118320 (11%)]\tLoss: 0.002039\n",
      "Train Epoch: 45 [15360/118320 (13%)]\tLoss: 0.002030\n",
      "Train Epoch: 45 [17920/118320 (15%)]\tLoss: 0.002067\n",
      "Train Epoch: 45 [20480/118320 (17%)]\tLoss: 0.002103\n",
      "Train Epoch: 45 [23040/118320 (19%)]\tLoss: 0.002054\n",
      "Train Epoch: 45 [25600/118320 (22%)]\tLoss: 0.002055\n",
      "Train Epoch: 45 [28160/118320 (24%)]\tLoss: 0.002063\n",
      "Train Epoch: 45 [30720/118320 (26%)]\tLoss: 0.002053\n",
      "Train Epoch: 45 [33280/118320 (28%)]\tLoss: 0.002039\n",
      "Train Epoch: 45 [35840/118320 (30%)]\tLoss: 0.002054\n",
      "Train Epoch: 45 [38400/118320 (32%)]\tLoss: 0.002079\n",
      "Train Epoch: 45 [40960/118320 (35%)]\tLoss: 0.002072\n",
      "Train Epoch: 45 [43520/118320 (37%)]\tLoss: 0.002038\n",
      "Train Epoch: 45 [46080/118320 (39%)]\tLoss: 0.002068\n",
      "Train Epoch: 45 [48640/118320 (41%)]\tLoss: 0.002048\n",
      "Train Epoch: 45 [51200/118320 (43%)]\tLoss: 0.002064\n",
      "Train Epoch: 45 [53760/118320 (45%)]\tLoss: 0.002072\n",
      "Train Epoch: 45 [56320/118320 (48%)]\tLoss: 0.002044\n",
      "Train Epoch: 45 [58880/118320 (50%)]\tLoss: 0.002057\n",
      "Train Epoch: 45 [61440/118320 (52%)]\tLoss: 0.002074\n",
      "Train Epoch: 45 [64000/118320 (54%)]\tLoss: 0.002056\n",
      "Train Epoch: 45 [66560/118320 (56%)]\tLoss: 0.002009\n",
      "Train Epoch: 45 [69120/118320 (58%)]\tLoss: 0.002051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 45 [71680/118320 (60%)]\tLoss: 0.002028\n",
      "Train Epoch: 45 [74240/118320 (63%)]\tLoss: 0.002076\n",
      "Train Epoch: 45 [76800/118320 (65%)]\tLoss: 0.002093\n",
      "Train Epoch: 45 [79360/118320 (67%)]\tLoss: 0.002077\n",
      "Train Epoch: 45 [81920/118320 (69%)]\tLoss: 0.002090\n",
      "Train Epoch: 45 [84480/118320 (71%)]\tLoss: 0.002024\n",
      "Train Epoch: 45 [87040/118320 (73%)]\tLoss: 0.002029\n",
      "Train Epoch: 45 [89600/118320 (76%)]\tLoss: 0.002054\n",
      "Train Epoch: 45 [92160/118320 (78%)]\tLoss: 0.002046\n",
      "Train Epoch: 45 [94720/118320 (80%)]\tLoss: 0.002050\n",
      "Train Epoch: 45 [97280/118320 (82%)]\tLoss: 0.002096\n",
      "Train Epoch: 45 [99840/118320 (84%)]\tLoss: 0.002081\n",
      "Train Epoch: 45 [102400/118320 (86%)]\tLoss: 0.002074\n",
      "Train Epoch: 45 [104960/118320 (89%)]\tLoss: 0.002043\n",
      "Train Epoch: 45 [107520/118320 (91%)]\tLoss: 0.002049\n",
      "Train Epoch: 45 [110080/118320 (93%)]\tLoss: 0.002066\n",
      "Train Epoch: 45 [112640/118320 (95%)]\tLoss: 0.002066\n",
      "Train Epoch: 45 [115200/118320 (97%)]\tLoss: 0.002038\n",
      "Train Epoch: 45 [117760/118320 (99%)]\tLoss: 0.002045\n",
      "\n",
      "Test set: Average loss: 0.0020\n",
      "\n",
      "Train Epoch: 46 [0/118320 (0%)]\tLoss: 0.002034\n",
      "Train Epoch: 46 [2560/118320 (2%)]\tLoss: 0.002099\n",
      "Train Epoch: 46 [5120/118320 (4%)]\tLoss: 0.002050\n",
      "Train Epoch: 46 [7680/118320 (6%)]\tLoss: 0.002050\n",
      "Train Epoch: 46 [10240/118320 (9%)]\tLoss: 0.002054\n",
      "Train Epoch: 46 [12800/118320 (11%)]\tLoss: 0.002037\n",
      "Train Epoch: 46 [15360/118320 (13%)]\tLoss: 0.002032\n",
      "Train Epoch: 46 [17920/118320 (15%)]\tLoss: 0.002053\n",
      "Train Epoch: 46 [20480/118320 (17%)]\tLoss: 0.002003\n",
      "Train Epoch: 46 [23040/118320 (19%)]\tLoss: 0.002067\n",
      "Train Epoch: 46 [25600/118320 (22%)]\tLoss: 0.002053\n",
      "Train Epoch: 46 [28160/118320 (24%)]\tLoss: 0.002048\n",
      "Train Epoch: 46 [30720/118320 (26%)]\tLoss: 0.002045\n",
      "Train Epoch: 46 [33280/118320 (28%)]\tLoss: 0.002048\n",
      "Train Epoch: 46 [35840/118320 (30%)]\tLoss: 0.002043\n",
      "Train Epoch: 46 [38400/118320 (32%)]\tLoss: 0.002083\n",
      "Train Epoch: 46 [40960/118320 (35%)]\tLoss: 0.002043\n",
      "Train Epoch: 46 [43520/118320 (37%)]\tLoss: 0.002092\n",
      "Train Epoch: 46 [46080/118320 (39%)]\tLoss: 0.002068\n",
      "Train Epoch: 46 [48640/118320 (41%)]\tLoss: 0.002070\n",
      "Train Epoch: 46 [51200/118320 (43%)]\tLoss: 0.002091\n",
      "Train Epoch: 46 [53760/118320 (45%)]\tLoss: 0.002033\n",
      "Train Epoch: 46 [56320/118320 (48%)]\tLoss: 0.002034\n",
      "Train Epoch: 46 [58880/118320 (50%)]\tLoss: 0.002030\n",
      "Train Epoch: 46 [61440/118320 (52%)]\tLoss: 0.002069\n",
      "Train Epoch: 46 [64000/118320 (54%)]\tLoss: 0.002055\n",
      "Train Epoch: 46 [66560/118320 (56%)]\tLoss: 0.002060\n",
      "Train Epoch: 46 [69120/118320 (58%)]\tLoss: 0.002030\n",
      "Train Epoch: 46 [71680/118320 (60%)]\tLoss: 0.002043\n",
      "Train Epoch: 46 [74240/118320 (63%)]\tLoss: 0.002036\n",
      "Train Epoch: 46 [76800/118320 (65%)]\tLoss: 0.002094\n",
      "Train Epoch: 46 [79360/118320 (67%)]\tLoss: 0.002088\n",
      "Train Epoch: 46 [81920/118320 (69%)]\tLoss: 0.002040\n",
      "Train Epoch: 46 [84480/118320 (71%)]\tLoss: 0.002047\n",
      "Train Epoch: 46 [87040/118320 (73%)]\tLoss: 0.002020\n",
      "Train Epoch: 46 [89600/118320 (76%)]\tLoss: 0.002044\n",
      "Train Epoch: 46 [92160/118320 (78%)]\tLoss: 0.002021\n",
      "Train Epoch: 46 [94720/118320 (80%)]\tLoss: 0.002028\n",
      "Train Epoch: 46 [97280/118320 (82%)]\tLoss: 0.002031\n",
      "Train Epoch: 46 [99840/118320 (84%)]\tLoss: 0.002071\n",
      "Train Epoch: 46 [102400/118320 (86%)]\tLoss: 0.002037\n",
      "Train Epoch: 46 [104960/118320 (89%)]\tLoss: 0.002054\n",
      "Train Epoch: 46 [107520/118320 (91%)]\tLoss: 0.002053\n",
      "Train Epoch: 46 [110080/118320 (93%)]\tLoss: 0.002033\n",
      "Train Epoch: 46 [112640/118320 (95%)]\tLoss: 0.002039\n",
      "Train Epoch: 46 [115200/118320 (97%)]\tLoss: 0.002026\n",
      "Train Epoch: 46 [117760/118320 (99%)]\tLoss: 0.002053\n",
      "\n",
      "Test set: Average loss: 0.0020\n",
      "\n",
      "Train Epoch: 47 [0/118320 (0%)]\tLoss: 0.002024\n",
      "Train Epoch: 47 [2560/118320 (2%)]\tLoss: 0.002086\n",
      "Train Epoch: 47 [5120/118320 (4%)]\tLoss: 0.002044\n",
      "Train Epoch: 47 [7680/118320 (6%)]\tLoss: 0.002055\n",
      "Train Epoch: 47 [10240/118320 (9%)]\tLoss: 0.002043\n",
      "Train Epoch: 47 [12800/118320 (11%)]\tLoss: 0.002043\n",
      "Train Epoch: 47 [15360/118320 (13%)]\tLoss: 0.002048\n",
      "Train Epoch: 47 [17920/118320 (15%)]\tLoss: 0.002050\n",
      "Train Epoch: 47 [20480/118320 (17%)]\tLoss: 0.002065\n",
      "Train Epoch: 47 [23040/118320 (19%)]\tLoss: 0.002071\n",
      "Train Epoch: 47 [25600/118320 (22%)]\tLoss: 0.002040\n",
      "Train Epoch: 47 [28160/118320 (24%)]\tLoss: 0.002045\n",
      "Train Epoch: 47 [30720/118320 (26%)]\tLoss: 0.002042\n",
      "Train Epoch: 47 [33280/118320 (28%)]\tLoss: 0.002084\n",
      "Train Epoch: 47 [35840/118320 (30%)]\tLoss: 0.002020\n",
      "Train Epoch: 47 [38400/118320 (32%)]\tLoss: 0.002050\n",
      "Train Epoch: 47 [40960/118320 (35%)]\tLoss: 0.002040\n",
      "Train Epoch: 47 [43520/118320 (37%)]\tLoss: 0.002016\n",
      "Train Epoch: 47 [46080/118320 (39%)]\tLoss: 0.002043\n",
      "Train Epoch: 47 [48640/118320 (41%)]\tLoss: 0.002027\n",
      "Train Epoch: 47 [51200/118320 (43%)]\tLoss: 0.002069\n",
      "Train Epoch: 47 [53760/118320 (45%)]\tLoss: 0.002046\n",
      "Train Epoch: 47 [56320/118320 (48%)]\tLoss: 0.002054\n",
      "Train Epoch: 47 [58880/118320 (50%)]\tLoss: 0.002025\n",
      "Train Epoch: 47 [61440/118320 (52%)]\tLoss: 0.002036\n",
      "Train Epoch: 47 [64000/118320 (54%)]\tLoss: 0.002025\n",
      "Train Epoch: 47 [66560/118320 (56%)]\tLoss: 0.002027\n",
      "Train Epoch: 47 [69120/118320 (58%)]\tLoss: 0.002050\n",
      "Train Epoch: 47 [71680/118320 (60%)]\tLoss: 0.002044\n",
      "Train Epoch: 47 [74240/118320 (63%)]\tLoss: 0.002054\n",
      "Train Epoch: 47 [76800/118320 (65%)]\tLoss: 0.002034\n",
      "Train Epoch: 47 [79360/118320 (67%)]\tLoss: 0.002086\n",
      "Train Epoch: 47 [81920/118320 (69%)]\tLoss: 0.002058\n",
      "Train Epoch: 47 [84480/118320 (71%)]\tLoss: 0.002027\n",
      "Train Epoch: 47 [87040/118320 (73%)]\tLoss: 0.002040\n",
      "Train Epoch: 47 [89600/118320 (76%)]\tLoss: 0.002037\n",
      "Train Epoch: 47 [92160/118320 (78%)]\tLoss: 0.002065\n",
      "Train Epoch: 47 [94720/118320 (80%)]\tLoss: 0.002039\n",
      "Train Epoch: 47 [97280/118320 (82%)]\tLoss: 0.002041\n",
      "Train Epoch: 47 [99840/118320 (84%)]\tLoss: 0.002027\n",
      "Train Epoch: 47 [102400/118320 (86%)]\tLoss: 0.002027\n",
      "Train Epoch: 47 [104960/118320 (89%)]\tLoss: 0.002047\n",
      "Train Epoch: 47 [107520/118320 (91%)]\tLoss: 0.002063\n",
      "Train Epoch: 47 [110080/118320 (93%)]\tLoss: 0.002055\n",
      "Train Epoch: 47 [112640/118320 (95%)]\tLoss: 0.002042\n",
      "Train Epoch: 47 [115200/118320 (97%)]\tLoss: 0.002056\n",
      "Train Epoch: 47 [117760/118320 (99%)]\tLoss: 0.002029\n",
      "\n",
      "Test set: Average loss: 0.0020\n",
      "\n",
      "Train Epoch: 48 [0/118320 (0%)]\tLoss: 0.002056\n",
      "Train Epoch: 48 [2560/118320 (2%)]\tLoss: 0.002060\n",
      "Train Epoch: 48 [5120/118320 (4%)]\tLoss: 0.002035\n",
      "Train Epoch: 48 [7680/118320 (6%)]\tLoss: 0.002042\n",
      "Train Epoch: 48 [10240/118320 (9%)]\tLoss: 0.002049\n",
      "Train Epoch: 48 [12800/118320 (11%)]\tLoss: 0.002061\n",
      "Train Epoch: 48 [15360/118320 (13%)]\tLoss: 0.002030\n",
      "Train Epoch: 48 [17920/118320 (15%)]\tLoss: 0.002035\n",
      "Train Epoch: 48 [20480/118320 (17%)]\tLoss: 0.002019\n",
      "Train Epoch: 48 [23040/118320 (19%)]\tLoss: 0.002053\n",
      "Train Epoch: 48 [25600/118320 (22%)]\tLoss: 0.002040\n",
      "Train Epoch: 48 [28160/118320 (24%)]\tLoss: 0.002022\n",
      "Train Epoch: 48 [30720/118320 (26%)]\tLoss: 0.002048\n",
      "Train Epoch: 48 [33280/118320 (28%)]\tLoss: 0.002045\n",
      "Train Epoch: 48 [35840/118320 (30%)]\tLoss: 0.002059\n",
      "Train Epoch: 48 [38400/118320 (32%)]\tLoss: 0.002007\n",
      "Train Epoch: 48 [40960/118320 (35%)]\tLoss: 0.002036\n",
      "Train Epoch: 48 [43520/118320 (37%)]\tLoss: 0.002000\n",
      "Train Epoch: 48 [46080/118320 (39%)]\tLoss: 0.002025\n",
      "Train Epoch: 48 [48640/118320 (41%)]\tLoss: 0.002065\n",
      "Train Epoch: 48 [51200/118320 (43%)]\tLoss: 0.002047\n",
      "Train Epoch: 48 [53760/118320 (45%)]\tLoss: 0.002057\n",
      "Train Epoch: 48 [56320/118320 (48%)]\tLoss: 0.002026\n",
      "Train Epoch: 48 [58880/118320 (50%)]\tLoss: 0.002053\n",
      "Train Epoch: 48 [61440/118320 (52%)]\tLoss: 0.002066\n",
      "Train Epoch: 48 [64000/118320 (54%)]\tLoss: 0.002056\n",
      "Train Epoch: 48 [66560/118320 (56%)]\tLoss: 0.002060\n",
      "Train Epoch: 48 [69120/118320 (58%)]\tLoss: 0.002023\n",
      "Train Epoch: 48 [71680/118320 (60%)]\tLoss: 0.002028\n",
      "Train Epoch: 48 [74240/118320 (63%)]\tLoss: 0.002025\n",
      "Train Epoch: 48 [76800/118320 (65%)]\tLoss: 0.002045\n",
      "Train Epoch: 48 [79360/118320 (67%)]\tLoss: 0.002033\n",
      "Train Epoch: 48 [81920/118320 (69%)]\tLoss: 0.002058\n",
      "Train Epoch: 48 [84480/118320 (71%)]\tLoss: 0.002082\n",
      "Train Epoch: 48 [87040/118320 (73%)]\tLoss: 0.002045\n",
      "Train Epoch: 48 [89600/118320 (76%)]\tLoss: 0.002027\n",
      "Train Epoch: 48 [92160/118320 (78%)]\tLoss: 0.002059\n",
      "Train Epoch: 48 [94720/118320 (80%)]\tLoss: 0.002096\n",
      "Train Epoch: 48 [97280/118320 (82%)]\tLoss: 0.002057\n",
      "Train Epoch: 48 [99840/118320 (84%)]\tLoss: 0.002035\n",
      "Train Epoch: 48 [102400/118320 (86%)]\tLoss: 0.002081\n",
      "Train Epoch: 48 [104960/118320 (89%)]\tLoss: 0.002030\n",
      "Train Epoch: 48 [107520/118320 (91%)]\tLoss: 0.002069\n",
      "Train Epoch: 48 [110080/118320 (93%)]\tLoss: 0.002019\n",
      "Train Epoch: 48 [112640/118320 (95%)]\tLoss: 0.002044\n",
      "Train Epoch: 48 [115200/118320 (97%)]\tLoss: 0.002007\n",
      "Train Epoch: 48 [117760/118320 (99%)]\tLoss: 0.002062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0020\n",
      "\n",
      "Train Epoch: 49 [0/118320 (0%)]\tLoss: 0.002014\n",
      "Train Epoch: 49 [2560/118320 (2%)]\tLoss: 0.002045\n",
      "Train Epoch: 49 [5120/118320 (4%)]\tLoss: 0.002023\n",
      "Train Epoch: 49 [7680/118320 (6%)]\tLoss: 0.002071\n",
      "Train Epoch: 49 [10240/118320 (9%)]\tLoss: 0.002050\n",
      "Train Epoch: 49 [12800/118320 (11%)]\tLoss: 0.002032\n",
      "Train Epoch: 49 [15360/118320 (13%)]\tLoss: 0.002044\n",
      "Train Epoch: 49 [17920/118320 (15%)]\tLoss: 0.002013\n",
      "Train Epoch: 49 [20480/118320 (17%)]\tLoss: 0.002049\n",
      "Train Epoch: 49 [23040/118320 (19%)]\tLoss: 0.002045\n",
      "Train Epoch: 49 [25600/118320 (22%)]\tLoss: 0.002056\n",
      "Train Epoch: 49 [28160/118320 (24%)]\tLoss: 0.002045\n",
      "Train Epoch: 49 [30720/118320 (26%)]\tLoss: 0.002045\n",
      "Train Epoch: 49 [33280/118320 (28%)]\tLoss: 0.002043\n",
      "Train Epoch: 49 [35840/118320 (30%)]\tLoss: 0.002029\n",
      "Train Epoch: 49 [38400/118320 (32%)]\tLoss: 0.001998\n",
      "Train Epoch: 49 [40960/118320 (35%)]\tLoss: 0.002048\n",
      "Train Epoch: 49 [43520/118320 (37%)]\tLoss: 0.002045\n",
      "Train Epoch: 49 [46080/118320 (39%)]\tLoss: 0.002045\n",
      "Train Epoch: 49 [48640/118320 (41%)]\tLoss: 0.002057\n",
      "Train Epoch: 49 [51200/118320 (43%)]\tLoss: 0.002053\n",
      "Train Epoch: 49 [53760/118320 (45%)]\tLoss: 0.002021\n",
      "Train Epoch: 49 [56320/118320 (48%)]\tLoss: 0.001992\n",
      "Train Epoch: 49 [58880/118320 (50%)]\tLoss: 0.002034\n",
      "Train Epoch: 49 [61440/118320 (52%)]\tLoss: 0.002019\n",
      "Train Epoch: 49 [64000/118320 (54%)]\tLoss: 0.001992\n",
      "Train Epoch: 49 [66560/118320 (56%)]\tLoss: 0.002037\n",
      "Train Epoch: 49 [69120/118320 (58%)]\tLoss: 0.002052\n",
      "Train Epoch: 49 [71680/118320 (60%)]\tLoss: 0.002021\n",
      "Train Epoch: 49 [74240/118320 (63%)]\tLoss: 0.002045\n",
      "Train Epoch: 49 [76800/118320 (65%)]\tLoss: 0.002031\n",
      "Train Epoch: 49 [79360/118320 (67%)]\tLoss: 0.002025\n",
      "Train Epoch: 49 [81920/118320 (69%)]\tLoss: 0.002059\n",
      "Train Epoch: 49 [84480/118320 (71%)]\tLoss: 0.002080\n",
      "Train Epoch: 49 [87040/118320 (73%)]\tLoss: 0.002067\n",
      "Train Epoch: 49 [89600/118320 (76%)]\tLoss: 0.002051\n",
      "Train Epoch: 49 [92160/118320 (78%)]\tLoss: 0.002043\n",
      "Train Epoch: 49 [94720/118320 (80%)]\tLoss: 0.002035\n",
      "Train Epoch: 49 [97280/118320 (82%)]\tLoss: 0.002024\n",
      "Train Epoch: 49 [99840/118320 (84%)]\tLoss: 0.002031\n",
      "Train Epoch: 49 [102400/118320 (86%)]\tLoss: 0.002038\n",
      "Train Epoch: 49 [104960/118320 (89%)]\tLoss: 0.002067\n",
      "Train Epoch: 49 [107520/118320 (91%)]\tLoss: 0.002003\n",
      "Train Epoch: 49 [110080/118320 (93%)]\tLoss: 0.002044\n",
      "Train Epoch: 49 [112640/118320 (95%)]\tLoss: 0.002049\n",
      "Train Epoch: 49 [115200/118320 (97%)]\tLoss: 0.002048\n",
      "Train Epoch: 49 [117760/118320 (99%)]\tLoss: 0.002033\n",
      "\n",
      "Test set: Average loss: 0.0020\n",
      "\n",
      "Train Epoch: 50 [0/118320 (0%)]\tLoss: 0.002034\n",
      "Train Epoch: 50 [2560/118320 (2%)]\tLoss: 0.002015\n",
      "Train Epoch: 50 [5120/118320 (4%)]\tLoss: 0.002084\n",
      "Train Epoch: 50 [7680/118320 (6%)]\tLoss: 0.002082\n",
      "Train Epoch: 50 [10240/118320 (9%)]\tLoss: 0.002040\n",
      "Train Epoch: 50 [12800/118320 (11%)]\tLoss: 0.002053\n",
      "Train Epoch: 50 [15360/118320 (13%)]\tLoss: 0.002026\n",
      "Train Epoch: 50 [17920/118320 (15%)]\tLoss: 0.002050\n",
      "Train Epoch: 50 [20480/118320 (17%)]\tLoss: 0.002072\n",
      "Train Epoch: 50 [23040/118320 (19%)]\tLoss: 0.002039\n",
      "Train Epoch: 50 [25600/118320 (22%)]\tLoss: 0.002029\n",
      "Train Epoch: 50 [28160/118320 (24%)]\tLoss: 0.002037\n",
      "Train Epoch: 50 [30720/118320 (26%)]\tLoss: 0.002031\n",
      "Train Epoch: 50 [33280/118320 (28%)]\tLoss: 0.002037\n",
      "Train Epoch: 50 [35840/118320 (30%)]\tLoss: 0.002015\n",
      "Train Epoch: 50 [38400/118320 (32%)]\tLoss: 0.002054\n",
      "Train Epoch: 50 [40960/118320 (35%)]\tLoss: 0.002041\n",
      "Train Epoch: 50 [43520/118320 (37%)]\tLoss: 0.002055\n",
      "Train Epoch: 50 [46080/118320 (39%)]\tLoss: 0.002016\n",
      "Train Epoch: 50 [48640/118320 (41%)]\tLoss: 0.002044\n",
      "Train Epoch: 50 [51200/118320 (43%)]\tLoss: 0.002027\n",
      "Train Epoch: 50 [53760/118320 (45%)]\tLoss: 0.002018\n",
      "Train Epoch: 50 [56320/118320 (48%)]\tLoss: 0.002020\n",
      "Train Epoch: 50 [58880/118320 (50%)]\tLoss: 0.002016\n",
      "Train Epoch: 50 [61440/118320 (52%)]\tLoss: 0.002021\n",
      "Train Epoch: 50 [64000/118320 (54%)]\tLoss: 0.002051\n",
      "Train Epoch: 50 [66560/118320 (56%)]\tLoss: 0.002055\n",
      "Train Epoch: 50 [69120/118320 (58%)]\tLoss: 0.002005\n",
      "Train Epoch: 50 [71680/118320 (60%)]\tLoss: 0.002019\n",
      "Train Epoch: 50 [74240/118320 (63%)]\tLoss: 0.002037\n",
      "Train Epoch: 50 [76800/118320 (65%)]\tLoss: 0.002005\n",
      "Train Epoch: 50 [79360/118320 (67%)]\tLoss: 0.002016\n",
      "Train Epoch: 50 [81920/118320 (69%)]\tLoss: 0.002041\n",
      "Train Epoch: 50 [84480/118320 (71%)]\tLoss: 0.002021\n",
      "Train Epoch: 50 [87040/118320 (73%)]\tLoss: 0.002024\n",
      "Train Epoch: 50 [89600/118320 (76%)]\tLoss: 0.002008\n",
      "Train Epoch: 50 [92160/118320 (78%)]\tLoss: 0.002065\n",
      "Train Epoch: 50 [94720/118320 (80%)]\tLoss: 0.002048\n",
      "Train Epoch: 50 [97280/118320 (82%)]\tLoss: 0.001995\n",
      "Train Epoch: 50 [99840/118320 (84%)]\tLoss: 0.002019\n",
      "Train Epoch: 50 [102400/118320 (86%)]\tLoss: 0.002016\n",
      "Train Epoch: 50 [104960/118320 (89%)]\tLoss: 0.001991\n",
      "Train Epoch: 50 [107520/118320 (91%)]\tLoss: 0.002029\n",
      "Train Epoch: 50 [110080/118320 (93%)]\tLoss: 0.002008\n",
      "Train Epoch: 50 [112640/118320 (95%)]\tLoss: 0.002021\n",
      "Train Epoch: 50 [115200/118320 (97%)]\tLoss: 0.002056\n",
      "Train Epoch: 50 [117760/118320 (99%)]\tLoss: 0.002020\n",
      "\n",
      "Test set: Average loss: 0.0020\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for epoch in range(1, epochs + 1):\n",
    "        train(net, train_loader, optimizer, epoch,device)\n",
    "        test(net, test_loader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0020360895261554686\n",
      "\n",
      "Test Loss: 0.002033973118952146\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate Accuracy\n",
    "print('Training Loss:', train_loss[-1])\n",
    "# print('Training Accuracy:', train_accu[-1])\n",
    "print()\n",
    "print('Test Loss:', val_loss[-1])\n",
    "# print('Testing Accuracy:', test_accu[-1])\n",
    "print()\n",
    "\n",
    "plt.plot(train_loss,'r', label='Training Loss')\n",
    "plt.plot(val_loss,'b', label='Testing Loss')\n",
    "plt.title('Test Loss' + str(val_loss[-1]))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# plt.plot(train_accu,'r', label='Training accuracy')\n",
    "# plt.plot(test_accu,'b', label='Testing accuracy')\n",
    "# plt.title('Test Accuracy : '+ str(test_accu[-1]))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model_ft,(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
