{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Predict if someone makes more or less than 50k using the adult dataset\n",
    "\n",
    "   * Note that this dataset strictly refers to people living in the US\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anirudh/anaconda2/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# !pip install torchsummary \n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Training and Testing Data using Data Loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Training and Testing Data\n",
    "trainImages = np.load('./Adult/data.npy').astype('float32')\n",
    "trainLabels = np.load('./Adult/labels.npy').astype('float32')\n",
    "\n",
    "# # Normalizing the data\n",
    "# mx = np.max(np.float32(trainImages.flatten()))\n",
    "# Splitting the Data into Training and Test Data    trainImages.max(axis=0)\n",
    "X_train, X_test,Y_train,Y_test = train_test_split(trainImages,trainLabels, test_size=0.15, shuffle = True)\n",
    "\n",
    "# batch_size\n",
    "batch = 256\n",
    "\n",
    "# Train Data Loader\n",
    "train = data_utils.TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(Y_train))\n",
    "train_loader = data_utils.DataLoader(train, batch_size=batch, shuffle=True)\n",
    "\n",
    "# Test Data loader\n",
    "test = data_utils.TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(Y_test))\n",
    "test_loader = data_utils.DataLoader(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38438, 67)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6784, 67)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showing the Training Data after Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(22.)\n",
      "1\n",
      "tensor(21.)\n",
      "2\n",
      "tensor(52.)\n",
      "3\n",
      "tensor(32.)\n",
      "4\n",
      "tensor(51.)\n",
      "5\n",
      "tensor(26.)\n",
      "6\n",
      "tensor(21.)\n",
      "7\n",
      "tensor(36.)\n",
      "8\n",
      "tensor(62.)\n",
      "9\n",
      "tensor(51.)\n",
      "10\n",
      "tensor(25.)\n",
      "11\n",
      "tensor(30.)\n",
      "12\n",
      "tensor(26.)\n",
      "13\n",
      "tensor(44.)\n",
      "14\n",
      "tensor(39.)\n",
      "15\n",
      "tensor(17.)\n",
      "16\n",
      "tensor(50.)\n",
      "17\n",
      "tensor(50.)\n",
      "18\n",
      "tensor(17.)\n",
      "19\n",
      "tensor(31.)\n",
      "20\n",
      "tensor(36.)\n",
      "21\n",
      "tensor(46.)\n",
      "22\n",
      "tensor(19.)\n",
      "23\n",
      "tensor(37.)\n",
      "24\n",
      "tensor(27.)\n",
      "25\n",
      "tensor(42.)\n",
      "26\n",
      "tensor(30.)\n",
      "27\n",
      "tensor(25.)\n",
      "28\n",
      "tensor(72.)\n",
      "29\n",
      "tensor(36.)\n",
      "30\n",
      "tensor(45.)\n",
      "31\n",
      "tensor(58.)\n",
      "32\n",
      "tensor(24.)\n",
      "33\n",
      "tensor(26.)\n",
      "34\n",
      "tensor(41.)\n",
      "35\n",
      "tensor(24.)\n",
      "36\n",
      "tensor(37.)\n",
      "37\n",
      "tensor(20.)\n",
      "38\n",
      "tensor(41.)\n",
      "39\n",
      "tensor(66.)\n",
      "40\n",
      "tensor(52.)\n",
      "41\n",
      "tensor(23.)\n",
      "42\n",
      "tensor(35.)\n",
      "43\n",
      "tensor(23.)\n",
      "44\n",
      "tensor(64.)\n",
      "45\n",
      "tensor(38.)\n",
      "46\n",
      "tensor(36.)\n",
      "47\n",
      "tensor(69.)\n",
      "48\n",
      "tensor(34.)\n",
      "49\n",
      "tensor(56.)\n",
      "50\n",
      "tensor(37.)\n",
      "51\n",
      "tensor(30.)\n",
      "52\n",
      "tensor(32.)\n",
      "53\n",
      "tensor(72.)\n",
      "54\n",
      "tensor(32.)\n",
      "55\n",
      "tensor(23.)\n",
      "56\n",
      "tensor(39.)\n",
      "57\n",
      "tensor(37.)\n",
      "58\n",
      "tensor(45.)\n",
      "59\n",
      "tensor(31.)\n",
      "60\n",
      "tensor(38.)\n",
      "61\n",
      "tensor(23.)\n",
      "62\n",
      "tensor(30.)\n",
      "63\n",
      "tensor(23.)\n",
      "64\n",
      "tensor(19.)\n",
      "65\n",
      "tensor(54.)\n",
      "66\n",
      "tensor(43.)\n",
      "67\n",
      "tensor(26.)\n",
      "68\n",
      "tensor(28.)\n",
      "69\n",
      "tensor(31.)\n",
      "70\n",
      "tensor(41.)\n",
      "71\n",
      "tensor(42.)\n",
      "72\n",
      "tensor(20.)\n",
      "73\n",
      "tensor(24.)\n",
      "74\n",
      "tensor(29.)\n",
      "75\n",
      "tensor(43.)\n",
      "76\n",
      "tensor(45.)\n",
      "77\n",
      "tensor(28.)\n",
      "78\n",
      "tensor(20.)\n",
      "79\n",
      "tensor(68.)\n",
      "80\n",
      "tensor(62.)\n",
      "81\n",
      "tensor(40.)\n",
      "82\n",
      "tensor(22.)\n",
      "83\n",
      "tensor(33.)\n",
      "84\n",
      "tensor(47.)\n",
      "85\n",
      "tensor(47.)\n",
      "86\n",
      "tensor(21.)\n",
      "87\n",
      "tensor(27.)\n",
      "88\n",
      "tensor(23.)\n",
      "89\n",
      "tensor(39.)\n",
      "90\n",
      "tensor(46.)\n",
      "91\n",
      "tensor(23.)\n",
      "92\n",
      "tensor(18.)\n",
      "93\n",
      "tensor(27.)\n",
      "94\n",
      "tensor(57.)\n",
      "95\n",
      "tensor(62.)\n",
      "96\n",
      "tensor(58.)\n",
      "97\n",
      "tensor(30.)\n",
      "98\n",
      "tensor(22.)\n",
      "99\n",
      "tensor(39.)\n",
      "100\n",
      "tensor(20.)\n",
      "101\n",
      "tensor(41.)\n",
      "102\n",
      "tensor(55.)\n",
      "103\n",
      "tensor(32.)\n",
      "104\n",
      "tensor(30.)\n",
      "105\n",
      "tensor(44.)\n",
      "106\n",
      "tensor(53.)\n",
      "107\n",
      "tensor(29.)\n",
      "108\n",
      "tensor(31.)\n",
      "109\n",
      "tensor(47.)\n",
      "110\n",
      "tensor(56.)\n",
      "111\n",
      "tensor(36.)\n",
      "112\n",
      "tensor(55.)\n",
      "113\n",
      "tensor(35.)\n",
      "114\n",
      "tensor(28.)\n",
      "115\n",
      "tensor(20.)\n",
      "116\n",
      "tensor(34.)\n",
      "117\n",
      "tensor(26.)\n",
      "118\n",
      "tensor(21.)\n",
      "119\n",
      "tensor(67.)\n",
      "120\n",
      "tensor(51.)\n",
      "121\n",
      "tensor(39.)\n",
      "122\n",
      "tensor(35.)\n",
      "123\n",
      "tensor(22.)\n",
      "124\n",
      "tensor(40.)\n",
      "125\n",
      "tensor(59.)\n",
      "126\n",
      "tensor(35.)\n",
      "127\n",
      "tensor(43.)\n",
      "128\n",
      "tensor(48.)\n",
      "129\n",
      "tensor(49.)\n",
      "130\n",
      "tensor(32.)\n",
      "131\n",
      "tensor(36.)\n",
      "132\n",
      "tensor(33.)\n",
      "133\n",
      "tensor(61.)\n",
      "134\n",
      "tensor(28.)\n",
      "135\n",
      "tensor(35.)\n",
      "136\n",
      "tensor(30.)\n",
      "137\n",
      "tensor(69.)\n",
      "138\n",
      "tensor(36.)\n",
      "139\n",
      "tensor(24.)\n",
      "140\n",
      "tensor(22.)\n",
      "141\n",
      "tensor(34.)\n",
      "142\n",
      "tensor(38.)\n",
      "143\n",
      "tensor(64.)\n",
      "144\n",
      "tensor(41.)\n",
      "145\n",
      "tensor(48.)\n",
      "146\n",
      "tensor(54.)\n",
      "147\n",
      "tensor(30.)\n",
      "148\n",
      "tensor(46.)\n",
      "149\n",
      "tensor(54.)\n",
      "150\n",
      "tensor(45.)\n"
     ]
    }
   ],
   "source": [
    "# Preview the training data\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    print(batch_idx)\n",
    "#     print(\"Training Data\")\n",
    "    print(data[0][0])\n",
    "#     print(\"Testing Data\")\n",
    "#     print(target[0])\n",
    "#     print(data.sha?pe)\n",
    "#     break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Convolution Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=67, out_features=128, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (dout): Dropout(p=0.2)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (dout2): Dropout(p=0.2)\n",
       "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (prelu): PReLU(num_parameters=1)\n",
       "  (out): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (out_act): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(67, 128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dout = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dout2 = nn.Dropout(0.2)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.prelu = nn.PReLU(1)\n",
    "        self.out = nn.Linear(32, 1)\n",
    "        self.out_act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        inp = self.fc1(input_)\n",
    "        x = self.relu1(inp)\n",
    "        x = self.dout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dout2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.prelu(x)\n",
    "        x = self.out(x)\n",
    "        y = (self.out_act(x))\n",
    "        return y\n",
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1              [256, 1, 128]           8,704\n",
      "              ReLU-2              [256, 1, 128]               0\n",
      "           Dropout-3              [256, 1, 128]               0\n",
      "            Linear-4               [256, 1, 64]           8,256\n",
      "              ReLU-5               [256, 1, 64]               0\n",
      "           Dropout-6               [256, 1, 64]               0\n",
      "            Linear-7               [256, 1, 32]           2,080\n",
      "             PReLU-8               [256, 1, 32]               1\n",
      "            Linear-9                [256, 1, 1]              33\n",
      "          Sigmoid-10                [256, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 19,074\n",
      "Trainable params: 19,074\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.07\n",
      "Forward/backward pass size (MB): 1.25\n",
      "Params size (MB): 0.07\n",
      "Estimated Total Size (MB): 1.39\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net,input_size = (1,67),batch_size=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(net.parameters())\n",
    "# print(len(params))\n",
    "# print(params[0].size())  # conv1's .weight\n",
    "\n",
    "# params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Define a Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "train_loss =[]\n",
    "val_loss = []\n",
    "train_accu = []\n",
    "test_accu=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = net(data)\n",
    "#         print(target.dtype,output.dtype)\n",
    "target = target.view(-1,1)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "torch.sum(output==target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch,device):\n",
    "    model.train()\n",
    "    criterion = nn.BCELoss()\n",
    "    training_loss = 0\n",
    "    train_correct = 0\n",
    "    lo = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "#         print(target.dtype,output.dtype)\n",
    "        target = target.view(-1,1)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         print(loss.item())\n",
    "        lo.append(loss.item())\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "        train_correct += torch.sum(torch.round(output)==target)\n",
    "#         print(train_correct)\n",
    "    train_accu.append(100. * train_correct / len(train_loader.dataset))\n",
    "    train_loss.append(np.mean(lo))\n",
    "\n",
    "def test(model, test_loader,device):\n",
    "    model.eval()\n",
    "    criterion = nn.BCELoss()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    testlo = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            target = target.view(-1,1)\n",
    "#             test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            test_loss = criterion(output, target)\n",
    "            testlo.append(test_loss.item())\n",
    "#             print(test_loss)\n",
    "#             print()\n",
    "            correct += torch.sum(torch.round(output)==target)\n",
    "#     print(100. * correct / len(test_loader.dataset))\n",
    "    test_accu.append(100. * correct / len(test_loader.dataset))\n",
    "    val_loss.append(np.mean(testlo))\n",
    "#     print(test_loss)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        np.mean(testlo), correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/38438 (0%)]\tLoss: 0.534055\n",
      "Train Epoch: 1 [2560/38438 (7%)]\tLoss: 0.531182\n",
      "Train Epoch: 1 [5120/38438 (13%)]\tLoss: 0.492474\n",
      "Train Epoch: 1 [7680/38438 (20%)]\tLoss: 0.572266\n",
      "Train Epoch: 1 [10240/38438 (26%)]\tLoss: 0.596717\n",
      "Train Epoch: 1 [12800/38438 (33%)]\tLoss: 0.560076\n",
      "Train Epoch: 1 [15360/38438 (40%)]\tLoss: 0.572222\n",
      "Train Epoch: 1 [17920/38438 (46%)]\tLoss: 0.550599\n",
      "Train Epoch: 1 [20480/38438 (53%)]\tLoss: 0.568900\n",
      "Train Epoch: 1 [23040/38438 (60%)]\tLoss: 0.603931\n",
      "Train Epoch: 1 [25600/38438 (66%)]\tLoss: 0.589733\n",
      "Train Epoch: 1 [28160/38438 (73%)]\tLoss: 0.604763\n",
      "Train Epoch: 1 [30720/38438 (79%)]\tLoss: 0.530749\n",
      "Train Epoch: 1 [33280/38438 (86%)]\tLoss: 0.550177\n",
      "Train Epoch: 1 [35840/38438 (93%)]\tLoss: 0.550723\n",
      "Train Epoch: 1 [5700/38438 (99%)]\tLoss: 0.518731\n",
      "\n",
      "Test set: Average loss: 0.5488, Accuracy: 5189/6784 (76%)\n",
      "\n",
      "Train Epoch: 2 [0/38438 (0%)]\tLoss: 0.565936\n",
      "Train Epoch: 2 [2560/38438 (7%)]\tLoss: 0.608869\n",
      "Train Epoch: 2 [5120/38438 (13%)]\tLoss: 0.585071\n",
      "Train Epoch: 2 [7680/38438 (20%)]\tLoss: 0.565511\n",
      "Train Epoch: 2 [10240/38438 (26%)]\tLoss: 0.531766\n",
      "Train Epoch: 2 [12800/38438 (33%)]\tLoss: 0.503981\n",
      "Train Epoch: 2 [15360/38438 (40%)]\tLoss: 0.586439\n",
      "Train Epoch: 2 [17920/38438 (46%)]\tLoss: 0.499434\n",
      "Train Epoch: 2 [20480/38438 (53%)]\tLoss: 0.521471\n",
      "Train Epoch: 2 [23040/38438 (60%)]\tLoss: 0.588525\n",
      "Train Epoch: 2 [25600/38438 (66%)]\tLoss: 0.521515\n",
      "Train Epoch: 2 [28160/38438 (73%)]\tLoss: 0.565910\n",
      "Train Epoch: 2 [30720/38438 (79%)]\tLoss: 0.601637\n",
      "Train Epoch: 2 [33280/38438 (86%)]\tLoss: 0.573632\n",
      "Train Epoch: 2 [35840/38438 (93%)]\tLoss: 0.522183\n",
      "Train Epoch: 2 [5700/38438 (99%)]\tLoss: 0.449691\n",
      "\n",
      "Test set: Average loss: 0.5404, Accuracy: 5275/6784 (77%)\n",
      "\n",
      "Train Epoch: 3 [0/38438 (0%)]\tLoss: 0.544788\n",
      "Train Epoch: 3 [2560/38438 (7%)]\tLoss: 0.534672\n",
      "Train Epoch: 3 [5120/38438 (13%)]\tLoss: 0.523826\n",
      "Train Epoch: 3 [7680/38438 (20%)]\tLoss: 0.546781\n",
      "Train Epoch: 3 [10240/38438 (26%)]\tLoss: 0.547709\n",
      "Train Epoch: 3 [12800/38438 (33%)]\tLoss: 0.545983\n",
      "Train Epoch: 3 [15360/38438 (40%)]\tLoss: 0.552023\n",
      "Train Epoch: 3 [17920/38438 (46%)]\tLoss: 0.508132\n",
      "Train Epoch: 3 [20480/38438 (53%)]\tLoss: 0.521234\n",
      "Train Epoch: 3 [23040/38438 (60%)]\tLoss: 0.499919\n",
      "Train Epoch: 3 [25600/38438 (66%)]\tLoss: 0.618715\n",
      "Train Epoch: 3 [28160/38438 (73%)]\tLoss: 0.542144\n",
      "Train Epoch: 3 [30720/38438 (79%)]\tLoss: 0.516470\n",
      "Train Epoch: 3 [33280/38438 (86%)]\tLoss: 0.559015\n",
      "Train Epoch: 3 [35840/38438 (93%)]\tLoss: 0.548904\n",
      "Train Epoch: 3 [5700/38438 (99%)]\tLoss: 0.493818\n",
      "\n",
      "Test set: Average loss: 0.5349, Accuracy: 5264/6784 (77%)\n",
      "\n",
      "Train Epoch: 4 [0/38438 (0%)]\tLoss: 0.546131\n",
      "Train Epoch: 4 [2560/38438 (7%)]\tLoss: 0.547890\n",
      "Train Epoch: 4 [5120/38438 (13%)]\tLoss: 0.551972\n",
      "Train Epoch: 4 [7680/38438 (20%)]\tLoss: 0.562594\n",
      "Train Epoch: 4 [10240/38438 (26%)]\tLoss: 0.536447\n",
      "Train Epoch: 4 [12800/38438 (33%)]\tLoss: 0.531342\n",
      "Train Epoch: 4 [15360/38438 (40%)]\tLoss: 0.559028\n",
      "Train Epoch: 4 [17920/38438 (46%)]\tLoss: 0.548402\n",
      "Train Epoch: 4 [20480/38438 (53%)]\tLoss: 0.512274\n",
      "Train Epoch: 4 [23040/38438 (60%)]\tLoss: 0.542704\n",
      "Train Epoch: 4 [25600/38438 (66%)]\tLoss: 0.472226\n",
      "Train Epoch: 4 [28160/38438 (73%)]\tLoss: 0.524761\n",
      "Train Epoch: 4 [30720/38438 (79%)]\tLoss: 0.549092\n",
      "Train Epoch: 4 [33280/38438 (86%)]\tLoss: 0.514765\n",
      "Train Epoch: 4 [35840/38438 (93%)]\tLoss: 0.530448\n",
      "Train Epoch: 4 [5700/38438 (99%)]\tLoss: 0.550760\n",
      "\n",
      "Test set: Average loss: 0.5295, Accuracy: 5272/6784 (77%)\n",
      "\n",
      "Train Epoch: 5 [0/38438 (0%)]\tLoss: 0.557833\n",
      "Train Epoch: 5 [2560/38438 (7%)]\tLoss: 0.591305\n",
      "Train Epoch: 5 [5120/38438 (13%)]\tLoss: 0.556640\n",
      "Train Epoch: 5 [7680/38438 (20%)]\tLoss: 0.520748\n",
      "Train Epoch: 5 [10240/38438 (26%)]\tLoss: 0.543160\n",
      "Train Epoch: 5 [12800/38438 (33%)]\tLoss: 0.566309\n",
      "Train Epoch: 5 [15360/38438 (40%)]\tLoss: 0.563395\n",
      "Train Epoch: 5 [17920/38438 (46%)]\tLoss: 0.588715\n",
      "Train Epoch: 5 [20480/38438 (53%)]\tLoss: 0.549129\n",
      "Train Epoch: 5 [23040/38438 (60%)]\tLoss: 0.552474\n",
      "Train Epoch: 5 [25600/38438 (66%)]\tLoss: 0.495985\n",
      "Train Epoch: 5 [28160/38438 (73%)]\tLoss: 0.502993\n",
      "Train Epoch: 5 [30720/38438 (79%)]\tLoss: 0.540188\n",
      "Train Epoch: 5 [33280/38438 (86%)]\tLoss: 0.522781\n",
      "Train Epoch: 5 [35840/38438 (93%)]\tLoss: 0.550738\n",
      "Train Epoch: 5 [5700/38438 (99%)]\tLoss: 0.400914\n",
      "\n",
      "Test set: Average loss: 0.5238, Accuracy: 5276/6784 (77%)\n",
      "\n",
      "Train Epoch: 6 [0/38438 (0%)]\tLoss: 0.516192\n",
      "Train Epoch: 6 [2560/38438 (7%)]\tLoss: 0.508733\n",
      "Train Epoch: 6 [5120/38438 (13%)]\tLoss: 0.453602\n",
      "Train Epoch: 6 [7680/38438 (20%)]\tLoss: 0.484749\n",
      "Train Epoch: 6 [10240/38438 (26%)]\tLoss: 0.525174\n",
      "Train Epoch: 6 [12800/38438 (33%)]\tLoss: 0.555279\n",
      "Train Epoch: 6 [15360/38438 (40%)]\tLoss: 0.550247\n",
      "Train Epoch: 6 [17920/38438 (46%)]\tLoss: 0.508804\n",
      "Train Epoch: 6 [20480/38438 (53%)]\tLoss: 0.532158\n",
      "Train Epoch: 6 [23040/38438 (60%)]\tLoss: 0.557314\n",
      "Train Epoch: 6 [25600/38438 (66%)]\tLoss: 0.536458\n",
      "Train Epoch: 6 [28160/38438 (73%)]\tLoss: 0.526659\n",
      "Train Epoch: 6 [30720/38438 (79%)]\tLoss: 0.538210\n",
      "Train Epoch: 6 [33280/38438 (86%)]\tLoss: 0.614332\n",
      "Train Epoch: 6 [35840/38438 (93%)]\tLoss: 0.489141\n",
      "Train Epoch: 6 [5700/38438 (99%)]\tLoss: 0.555213\n",
      "\n",
      "Test set: Average loss: 0.5194, Accuracy: 5275/6784 (77%)\n",
      "\n",
      "Train Epoch: 7 [0/38438 (0%)]\tLoss: 0.576014\n",
      "Train Epoch: 7 [2560/38438 (7%)]\tLoss: 0.571691\n",
      "Train Epoch: 7 [5120/38438 (13%)]\tLoss: 0.548563\n",
      "Train Epoch: 7 [7680/38438 (20%)]\tLoss: 0.505508\n",
      "Train Epoch: 7 [10240/38438 (26%)]\tLoss: 0.534175\n",
      "Train Epoch: 7 [12800/38438 (33%)]\tLoss: 0.520717\n",
      "Train Epoch: 7 [15360/38438 (40%)]\tLoss: 0.557913\n",
      "Train Epoch: 7 [17920/38438 (46%)]\tLoss: 0.547145\n",
      "Train Epoch: 7 [20480/38438 (53%)]\tLoss: 0.498124\n",
      "Train Epoch: 7 [23040/38438 (60%)]\tLoss: 0.545685\n",
      "Train Epoch: 7 [25600/38438 (66%)]\tLoss: 0.544131\n",
      "Train Epoch: 7 [28160/38438 (73%)]\tLoss: 0.500460\n",
      "Train Epoch: 7 [30720/38438 (79%)]\tLoss: 0.496423\n",
      "Train Epoch: 7 [33280/38438 (86%)]\tLoss: 0.549404\n",
      "Train Epoch: 7 [35840/38438 (93%)]\tLoss: 0.489960\n",
      "Train Epoch: 7 [5700/38438 (99%)]\tLoss: 0.609401\n",
      "\n",
      "Test set: Average loss: 0.5135, Accuracy: 5274/6784 (77%)\n",
      "\n",
      "Train Epoch: 8 [0/38438 (0%)]\tLoss: 0.484847\n",
      "Train Epoch: 8 [2560/38438 (7%)]\tLoss: 0.514391\n",
      "Train Epoch: 8 [5120/38438 (13%)]\tLoss: 0.557800\n",
      "Train Epoch: 8 [7680/38438 (20%)]\tLoss: 0.557999\n",
      "Train Epoch: 8 [10240/38438 (26%)]\tLoss: 0.512201\n",
      "Train Epoch: 8 [12800/38438 (33%)]\tLoss: 0.557401\n",
      "Train Epoch: 8 [15360/38438 (40%)]\tLoss: 0.522654\n",
      "Train Epoch: 8 [17920/38438 (46%)]\tLoss: 0.505619\n",
      "Train Epoch: 8 [20480/38438 (53%)]\tLoss: 0.512979\n",
      "Train Epoch: 8 [23040/38438 (60%)]\tLoss: 0.548997\n",
      "Train Epoch: 8 [25600/38438 (66%)]\tLoss: 0.503547\n",
      "Train Epoch: 8 [28160/38438 (73%)]\tLoss: 0.535291\n",
      "Train Epoch: 8 [30720/38438 (79%)]\tLoss: 0.491291\n",
      "Train Epoch: 8 [33280/38438 (86%)]\tLoss: 0.562733\n",
      "Train Epoch: 8 [35840/38438 (93%)]\tLoss: 0.537943\n",
      "Train Epoch: 8 [5700/38438 (99%)]\tLoss: 0.440515\n",
      "\n",
      "Test set: Average loss: 0.5093, Accuracy: 5275/6784 (77%)\n",
      "\n",
      "Train Epoch: 9 [0/38438 (0%)]\tLoss: 0.561383\n",
      "Train Epoch: 9 [2560/38438 (7%)]\tLoss: 0.505330\n",
      "Train Epoch: 9 [5120/38438 (13%)]\tLoss: 0.531009\n",
      "Train Epoch: 9 [7680/38438 (20%)]\tLoss: 0.513993\n",
      "Train Epoch: 9 [10240/38438 (26%)]\tLoss: 0.466354\n",
      "Train Epoch: 9 [12800/38438 (33%)]\tLoss: 0.534467\n",
      "Train Epoch: 9 [15360/38438 (40%)]\tLoss: 0.498604\n",
      "Train Epoch: 9 [17920/38438 (46%)]\tLoss: 0.477755\n",
      "Train Epoch: 9 [20480/38438 (53%)]\tLoss: 0.491227\n",
      "Train Epoch: 9 [23040/38438 (60%)]\tLoss: 0.515873\n",
      "Train Epoch: 9 [25600/38438 (66%)]\tLoss: 0.509428\n",
      "Train Epoch: 9 [28160/38438 (73%)]\tLoss: 0.500520\n",
      "Train Epoch: 9 [30720/38438 (79%)]\tLoss: 0.495678\n",
      "Train Epoch: 9 [33280/38438 (86%)]\tLoss: 0.482667\n",
      "Train Epoch: 9 [35840/38438 (93%)]\tLoss: 0.504867\n",
      "Train Epoch: 9 [5700/38438 (99%)]\tLoss: 0.471442\n",
      "\n",
      "Test set: Average loss: 0.5042, Accuracy: 5269/6784 (77%)\n",
      "\n",
      "Train Epoch: 10 [0/38438 (0%)]\tLoss: 0.492066\n",
      "Train Epoch: 10 [2560/38438 (7%)]\tLoss: 0.543352\n",
      "Train Epoch: 10 [5120/38438 (13%)]\tLoss: 0.513646\n",
      "Train Epoch: 10 [7680/38438 (20%)]\tLoss: 0.551964\n",
      "Train Epoch: 10 [10240/38438 (26%)]\tLoss: 0.496359\n",
      "Train Epoch: 10 [12800/38438 (33%)]\tLoss: 0.514716\n",
      "Train Epoch: 10 [15360/38438 (40%)]\tLoss: 0.520013\n",
      "Train Epoch: 10 [17920/38438 (46%)]\tLoss: 0.503301\n",
      "Train Epoch: 10 [20480/38438 (53%)]\tLoss: 0.519725\n",
      "Train Epoch: 10 [23040/38438 (60%)]\tLoss: 0.457392\n",
      "Train Epoch: 10 [25600/38438 (66%)]\tLoss: 0.525280\n",
      "Train Epoch: 10 [28160/38438 (73%)]\tLoss: 0.484838\n",
      "Train Epoch: 10 [30720/38438 (79%)]\tLoss: 0.486665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [33280/38438 (86%)]\tLoss: 0.495876\n",
      "Train Epoch: 10 [35840/38438 (93%)]\tLoss: 0.468283\n",
      "Train Epoch: 10 [5700/38438 (99%)]\tLoss: 0.556391\n",
      "\n",
      "Test set: Average loss: 0.4966, Accuracy: 5263/6784 (77%)\n",
      "\n",
      "Train Epoch: 11 [0/38438 (0%)]\tLoss: 0.487889\n",
      "Train Epoch: 11 [2560/38438 (7%)]\tLoss: 0.511873\n",
      "Train Epoch: 11 [5120/38438 (13%)]\tLoss: 0.501824\n",
      "Train Epoch: 11 [7680/38438 (20%)]\tLoss: 0.492425\n",
      "Train Epoch: 11 [10240/38438 (26%)]\tLoss: 0.527978\n",
      "Train Epoch: 11 [12800/38438 (33%)]\tLoss: 0.529602\n",
      "Train Epoch: 11 [15360/38438 (40%)]\tLoss: 0.499598\n",
      "Train Epoch: 11 [17920/38438 (46%)]\tLoss: 0.526091\n",
      "Train Epoch: 11 [20480/38438 (53%)]\tLoss: 0.484086\n",
      "Train Epoch: 11 [23040/38438 (60%)]\tLoss: 0.520601\n",
      "Train Epoch: 11 [25600/38438 (66%)]\tLoss: 0.514094\n",
      "Train Epoch: 11 [28160/38438 (73%)]\tLoss: 0.508636\n",
      "Train Epoch: 11 [30720/38438 (79%)]\tLoss: 0.538380\n",
      "Train Epoch: 11 [33280/38438 (86%)]\tLoss: 0.538152\n",
      "Train Epoch: 11 [35840/38438 (93%)]\tLoss: 0.518066\n",
      "Train Epoch: 11 [5700/38438 (99%)]\tLoss: 0.399498\n",
      "\n",
      "Test set: Average loss: 0.4910, Accuracy: 5286/6784 (77%)\n",
      "\n",
      "Train Epoch: 12 [0/38438 (0%)]\tLoss: 0.511937\n",
      "Train Epoch: 12 [2560/38438 (7%)]\tLoss: 0.506117\n",
      "Train Epoch: 12 [5120/38438 (13%)]\tLoss: 0.560838\n",
      "Train Epoch: 12 [7680/38438 (20%)]\tLoss: 0.530733\n",
      "Train Epoch: 12 [10240/38438 (26%)]\tLoss: 0.502208\n",
      "Train Epoch: 12 [12800/38438 (33%)]\tLoss: 0.560728\n",
      "Train Epoch: 12 [15360/38438 (40%)]\tLoss: 0.512798\n",
      "Train Epoch: 12 [17920/38438 (46%)]\tLoss: 0.495712\n",
      "Train Epoch: 12 [20480/38438 (53%)]\tLoss: 0.510809\n",
      "Train Epoch: 12 [23040/38438 (60%)]\tLoss: 0.510174\n",
      "Train Epoch: 12 [25600/38438 (66%)]\tLoss: 0.498022\n",
      "Train Epoch: 12 [28160/38438 (73%)]\tLoss: 0.511847\n",
      "Train Epoch: 12 [30720/38438 (79%)]\tLoss: 0.508380\n",
      "Train Epoch: 12 [33280/38438 (86%)]\tLoss: 0.492664\n",
      "Train Epoch: 12 [35840/38438 (93%)]\tLoss: 0.548180\n",
      "Train Epoch: 12 [5700/38438 (99%)]\tLoss: 0.352123\n",
      "\n",
      "Test set: Average loss: 0.4829, Accuracy: 5289/6784 (77%)\n",
      "\n",
      "Train Epoch: 13 [0/38438 (0%)]\tLoss: 0.551535\n",
      "Train Epoch: 13 [2560/38438 (7%)]\tLoss: 0.519505\n",
      "Train Epoch: 13 [5120/38438 (13%)]\tLoss: 0.469562\n",
      "Train Epoch: 13 [7680/38438 (20%)]\tLoss: 0.490711\n",
      "Train Epoch: 13 [10240/38438 (26%)]\tLoss: 0.530973\n",
      "Train Epoch: 13 [12800/38438 (33%)]\tLoss: 0.472673\n",
      "Train Epoch: 13 [15360/38438 (40%)]\tLoss: 0.462752\n",
      "Train Epoch: 13 [17920/38438 (46%)]\tLoss: 0.526760\n",
      "Train Epoch: 13 [20480/38438 (53%)]\tLoss: 0.462485\n",
      "Train Epoch: 13 [23040/38438 (60%)]\tLoss: 0.467963\n",
      "Train Epoch: 13 [25600/38438 (66%)]\tLoss: 0.498012\n",
      "Train Epoch: 13 [28160/38438 (73%)]\tLoss: 0.537254\n",
      "Train Epoch: 13 [30720/38438 (79%)]\tLoss: 0.490815\n",
      "Train Epoch: 13 [33280/38438 (86%)]\tLoss: 0.542515\n",
      "Train Epoch: 13 [35840/38438 (93%)]\tLoss: 0.490299\n",
      "Train Epoch: 13 [5700/38438 (99%)]\tLoss: 0.550160\n",
      "\n",
      "Test set: Average loss: 0.4764, Accuracy: 5306/6784 (78%)\n",
      "\n",
      "Train Epoch: 14 [0/38438 (0%)]\tLoss: 0.483709\n",
      "Train Epoch: 14 [2560/38438 (7%)]\tLoss: 0.425195\n",
      "Train Epoch: 14 [5120/38438 (13%)]\tLoss: 0.544657\n",
      "Train Epoch: 14 [7680/38438 (20%)]\tLoss: 0.504985\n",
      "Train Epoch: 14 [10240/38438 (26%)]\tLoss: 0.420378\n",
      "Train Epoch: 14 [12800/38438 (33%)]\tLoss: 0.511982\n",
      "Train Epoch: 14 [15360/38438 (40%)]\tLoss: 0.462533\n",
      "Train Epoch: 14 [17920/38438 (46%)]\tLoss: 0.502538\n",
      "Train Epoch: 14 [20480/38438 (53%)]\tLoss: 0.482608\n",
      "Train Epoch: 14 [23040/38438 (60%)]\tLoss: 0.445882\n",
      "Train Epoch: 14 [25600/38438 (66%)]\tLoss: 0.463176\n",
      "Train Epoch: 14 [28160/38438 (73%)]\tLoss: 0.525710\n",
      "Train Epoch: 14 [30720/38438 (79%)]\tLoss: 0.504501\n",
      "Train Epoch: 14 [33280/38438 (86%)]\tLoss: 0.476155\n",
      "Train Epoch: 14 [35840/38438 (93%)]\tLoss: 0.443209\n",
      "Train Epoch: 14 [5700/38438 (99%)]\tLoss: 0.357792\n",
      "\n",
      "Test set: Average loss: 0.4643, Accuracy: 5326/6784 (78%)\n",
      "\n",
      "Train Epoch: 15 [0/38438 (0%)]\tLoss: 0.485944\n",
      "Train Epoch: 15 [2560/38438 (7%)]\tLoss: 0.445739\n",
      "Train Epoch: 15 [5120/38438 (13%)]\tLoss: 0.498145\n",
      "Train Epoch: 15 [7680/38438 (20%)]\tLoss: 0.464085\n",
      "Train Epoch: 15 [10240/38438 (26%)]\tLoss: 0.503227\n",
      "Train Epoch: 15 [12800/38438 (33%)]\tLoss: 0.468058\n",
      "Train Epoch: 15 [15360/38438 (40%)]\tLoss: 0.510581\n",
      "Train Epoch: 15 [17920/38438 (46%)]\tLoss: 0.463151\n",
      "Train Epoch: 15 [20480/38438 (53%)]\tLoss: 0.533886\n",
      "Train Epoch: 15 [23040/38438 (60%)]\tLoss: 0.429598\n",
      "Train Epoch: 15 [25600/38438 (66%)]\tLoss: 0.482476\n",
      "Train Epoch: 15 [28160/38438 (73%)]\tLoss: 0.425086\n",
      "Train Epoch: 15 [30720/38438 (79%)]\tLoss: 0.473882\n",
      "Train Epoch: 15 [33280/38438 (86%)]\tLoss: 0.432673\n",
      "Train Epoch: 15 [35840/38438 (93%)]\tLoss: 0.506638\n",
      "Train Epoch: 15 [5700/38438 (99%)]\tLoss: 0.436577\n",
      "\n",
      "Test set: Average loss: 0.4505, Accuracy: 5315/6784 (78%)\n",
      "\n",
      "Train Epoch: 16 [0/38438 (0%)]\tLoss: 0.441404\n",
      "Train Epoch: 16 [2560/38438 (7%)]\tLoss: 0.531434\n",
      "Train Epoch: 16 [5120/38438 (13%)]\tLoss: 0.500805\n",
      "Train Epoch: 16 [7680/38438 (20%)]\tLoss: 0.484780\n",
      "Train Epoch: 16 [10240/38438 (26%)]\tLoss: 0.439654\n",
      "Train Epoch: 16 [12800/38438 (33%)]\tLoss: 0.439201\n",
      "Train Epoch: 16 [15360/38438 (40%)]\tLoss: 0.430026\n",
      "Train Epoch: 16 [17920/38438 (46%)]\tLoss: 0.470205\n",
      "Train Epoch: 16 [20480/38438 (53%)]\tLoss: 0.462053\n",
      "Train Epoch: 16 [23040/38438 (60%)]\tLoss: 0.485931\n",
      "Train Epoch: 16 [25600/38438 (66%)]\tLoss: 0.444162\n",
      "Train Epoch: 16 [28160/38438 (73%)]\tLoss: 0.426508\n",
      "Train Epoch: 16 [30720/38438 (79%)]\tLoss: 0.448452\n",
      "Train Epoch: 16 [33280/38438 (86%)]\tLoss: 0.428317\n",
      "Train Epoch: 16 [35840/38438 (93%)]\tLoss: 0.435664\n",
      "Train Epoch: 16 [5700/38438 (99%)]\tLoss: 0.514646\n",
      "\n",
      "Test set: Average loss: 0.4365, Accuracy: 5348/6784 (78%)\n",
      "\n",
      "Train Epoch: 17 [0/38438 (0%)]\tLoss: 0.460772\n",
      "Train Epoch: 17 [2560/38438 (7%)]\tLoss: 0.479865\n",
      "Train Epoch: 17 [5120/38438 (13%)]\tLoss: 0.412036\n",
      "Train Epoch: 17 [7680/38438 (20%)]\tLoss: 0.467351\n",
      "Train Epoch: 17 [10240/38438 (26%)]\tLoss: 0.458649\n",
      "Train Epoch: 17 [12800/38438 (33%)]\tLoss: 0.467024\n",
      "Train Epoch: 17 [15360/38438 (40%)]\tLoss: 0.448856\n",
      "Train Epoch: 17 [17920/38438 (46%)]\tLoss: 0.468706\n",
      "Train Epoch: 17 [20480/38438 (53%)]\tLoss: 0.447553\n",
      "Train Epoch: 17 [23040/38438 (60%)]\tLoss: 0.425338\n",
      "Train Epoch: 17 [25600/38438 (66%)]\tLoss: 0.428845\n",
      "Train Epoch: 17 [28160/38438 (73%)]\tLoss: 0.459460\n",
      "Train Epoch: 17 [30720/38438 (79%)]\tLoss: 0.428689\n",
      "Train Epoch: 17 [33280/38438 (86%)]\tLoss: 0.445113\n",
      "Train Epoch: 17 [35840/38438 (93%)]\tLoss: 0.429329\n",
      "Train Epoch: 17 [5700/38438 (99%)]\tLoss: 0.513072\n",
      "\n",
      "Test set: Average loss: 0.4234, Accuracy: 5373/6784 (79%)\n",
      "\n",
      "Train Epoch: 18 [0/38438 (0%)]\tLoss: 0.438191\n",
      "Train Epoch: 18 [2560/38438 (7%)]\tLoss: 0.392283\n",
      "Train Epoch: 18 [5120/38438 (13%)]\tLoss: 0.443252\n",
      "Train Epoch: 18 [7680/38438 (20%)]\tLoss: 0.511796\n",
      "Train Epoch: 18 [10240/38438 (26%)]\tLoss: 0.399308\n",
      "Train Epoch: 18 [12800/38438 (33%)]\tLoss: 0.444343\n",
      "Train Epoch: 18 [15360/38438 (40%)]\tLoss: 0.482996\n",
      "Train Epoch: 18 [17920/38438 (46%)]\tLoss: 0.460850\n",
      "Train Epoch: 18 [20480/38438 (53%)]\tLoss: 0.474223\n",
      "Train Epoch: 18 [23040/38438 (60%)]\tLoss: 0.447388\n",
      "Train Epoch: 18 [25600/38438 (66%)]\tLoss: 0.411826\n",
      "Train Epoch: 18 [28160/38438 (73%)]\tLoss: 0.445618\n",
      "Train Epoch: 18 [30720/38438 (79%)]\tLoss: 0.438912\n",
      "Train Epoch: 18 [33280/38438 (86%)]\tLoss: 0.434559\n",
      "Train Epoch: 18 [35840/38438 (93%)]\tLoss: 0.401453\n",
      "Train Epoch: 18 [5700/38438 (99%)]\tLoss: 0.444004\n",
      "\n",
      "Test set: Average loss: 0.4086, Accuracy: 5511/6784 (81%)\n",
      "\n",
      "Train Epoch: 19 [0/38438 (0%)]\tLoss: 0.432992\n",
      "Train Epoch: 19 [2560/38438 (7%)]\tLoss: 0.425186\n",
      "Train Epoch: 19 [5120/38438 (13%)]\tLoss: 0.416894\n",
      "Train Epoch: 19 [7680/38438 (20%)]\tLoss: 0.512212\n",
      "Train Epoch: 19 [10240/38438 (26%)]\tLoss: 0.397565\n",
      "Train Epoch: 19 [12800/38438 (33%)]\tLoss: 0.432140\n",
      "Train Epoch: 19 [15360/38438 (40%)]\tLoss: 0.438233\n",
      "Train Epoch: 19 [17920/38438 (46%)]\tLoss: 0.453354\n",
      "Train Epoch: 19 [20480/38438 (53%)]\tLoss: 0.400060\n",
      "Train Epoch: 19 [23040/38438 (60%)]\tLoss: 0.431188\n",
      "Train Epoch: 19 [25600/38438 (66%)]\tLoss: 0.382474\n",
      "Train Epoch: 19 [28160/38438 (73%)]\tLoss: 0.388292\n",
      "Train Epoch: 19 [30720/38438 (79%)]\tLoss: 0.395471\n",
      "Train Epoch: 19 [33280/38438 (86%)]\tLoss: 0.358975\n",
      "Train Epoch: 19 [35840/38438 (93%)]\tLoss: 0.420005\n",
      "Train Epoch: 19 [5700/38438 (99%)]\tLoss: 0.446449\n",
      "\n",
      "Test set: Average loss: 0.3965, Accuracy: 5556/6784 (81%)\n",
      "\n",
      "Train Epoch: 20 [0/38438 (0%)]\tLoss: 0.411942\n",
      "Train Epoch: 20 [2560/38438 (7%)]\tLoss: 0.426516\n",
      "Train Epoch: 20 [5120/38438 (13%)]\tLoss: 0.438091\n",
      "Train Epoch: 20 [7680/38438 (20%)]\tLoss: 0.360646\n",
      "Train Epoch: 20 [10240/38438 (26%)]\tLoss: 0.426366\n",
      "Train Epoch: 20 [12800/38438 (33%)]\tLoss: 0.375734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20 [15360/38438 (40%)]\tLoss: 0.443870\n",
      "Train Epoch: 20 [17920/38438 (46%)]\tLoss: 0.410905\n",
      "Train Epoch: 20 [20480/38438 (53%)]\tLoss: 0.490082\n",
      "Train Epoch: 20 [23040/38438 (60%)]\tLoss: 0.444657\n",
      "Train Epoch: 20 [25600/38438 (66%)]\tLoss: 0.376187\n",
      "Train Epoch: 20 [28160/38438 (73%)]\tLoss: 0.422325\n",
      "Train Epoch: 20 [30720/38438 (79%)]\tLoss: 0.431807\n",
      "Train Epoch: 20 [33280/38438 (86%)]\tLoss: 0.434312\n",
      "Train Epoch: 20 [35840/38438 (93%)]\tLoss: 0.430517\n",
      "Train Epoch: 20 [5700/38438 (99%)]\tLoss: 0.429172\n",
      "\n",
      "Test set: Average loss: 0.3909, Accuracy: 5599/6784 (82%)\n",
      "\n",
      "Train Epoch: 21 [0/38438 (0%)]\tLoss: 0.390511\n",
      "Train Epoch: 21 [2560/38438 (7%)]\tLoss: 0.424740\n",
      "Train Epoch: 21 [5120/38438 (13%)]\tLoss: 0.507446\n",
      "Train Epoch: 21 [7680/38438 (20%)]\tLoss: 0.420381\n",
      "Train Epoch: 21 [10240/38438 (26%)]\tLoss: 0.320159\n",
      "Train Epoch: 21 [12800/38438 (33%)]\tLoss: 0.373794\n",
      "Train Epoch: 21 [15360/38438 (40%)]\tLoss: 0.396464\n",
      "Train Epoch: 21 [17920/38438 (46%)]\tLoss: 0.430644\n",
      "Train Epoch: 21 [20480/38438 (53%)]\tLoss: 0.429208\n",
      "Train Epoch: 21 [23040/38438 (60%)]\tLoss: 0.332369\n",
      "Train Epoch: 21 [25600/38438 (66%)]\tLoss: 0.409310\n",
      "Train Epoch: 21 [28160/38438 (73%)]\tLoss: 0.427748\n",
      "Train Epoch: 21 [30720/38438 (79%)]\tLoss: 0.408266\n",
      "Train Epoch: 21 [33280/38438 (86%)]\tLoss: 0.389475\n",
      "Train Epoch: 21 [35840/38438 (93%)]\tLoss: 0.387362\n",
      "Train Epoch: 21 [5700/38438 (99%)]\tLoss: 0.287075\n",
      "\n",
      "Test set: Average loss: 0.3939, Accuracy: 5557/6784 (81%)\n",
      "\n",
      "Train Epoch: 22 [0/38438 (0%)]\tLoss: 0.449522\n",
      "Train Epoch: 22 [2560/38438 (7%)]\tLoss: 0.408776\n",
      "Train Epoch: 22 [5120/38438 (13%)]\tLoss: 0.426799\n",
      "Train Epoch: 22 [7680/38438 (20%)]\tLoss: 0.410232\n",
      "Train Epoch: 22 [10240/38438 (26%)]\tLoss: 0.418011\n",
      "Train Epoch: 22 [12800/38438 (33%)]\tLoss: 0.402232\n",
      "Train Epoch: 22 [15360/38438 (40%)]\tLoss: 0.439089\n",
      "Train Epoch: 22 [17920/38438 (46%)]\tLoss: 0.330652\n",
      "Train Epoch: 22 [20480/38438 (53%)]\tLoss: 0.429161\n",
      "Train Epoch: 22 [23040/38438 (60%)]\tLoss: 0.381366\n",
      "Train Epoch: 22 [25600/38438 (66%)]\tLoss: 0.392154\n",
      "Train Epoch: 22 [28160/38438 (73%)]\tLoss: 0.398057\n",
      "Train Epoch: 22 [30720/38438 (79%)]\tLoss: 0.452687\n",
      "Train Epoch: 22 [33280/38438 (86%)]\tLoss: 0.412748\n",
      "Train Epoch: 22 [35840/38438 (93%)]\tLoss: 0.427212\n",
      "Train Epoch: 22 [5700/38438 (99%)]\tLoss: 0.330754\n",
      "\n",
      "Test set: Average loss: 0.3786, Accuracy: 5631/6784 (83%)\n",
      "\n",
      "Train Epoch: 23 [0/38438 (0%)]\tLoss: 0.421101\n",
      "Train Epoch: 23 [2560/38438 (7%)]\tLoss: 0.391383\n",
      "Train Epoch: 23 [5120/38438 (13%)]\tLoss: 0.379024\n",
      "Train Epoch: 23 [7680/38438 (20%)]\tLoss: 0.431797\n",
      "Train Epoch: 23 [10240/38438 (26%)]\tLoss: 0.415685\n",
      "Train Epoch: 23 [12800/38438 (33%)]\tLoss: 0.385958\n",
      "Train Epoch: 23 [15360/38438 (40%)]\tLoss: 0.373591\n",
      "Train Epoch: 23 [17920/38438 (46%)]\tLoss: 0.403349\n",
      "Train Epoch: 23 [20480/38438 (53%)]\tLoss: 0.415694\n",
      "Train Epoch: 23 [23040/38438 (60%)]\tLoss: 0.398787\n",
      "Train Epoch: 23 [25600/38438 (66%)]\tLoss: 0.420512\n",
      "Train Epoch: 23 [28160/38438 (73%)]\tLoss: 0.388958\n",
      "Train Epoch: 23 [30720/38438 (79%)]\tLoss: 0.434093\n",
      "Train Epoch: 23 [33280/38438 (86%)]\tLoss: 0.417496\n",
      "Train Epoch: 23 [35840/38438 (93%)]\tLoss: 0.443205\n",
      "Train Epoch: 23 [5700/38438 (99%)]\tLoss: 0.553702\n",
      "\n",
      "Test set: Average loss: 0.4056, Accuracy: 5545/6784 (81%)\n",
      "\n",
      "Train Epoch: 24 [0/38438 (0%)]\tLoss: 0.427729\n",
      "Train Epoch: 24 [2560/38438 (7%)]\tLoss: 0.415678\n",
      "Train Epoch: 24 [5120/38438 (13%)]\tLoss: 0.348225\n",
      "Train Epoch: 24 [7680/38438 (20%)]\tLoss: 0.423842\n",
      "Train Epoch: 24 [10240/38438 (26%)]\tLoss: 0.356276\n",
      "Train Epoch: 24 [12800/38438 (33%)]\tLoss: 0.477899\n",
      "Train Epoch: 24 [15360/38438 (40%)]\tLoss: 0.391370\n",
      "Train Epoch: 24 [17920/38438 (46%)]\tLoss: 0.449132\n",
      "Train Epoch: 24 [20480/38438 (53%)]\tLoss: 0.422147\n",
      "Train Epoch: 24 [23040/38438 (60%)]\tLoss: 0.430848\n",
      "Train Epoch: 24 [25600/38438 (66%)]\tLoss: 0.458621\n",
      "Train Epoch: 24 [28160/38438 (73%)]\tLoss: 0.426850\n",
      "Train Epoch: 24 [30720/38438 (79%)]\tLoss: 0.429718\n",
      "Train Epoch: 24 [33280/38438 (86%)]\tLoss: 0.423185\n",
      "Train Epoch: 24 [35840/38438 (93%)]\tLoss: 0.377645\n",
      "Train Epoch: 24 [5700/38438 (99%)]\tLoss: 0.508711\n",
      "\n",
      "Test set: Average loss: 0.4049, Accuracy: 5538/6784 (81%)\n",
      "\n",
      "Train Epoch: 25 [0/38438 (0%)]\tLoss: 0.439835\n",
      "Train Epoch: 25 [2560/38438 (7%)]\tLoss: 0.387647\n",
      "Train Epoch: 25 [5120/38438 (13%)]\tLoss: 0.388740\n",
      "Train Epoch: 25 [7680/38438 (20%)]\tLoss: 0.344393\n",
      "Train Epoch: 25 [10240/38438 (26%)]\tLoss: 0.385877\n",
      "Train Epoch: 25 [12800/38438 (33%)]\tLoss: 0.386781\n",
      "Train Epoch: 25 [15360/38438 (40%)]\tLoss: 0.375086\n",
      "Train Epoch: 25 [17920/38438 (46%)]\tLoss: 0.428888\n",
      "Train Epoch: 25 [20480/38438 (53%)]\tLoss: 0.390390\n",
      "Train Epoch: 25 [23040/38438 (60%)]\tLoss: 0.399180\n",
      "Train Epoch: 25 [25600/38438 (66%)]\tLoss: 0.429720\n",
      "Train Epoch: 25 [28160/38438 (73%)]\tLoss: 0.399077\n",
      "Train Epoch: 25 [30720/38438 (79%)]\tLoss: 0.414367\n",
      "Train Epoch: 25 [33280/38438 (86%)]\tLoss: 0.401388\n",
      "Train Epoch: 25 [35840/38438 (93%)]\tLoss: 0.394569\n",
      "Train Epoch: 25 [5700/38438 (99%)]\tLoss: 0.320914\n",
      "\n",
      "Test set: Average loss: 0.3741, Accuracy: 5647/6784 (83%)\n",
      "\n",
      "Train Epoch: 26 [0/38438 (0%)]\tLoss: 0.447148\n",
      "Train Epoch: 26 [2560/38438 (7%)]\tLoss: 0.395854\n",
      "Train Epoch: 26 [5120/38438 (13%)]\tLoss: 0.372055\n",
      "Train Epoch: 26 [7680/38438 (20%)]\tLoss: 0.388992\n",
      "Train Epoch: 26 [10240/38438 (26%)]\tLoss: 0.393150\n",
      "Train Epoch: 26 [12800/38438 (33%)]\tLoss: 0.399687\n",
      "Train Epoch: 26 [15360/38438 (40%)]\tLoss: 0.394135\n",
      "Train Epoch: 26 [17920/38438 (46%)]\tLoss: 0.359922\n",
      "Train Epoch: 26 [20480/38438 (53%)]\tLoss: 0.398150\n",
      "Train Epoch: 26 [23040/38438 (60%)]\tLoss: 0.467787\n",
      "Train Epoch: 26 [25600/38438 (66%)]\tLoss: 0.348903\n",
      "Train Epoch: 26 [28160/38438 (73%)]\tLoss: 0.360343\n",
      "Train Epoch: 26 [30720/38438 (79%)]\tLoss: 0.415187\n",
      "Train Epoch: 26 [33280/38438 (86%)]\tLoss: 0.409567\n",
      "Train Epoch: 26 [35840/38438 (93%)]\tLoss: 0.402724\n",
      "Train Epoch: 26 [5700/38438 (99%)]\tLoss: 0.358011\n",
      "\n",
      "Test set: Average loss: 0.3730, Accuracy: 5634/6784 (83%)\n",
      "\n",
      "Train Epoch: 27 [0/38438 (0%)]\tLoss: 0.435376\n",
      "Train Epoch: 27 [2560/38438 (7%)]\tLoss: 0.433299\n",
      "Train Epoch: 27 [5120/38438 (13%)]\tLoss: 0.394552\n",
      "Train Epoch: 27 [7680/38438 (20%)]\tLoss: 0.411848\n",
      "Train Epoch: 27 [10240/38438 (26%)]\tLoss: 0.375519\n",
      "Train Epoch: 27 [12800/38438 (33%)]\tLoss: 0.410311\n",
      "Train Epoch: 27 [15360/38438 (40%)]\tLoss: 0.406720\n",
      "Train Epoch: 27 [17920/38438 (46%)]\tLoss: 0.438433\n",
      "Train Epoch: 27 [20480/38438 (53%)]\tLoss: 0.375915\n",
      "Train Epoch: 27 [23040/38438 (60%)]\tLoss: 0.393400\n",
      "Train Epoch: 27 [25600/38438 (66%)]\tLoss: 0.398733\n",
      "Train Epoch: 27 [28160/38438 (73%)]\tLoss: 0.416003\n",
      "Train Epoch: 27 [30720/38438 (79%)]\tLoss: 0.398706\n",
      "Train Epoch: 27 [33280/38438 (86%)]\tLoss: 0.374654\n",
      "Train Epoch: 27 [35840/38438 (93%)]\tLoss: 0.379759\n",
      "Train Epoch: 27 [5700/38438 (99%)]\tLoss: 0.594545\n",
      "\n",
      "Test set: Average loss: 0.3763, Accuracy: 5665/6784 (83%)\n",
      "\n",
      "Train Epoch: 28 [0/38438 (0%)]\tLoss: 0.390095\n",
      "Train Epoch: 28 [2560/38438 (7%)]\tLoss: 0.370429\n",
      "Train Epoch: 28 [5120/38438 (13%)]\tLoss: 0.411618\n",
      "Train Epoch: 28 [7680/38438 (20%)]\tLoss: 0.432722\n",
      "Train Epoch: 28 [10240/38438 (26%)]\tLoss: 0.357633\n",
      "Train Epoch: 28 [12800/38438 (33%)]\tLoss: 0.425832\n",
      "Train Epoch: 28 [15360/38438 (40%)]\tLoss: 0.424327\n",
      "Train Epoch: 28 [17920/38438 (46%)]\tLoss: 0.380919\n",
      "Train Epoch: 28 [20480/38438 (53%)]\tLoss: 0.362846\n",
      "Train Epoch: 28 [23040/38438 (60%)]\tLoss: 0.366375\n",
      "Train Epoch: 28 [25600/38438 (66%)]\tLoss: 0.370855\n",
      "Train Epoch: 28 [28160/38438 (73%)]\tLoss: 0.415899\n",
      "Train Epoch: 28 [30720/38438 (79%)]\tLoss: 0.446971\n",
      "Train Epoch: 28 [33280/38438 (86%)]\tLoss: 0.448193\n",
      "Train Epoch: 28 [35840/38438 (93%)]\tLoss: 0.293547\n",
      "Train Epoch: 28 [5700/38438 (99%)]\tLoss: 0.414896\n",
      "\n",
      "Test set: Average loss: 0.3651, Accuracy: 5677/6784 (83%)\n",
      "\n",
      "Train Epoch: 29 [0/38438 (0%)]\tLoss: 0.411443\n",
      "Train Epoch: 29 [2560/38438 (7%)]\tLoss: 0.368872\n",
      "Train Epoch: 29 [5120/38438 (13%)]\tLoss: 0.408826\n",
      "Train Epoch: 29 [7680/38438 (20%)]\tLoss: 0.372294\n",
      "Train Epoch: 29 [10240/38438 (26%)]\tLoss: 0.296484\n",
      "Train Epoch: 29 [12800/38438 (33%)]\tLoss: 0.384071\n",
      "Train Epoch: 29 [15360/38438 (40%)]\tLoss: 0.354837\n",
      "Train Epoch: 29 [17920/38438 (46%)]\tLoss: 0.424374\n",
      "Train Epoch: 29 [20480/38438 (53%)]\tLoss: 0.388645\n",
      "Train Epoch: 29 [23040/38438 (60%)]\tLoss: 0.403111\n",
      "Train Epoch: 29 [25600/38438 (66%)]\tLoss: 0.387784\n",
      "Train Epoch: 29 [28160/38438 (73%)]\tLoss: 0.418011\n",
      "Train Epoch: 29 [30720/38438 (79%)]\tLoss: 0.348968\n",
      "Train Epoch: 29 [33280/38438 (86%)]\tLoss: 0.405605\n",
      "Train Epoch: 29 [35840/38438 (93%)]\tLoss: 0.369933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 29 [5700/38438 (99%)]\tLoss: 0.362574\n",
      "\n",
      "Test set: Average loss: 0.3696, Accuracy: 5653/6784 (83%)\n",
      "\n",
      "Train Epoch: 30 [0/38438 (0%)]\tLoss: 0.404531\n",
      "Train Epoch: 30 [2560/38438 (7%)]\tLoss: 0.378681\n",
      "Train Epoch: 30 [5120/38438 (13%)]\tLoss: 0.425880\n",
      "Train Epoch: 30 [7680/38438 (20%)]\tLoss: 0.422611\n",
      "Train Epoch: 30 [10240/38438 (26%)]\tLoss: 0.371961\n",
      "Train Epoch: 30 [12800/38438 (33%)]\tLoss: 0.428585\n",
      "Train Epoch: 30 [15360/38438 (40%)]\tLoss: 0.374798\n",
      "Train Epoch: 30 [17920/38438 (46%)]\tLoss: 0.433915\n",
      "Train Epoch: 30 [20480/38438 (53%)]\tLoss: 0.362109\n",
      "Train Epoch: 30 [23040/38438 (60%)]\tLoss: 0.417547\n",
      "Train Epoch: 30 [25600/38438 (66%)]\tLoss: 0.410114\n",
      "Train Epoch: 30 [28160/38438 (73%)]\tLoss: 0.412637\n",
      "Train Epoch: 30 [30720/38438 (79%)]\tLoss: 0.382492\n",
      "Train Epoch: 30 [33280/38438 (86%)]\tLoss: 0.369602\n",
      "Train Epoch: 30 [35840/38438 (93%)]\tLoss: 0.403172\n",
      "Train Epoch: 30 [5700/38438 (99%)]\tLoss: 0.452808\n",
      "\n",
      "Test set: Average loss: 0.3717, Accuracy: 5595/6784 (82%)\n",
      "\n",
      "Train Epoch: 31 [0/38438 (0%)]\tLoss: 0.395478\n",
      "Train Epoch: 31 [2560/38438 (7%)]\tLoss: 0.363715\n",
      "Train Epoch: 31 [5120/38438 (13%)]\tLoss: 0.435413\n",
      "Train Epoch: 31 [7680/38438 (20%)]\tLoss: 0.346009\n",
      "Train Epoch: 31 [10240/38438 (26%)]\tLoss: 0.369546\n",
      "Train Epoch: 31 [12800/38438 (33%)]\tLoss: 0.381279\n",
      "Train Epoch: 31 [15360/38438 (40%)]\tLoss: 0.425023\n",
      "Train Epoch: 31 [17920/38438 (46%)]\tLoss: 0.398589\n",
      "Train Epoch: 31 [20480/38438 (53%)]\tLoss: 0.422628\n",
      "Train Epoch: 31 [23040/38438 (60%)]\tLoss: 0.389006\n",
      "Train Epoch: 31 [25600/38438 (66%)]\tLoss: 0.371024\n",
      "Train Epoch: 31 [28160/38438 (73%)]\tLoss: 0.403029\n",
      "Train Epoch: 31 [30720/38438 (79%)]\tLoss: 0.340906\n",
      "Train Epoch: 31 [33280/38438 (86%)]\tLoss: 0.395904\n",
      "Train Epoch: 31 [35840/38438 (93%)]\tLoss: 0.384750\n",
      "Train Epoch: 31 [5700/38438 (99%)]\tLoss: 0.378171\n",
      "\n",
      "Test set: Average loss: 0.3645, Accuracy: 5689/6784 (83%)\n",
      "\n",
      "Train Epoch: 32 [0/38438 (0%)]\tLoss: 0.419001\n",
      "Train Epoch: 32 [2560/38438 (7%)]\tLoss: 0.345220\n",
      "Train Epoch: 32 [5120/38438 (13%)]\tLoss: 0.364156\n",
      "Train Epoch: 32 [7680/38438 (20%)]\tLoss: 0.403007\n",
      "Train Epoch: 32 [10240/38438 (26%)]\tLoss: 0.425427\n",
      "Train Epoch: 32 [12800/38438 (33%)]\tLoss: 0.422757\n",
      "Train Epoch: 32 [15360/38438 (40%)]\tLoss: 0.382415\n",
      "Train Epoch: 32 [17920/38438 (46%)]\tLoss: 0.491189\n",
      "Train Epoch: 32 [20480/38438 (53%)]\tLoss: 0.353490\n",
      "Train Epoch: 32 [23040/38438 (60%)]\tLoss: 0.385970\n",
      "Train Epoch: 32 [25600/38438 (66%)]\tLoss: 0.361594\n",
      "Train Epoch: 32 [28160/38438 (73%)]\tLoss: 0.422783\n",
      "Train Epoch: 32 [30720/38438 (79%)]\tLoss: 0.409736\n",
      "Train Epoch: 32 [33280/38438 (86%)]\tLoss: 0.362950\n",
      "Train Epoch: 32 [35840/38438 (93%)]\tLoss: 0.368116\n",
      "Train Epoch: 32 [5700/38438 (99%)]\tLoss: 0.297092\n",
      "\n",
      "Test set: Average loss: 0.3623, Accuracy: 5663/6784 (83%)\n",
      "\n",
      "Train Epoch: 33 [0/38438 (0%)]\tLoss: 0.436635\n",
      "Train Epoch: 33 [2560/38438 (7%)]\tLoss: 0.344026\n",
      "Train Epoch: 33 [5120/38438 (13%)]\tLoss: 0.389030\n",
      "Train Epoch: 33 [7680/38438 (20%)]\tLoss: 0.361242\n",
      "Train Epoch: 33 [10240/38438 (26%)]\tLoss: 0.386179\n",
      "Train Epoch: 33 [12800/38438 (33%)]\tLoss: 0.394055\n",
      "Train Epoch: 33 [15360/38438 (40%)]\tLoss: 0.345650\n",
      "Train Epoch: 33 [17920/38438 (46%)]\tLoss: 0.384960\n",
      "Train Epoch: 33 [20480/38438 (53%)]\tLoss: 0.391458\n",
      "Train Epoch: 33 [23040/38438 (60%)]\tLoss: 0.381964\n",
      "Train Epoch: 33 [25600/38438 (66%)]\tLoss: 0.382065\n",
      "Train Epoch: 33 [28160/38438 (73%)]\tLoss: 0.352649\n",
      "Train Epoch: 33 [30720/38438 (79%)]\tLoss: 0.389587\n",
      "Train Epoch: 33 [33280/38438 (86%)]\tLoss: 0.385405\n",
      "Train Epoch: 33 [35840/38438 (93%)]\tLoss: 0.386218\n",
      "Train Epoch: 33 [5700/38438 (99%)]\tLoss: 0.292456\n",
      "\n",
      "Test set: Average loss: 0.3681, Accuracy: 5615/6784 (82%)\n",
      "\n",
      "Train Epoch: 34 [0/38438 (0%)]\tLoss: 0.375509\n",
      "Train Epoch: 34 [2560/38438 (7%)]\tLoss: 0.315668\n",
      "Train Epoch: 34 [5120/38438 (13%)]\tLoss: 0.364786\n",
      "Train Epoch: 34 [7680/38438 (20%)]\tLoss: 0.389002\n",
      "Train Epoch: 34 [10240/38438 (26%)]\tLoss: 0.481940\n",
      "Train Epoch: 34 [12800/38438 (33%)]\tLoss: 0.379386\n",
      "Train Epoch: 34 [15360/38438 (40%)]\tLoss: 0.352911\n",
      "Train Epoch: 34 [17920/38438 (46%)]\tLoss: 0.355725\n",
      "Train Epoch: 34 [20480/38438 (53%)]\tLoss: 0.346588\n",
      "Train Epoch: 34 [23040/38438 (60%)]\tLoss: 0.419925\n",
      "Train Epoch: 34 [25600/38438 (66%)]\tLoss: 0.408953\n",
      "Train Epoch: 34 [28160/38438 (73%)]\tLoss: 0.372984\n",
      "Train Epoch: 34 [30720/38438 (79%)]\tLoss: 0.341757\n",
      "Train Epoch: 34 [33280/38438 (86%)]\tLoss: 0.310381\n",
      "Train Epoch: 34 [35840/38438 (93%)]\tLoss: 0.428706\n",
      "Train Epoch: 34 [5700/38438 (99%)]\tLoss: 0.313507\n",
      "\n",
      "Test set: Average loss: 0.3623, Accuracy: 5672/6784 (83%)\n",
      "\n",
      "Train Epoch: 35 [0/38438 (0%)]\tLoss: 0.381443\n",
      "Train Epoch: 35 [2560/38438 (7%)]\tLoss: 0.439684\n",
      "Train Epoch: 35 [5120/38438 (13%)]\tLoss: 0.362311\n",
      "Train Epoch: 35 [7680/38438 (20%)]\tLoss: 0.380179\n",
      "Train Epoch: 35 [10240/38438 (26%)]\tLoss: 0.389881\n",
      "Train Epoch: 35 [12800/38438 (33%)]\tLoss: 0.405235\n",
      "Train Epoch: 35 [15360/38438 (40%)]\tLoss: 0.470791\n",
      "Train Epoch: 35 [17920/38438 (46%)]\tLoss: 0.394158\n",
      "Train Epoch: 35 [20480/38438 (53%)]\tLoss: 0.384680\n",
      "Train Epoch: 35 [23040/38438 (60%)]\tLoss: 0.354139\n",
      "Train Epoch: 35 [25600/38438 (66%)]\tLoss: 0.319803\n",
      "Train Epoch: 35 [28160/38438 (73%)]\tLoss: 0.397661\n",
      "Train Epoch: 35 [30720/38438 (79%)]\tLoss: 0.383263\n",
      "Train Epoch: 35 [33280/38438 (86%)]\tLoss: 0.435675\n",
      "Train Epoch: 35 [35840/38438 (93%)]\tLoss: 0.381300\n",
      "Train Epoch: 35 [5700/38438 (99%)]\tLoss: 0.414970\n",
      "\n",
      "Test set: Average loss: 0.3633, Accuracy: 5659/6784 (83%)\n",
      "\n",
      "Train Epoch: 36 [0/38438 (0%)]\tLoss: 0.434041\n",
      "Train Epoch: 36 [2560/38438 (7%)]\tLoss: 0.307465\n",
      "Train Epoch: 36 [5120/38438 (13%)]\tLoss: 0.353290\n",
      "Train Epoch: 36 [7680/38438 (20%)]\tLoss: 0.374011\n",
      "Train Epoch: 36 [10240/38438 (26%)]\tLoss: 0.374355\n",
      "Train Epoch: 36 [12800/38438 (33%)]\tLoss: 0.383458\n",
      "Train Epoch: 36 [15360/38438 (40%)]\tLoss: 0.387790\n",
      "Train Epoch: 36 [17920/38438 (46%)]\tLoss: 0.358943\n",
      "Train Epoch: 36 [20480/38438 (53%)]\tLoss: 0.340759\n",
      "Train Epoch: 36 [23040/38438 (60%)]\tLoss: 0.378651\n",
      "Train Epoch: 36 [25600/38438 (66%)]\tLoss: 0.409494\n",
      "Train Epoch: 36 [28160/38438 (73%)]\tLoss: 0.413705\n",
      "Train Epoch: 36 [30720/38438 (79%)]\tLoss: 0.358067\n",
      "Train Epoch: 36 [33280/38438 (86%)]\tLoss: 0.393825\n",
      "Train Epoch: 36 [35840/38438 (93%)]\tLoss: 0.328972\n",
      "Train Epoch: 36 [5700/38438 (99%)]\tLoss: 0.296631\n",
      "\n",
      "Test set: Average loss: 0.3673, Accuracy: 5645/6784 (83%)\n",
      "\n",
      "Train Epoch: 37 [0/38438 (0%)]\tLoss: 0.441073\n",
      "Train Epoch: 37 [2560/38438 (7%)]\tLoss: 0.355856\n",
      "Train Epoch: 37 [5120/38438 (13%)]\tLoss: 0.381368\n",
      "Train Epoch: 37 [7680/38438 (20%)]\tLoss: 0.377115\n",
      "Train Epoch: 37 [10240/38438 (26%)]\tLoss: 0.384771\n",
      "Train Epoch: 37 [12800/38438 (33%)]\tLoss: 0.347106\n",
      "Train Epoch: 37 [15360/38438 (40%)]\tLoss: 0.359955\n",
      "Train Epoch: 37 [17920/38438 (46%)]\tLoss: 0.436249\n",
      "Train Epoch: 37 [20480/38438 (53%)]\tLoss: 0.388183\n",
      "Train Epoch: 37 [23040/38438 (60%)]\tLoss: 0.367581\n",
      "Train Epoch: 37 [25600/38438 (66%)]\tLoss: 0.372384\n",
      "Train Epoch: 37 [28160/38438 (73%)]\tLoss: 0.401055\n",
      "Train Epoch: 37 [30720/38438 (79%)]\tLoss: 0.374609\n",
      "Train Epoch: 37 [33280/38438 (86%)]\tLoss: 0.323885\n",
      "Train Epoch: 37 [35840/38438 (93%)]\tLoss: 0.378197\n",
      "Train Epoch: 37 [5700/38438 (99%)]\tLoss: 0.530017\n",
      "\n",
      "Test set: Average loss: 0.3576, Accuracy: 5668/6784 (83%)\n",
      "\n",
      "Train Epoch: 38 [0/38438 (0%)]\tLoss: 0.381429\n",
      "Train Epoch: 38 [2560/38438 (7%)]\tLoss: 0.385576\n",
      "Train Epoch: 38 [5120/38438 (13%)]\tLoss: 0.355419\n",
      "Train Epoch: 38 [7680/38438 (20%)]\tLoss: 0.360230\n",
      "Train Epoch: 38 [10240/38438 (26%)]\tLoss: 0.358540\n",
      "Train Epoch: 38 [12800/38438 (33%)]\tLoss: 0.326294\n",
      "Train Epoch: 38 [15360/38438 (40%)]\tLoss: 0.404804\n",
      "Train Epoch: 38 [17920/38438 (46%)]\tLoss: 0.425903\n",
      "Train Epoch: 38 [20480/38438 (53%)]\tLoss: 0.374138\n",
      "Train Epoch: 38 [23040/38438 (60%)]\tLoss: 0.380974\n",
      "Train Epoch: 38 [25600/38438 (66%)]\tLoss: 0.431812\n",
      "Train Epoch: 38 [28160/38438 (73%)]\tLoss: 0.377597\n",
      "Train Epoch: 38 [30720/38438 (79%)]\tLoss: 0.314598\n",
      "Train Epoch: 38 [33280/38438 (86%)]\tLoss: 0.464719\n",
      "Train Epoch: 38 [35840/38438 (93%)]\tLoss: 0.369849\n",
      "Train Epoch: 38 [5700/38438 (99%)]\tLoss: 0.351844\n",
      "\n",
      "Test set: Average loss: 0.3559, Accuracy: 5685/6784 (83%)\n",
      "\n",
      "Train Epoch: 39 [0/38438 (0%)]\tLoss: 0.359948\n",
      "Train Epoch: 39 [2560/38438 (7%)]\tLoss: 0.377117\n",
      "Train Epoch: 39 [5120/38438 (13%)]\tLoss: 0.427777\n",
      "Train Epoch: 39 [7680/38438 (20%)]\tLoss: 0.366920\n",
      "Train Epoch: 39 [10240/38438 (26%)]\tLoss: 0.397393\n",
      "Train Epoch: 39 [12800/38438 (33%)]\tLoss: 0.404450\n",
      "Train Epoch: 39 [15360/38438 (40%)]\tLoss: 0.317006\n",
      "Train Epoch: 39 [17920/38438 (46%)]\tLoss: 0.378585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 39 [20480/38438 (53%)]\tLoss: 0.431431\n",
      "Train Epoch: 39 [23040/38438 (60%)]\tLoss: 0.377665\n",
      "Train Epoch: 39 [25600/38438 (66%)]\tLoss: 0.393658\n",
      "Train Epoch: 39 [28160/38438 (73%)]\tLoss: 0.459615\n",
      "Train Epoch: 39 [30720/38438 (79%)]\tLoss: 0.404904\n",
      "Train Epoch: 39 [33280/38438 (86%)]\tLoss: 0.356220\n",
      "Train Epoch: 39 [35840/38438 (93%)]\tLoss: 0.386334\n",
      "Train Epoch: 39 [5700/38438 (99%)]\tLoss: 0.494294\n",
      "\n",
      "Test set: Average loss: 0.3621, Accuracy: 5691/6784 (83%)\n",
      "\n",
      "Train Epoch: 40 [0/38438 (0%)]\tLoss: 0.362819\n",
      "Train Epoch: 40 [2560/38438 (7%)]\tLoss: 0.392277\n",
      "Train Epoch: 40 [5120/38438 (13%)]\tLoss: 0.313717\n",
      "Train Epoch: 40 [7680/38438 (20%)]\tLoss: 0.358448\n",
      "Train Epoch: 40 [10240/38438 (26%)]\tLoss: 0.431412\n",
      "Train Epoch: 40 [12800/38438 (33%)]\tLoss: 0.347885\n",
      "Train Epoch: 40 [15360/38438 (40%)]\tLoss: 0.412184\n",
      "Train Epoch: 40 [17920/38438 (46%)]\tLoss: 0.385479\n",
      "Train Epoch: 40 [20480/38438 (53%)]\tLoss: 0.416774\n",
      "Train Epoch: 40 [23040/38438 (60%)]\tLoss: 0.393878\n",
      "Train Epoch: 40 [25600/38438 (66%)]\tLoss: 0.406620\n",
      "Train Epoch: 40 [28160/38438 (73%)]\tLoss: 0.390967\n",
      "Train Epoch: 40 [30720/38438 (79%)]\tLoss: 0.364842\n",
      "Train Epoch: 40 [33280/38438 (86%)]\tLoss: 0.385034\n",
      "Train Epoch: 40 [35840/38438 (93%)]\tLoss: 0.347280\n",
      "Train Epoch: 40 [5700/38438 (99%)]\tLoss: 0.453328\n",
      "\n",
      "Test set: Average loss: 0.3970, Accuracy: 5324/6784 (78%)\n",
      "\n",
      "Train Epoch: 41 [0/38438 (0%)]\tLoss: 0.414190\n",
      "Train Epoch: 41 [2560/38438 (7%)]\tLoss: 0.397681\n",
      "Train Epoch: 41 [5120/38438 (13%)]\tLoss: 0.363632\n",
      "Train Epoch: 41 [7680/38438 (20%)]\tLoss: 0.404007\n",
      "Train Epoch: 41 [10240/38438 (26%)]\tLoss: 0.437220\n",
      "Train Epoch: 41 [12800/38438 (33%)]\tLoss: 0.397086\n",
      "Train Epoch: 41 [15360/38438 (40%)]\tLoss: 0.363859\n",
      "Train Epoch: 41 [17920/38438 (46%)]\tLoss: 0.402216\n",
      "Train Epoch: 41 [20480/38438 (53%)]\tLoss: 0.399658\n",
      "Train Epoch: 41 [23040/38438 (60%)]\tLoss: 0.417507\n",
      "Train Epoch: 41 [25600/38438 (66%)]\tLoss: 0.324410\n",
      "Train Epoch: 41 [28160/38438 (73%)]\tLoss: 0.392946\n",
      "Train Epoch: 41 [30720/38438 (79%)]\tLoss: 0.402820\n",
      "Train Epoch: 41 [33280/38438 (86%)]\tLoss: 0.363698\n",
      "Train Epoch: 41 [35840/38438 (93%)]\tLoss: 0.448448\n",
      "Train Epoch: 41 [5700/38438 (99%)]\tLoss: 0.393585\n",
      "\n",
      "Test set: Average loss: 0.3963, Accuracy: 5383/6784 (79%)\n",
      "\n",
      "Train Epoch: 42 [0/38438 (0%)]\tLoss: 0.420004\n",
      "Train Epoch: 42 [2560/38438 (7%)]\tLoss: 0.431371\n",
      "Train Epoch: 42 [5120/38438 (13%)]\tLoss: 0.374167\n",
      "Train Epoch: 42 [7680/38438 (20%)]\tLoss: 0.423952\n",
      "Train Epoch: 42 [10240/38438 (26%)]\tLoss: 0.362921\n",
      "Train Epoch: 42 [12800/38438 (33%)]\tLoss: 0.332352\n",
      "Train Epoch: 42 [15360/38438 (40%)]\tLoss: 0.366185\n",
      "Train Epoch: 42 [17920/38438 (46%)]\tLoss: 0.393860\n",
      "Train Epoch: 42 [20480/38438 (53%)]\tLoss: 0.356607\n",
      "Train Epoch: 42 [23040/38438 (60%)]\tLoss: 0.346955\n",
      "Train Epoch: 42 [25600/38438 (66%)]\tLoss: 0.335297\n",
      "Train Epoch: 42 [28160/38438 (73%)]\tLoss: 0.376637\n",
      "Train Epoch: 42 [30720/38438 (79%)]\tLoss: 0.384786\n",
      "Train Epoch: 42 [33280/38438 (86%)]\tLoss: 0.382327\n",
      "Train Epoch: 42 [35840/38438 (93%)]\tLoss: 0.385351\n",
      "Train Epoch: 42 [5700/38438 (99%)]\tLoss: 0.346635\n",
      "\n",
      "Test set: Average loss: 0.3537, Accuracy: 5684/6784 (83%)\n",
      "\n",
      "Train Epoch: 43 [0/38438 (0%)]\tLoss: 0.428750\n",
      "Train Epoch: 43 [2560/38438 (7%)]\tLoss: 0.375649\n",
      "Train Epoch: 43 [5120/38438 (13%)]\tLoss: 0.366790\n",
      "Train Epoch: 43 [7680/38438 (20%)]\tLoss: 0.360574\n",
      "Train Epoch: 43 [10240/38438 (26%)]\tLoss: 0.379316\n",
      "Train Epoch: 43 [12800/38438 (33%)]\tLoss: 0.365198\n",
      "Train Epoch: 43 [15360/38438 (40%)]\tLoss: 0.345641\n",
      "Train Epoch: 43 [17920/38438 (46%)]\tLoss: 0.403660\n",
      "Train Epoch: 43 [20480/38438 (53%)]\tLoss: 0.375767\n",
      "Train Epoch: 43 [23040/38438 (60%)]\tLoss: 0.429588\n",
      "Train Epoch: 43 [25600/38438 (66%)]\tLoss: 0.319196\n",
      "Train Epoch: 43 [28160/38438 (73%)]\tLoss: 0.303544\n",
      "Train Epoch: 43 [30720/38438 (79%)]\tLoss: 0.356118\n",
      "Train Epoch: 43 [33280/38438 (86%)]\tLoss: 0.399997\n",
      "Train Epoch: 43 [35840/38438 (93%)]\tLoss: 0.357386\n",
      "Train Epoch: 43 [5700/38438 (99%)]\tLoss: 0.529397\n",
      "\n",
      "Test set: Average loss: 0.3611, Accuracy: 5650/6784 (83%)\n",
      "\n",
      "Train Epoch: 44 [0/38438 (0%)]\tLoss: 0.323785\n",
      "Train Epoch: 44 [2560/38438 (7%)]\tLoss: 0.403216\n",
      "Train Epoch: 44 [5120/38438 (13%)]\tLoss: 0.352089\n",
      "Train Epoch: 44 [7680/38438 (20%)]\tLoss: 0.414205\n",
      "Train Epoch: 44 [10240/38438 (26%)]\tLoss: 0.387517\n",
      "Train Epoch: 44 [12800/38438 (33%)]\tLoss: 0.460958\n",
      "Train Epoch: 44 [15360/38438 (40%)]\tLoss: 0.387817\n",
      "Train Epoch: 44 [17920/38438 (46%)]\tLoss: 0.325445\n",
      "Train Epoch: 44 [20480/38438 (53%)]\tLoss: 0.342148\n",
      "Train Epoch: 44 [23040/38438 (60%)]\tLoss: 0.366629\n",
      "Train Epoch: 44 [25600/38438 (66%)]\tLoss: 0.339334\n",
      "Train Epoch: 44 [28160/38438 (73%)]\tLoss: 0.422352\n",
      "Train Epoch: 44 [30720/38438 (79%)]\tLoss: 0.318850\n",
      "Train Epoch: 44 [33280/38438 (86%)]\tLoss: 0.430163\n",
      "Train Epoch: 44 [35840/38438 (93%)]\tLoss: 0.359218\n",
      "Train Epoch: 44 [5700/38438 (99%)]\tLoss: 0.426300\n",
      "\n",
      "Test set: Average loss: 0.3593, Accuracy: 5675/6784 (83%)\n",
      "\n",
      "Train Epoch: 45 [0/38438 (0%)]\tLoss: 0.357414\n",
      "Train Epoch: 45 [2560/38438 (7%)]\tLoss: 0.370441\n",
      "Train Epoch: 45 [5120/38438 (13%)]\tLoss: 0.374394\n",
      "Train Epoch: 45 [7680/38438 (20%)]\tLoss: 0.341128\n",
      "Train Epoch: 45 [10240/38438 (26%)]\tLoss: 0.411068\n",
      "Train Epoch: 45 [12800/38438 (33%)]\tLoss: 0.359805\n",
      "Train Epoch: 45 [15360/38438 (40%)]\tLoss: 0.398839\n",
      "Train Epoch: 45 [17920/38438 (46%)]\tLoss: 0.361372\n",
      "Train Epoch: 45 [20480/38438 (53%)]\tLoss: 0.372802\n",
      "Train Epoch: 45 [23040/38438 (60%)]\tLoss: 0.423267\n",
      "Train Epoch: 45 [25600/38438 (66%)]\tLoss: 0.388522\n",
      "Train Epoch: 45 [28160/38438 (73%)]\tLoss: 0.389405\n",
      "Train Epoch: 45 [30720/38438 (79%)]\tLoss: 0.385766\n",
      "Train Epoch: 45 [33280/38438 (86%)]\tLoss: 0.362162\n",
      "Train Epoch: 45 [35840/38438 (93%)]\tLoss: 0.349883\n",
      "Train Epoch: 45 [5700/38438 (99%)]\tLoss: 0.376532\n",
      "\n",
      "Test set: Average loss: 0.3543, Accuracy: 5708/6784 (84%)\n",
      "\n",
      "Train Epoch: 46 [0/38438 (0%)]\tLoss: 0.413334\n",
      "Train Epoch: 46 [2560/38438 (7%)]\tLoss: 0.360787\n",
      "Train Epoch: 46 [5120/38438 (13%)]\tLoss: 0.409215\n",
      "Train Epoch: 46 [7680/38438 (20%)]\tLoss: 0.356780\n",
      "Train Epoch: 46 [10240/38438 (26%)]\tLoss: 0.374014\n",
      "Train Epoch: 46 [12800/38438 (33%)]\tLoss: 0.384081\n",
      "Train Epoch: 46 [15360/38438 (40%)]\tLoss: 0.381303\n",
      "Train Epoch: 46 [17920/38438 (46%)]\tLoss: 0.401934\n",
      "Train Epoch: 46 [20480/38438 (53%)]\tLoss: 0.416125\n",
      "Train Epoch: 46 [23040/38438 (60%)]\tLoss: 0.400540\n",
      "Train Epoch: 46 [25600/38438 (66%)]\tLoss: 0.401381\n",
      "Train Epoch: 46 [28160/38438 (73%)]\tLoss: 0.392359\n",
      "Train Epoch: 46 [30720/38438 (79%)]\tLoss: 0.361549\n",
      "Train Epoch: 46 [33280/38438 (86%)]\tLoss: 0.346208\n",
      "Train Epoch: 46 [35840/38438 (93%)]\tLoss: 0.411062\n",
      "Train Epoch: 46 [5700/38438 (99%)]\tLoss: 0.310197\n",
      "\n",
      "Test set: Average loss: 0.3639, Accuracy: 5645/6784 (83%)\n",
      "\n",
      "Train Epoch: 47 [0/38438 (0%)]\tLoss: 0.395923\n",
      "Train Epoch: 47 [2560/38438 (7%)]\tLoss: 0.379408\n",
      "Train Epoch: 47 [5120/38438 (13%)]\tLoss: 0.387361\n",
      "Train Epoch: 47 [7680/38438 (20%)]\tLoss: 0.368557\n",
      "Train Epoch: 47 [10240/38438 (26%)]\tLoss: 0.322041\n",
      "Train Epoch: 47 [12800/38438 (33%)]\tLoss: 0.301656\n",
      "Train Epoch: 47 [15360/38438 (40%)]\tLoss: 0.326799\n",
      "Train Epoch: 47 [17920/38438 (46%)]\tLoss: 0.358673\n",
      "Train Epoch: 47 [20480/38438 (53%)]\tLoss: 0.339903\n",
      "Train Epoch: 47 [23040/38438 (60%)]\tLoss: 0.376913\n",
      "Train Epoch: 47 [25600/38438 (66%)]\tLoss: 0.375053\n",
      "Train Epoch: 47 [28160/38438 (73%)]\tLoss: 0.408925\n",
      "Train Epoch: 47 [30720/38438 (79%)]\tLoss: 0.347680\n",
      "Train Epoch: 47 [33280/38438 (86%)]\tLoss: 0.358468\n",
      "Train Epoch: 47 [35840/38438 (93%)]\tLoss: 0.414404\n",
      "Train Epoch: 47 [5700/38438 (99%)]\tLoss: 0.364679\n",
      "\n",
      "Test set: Average loss: 0.3631, Accuracy: 5675/6784 (83%)\n",
      "\n",
      "Train Epoch: 48 [0/38438 (0%)]\tLoss: 0.400100\n",
      "Train Epoch: 48 [2560/38438 (7%)]\tLoss: 0.366644\n",
      "Train Epoch: 48 [5120/38438 (13%)]\tLoss: 0.362258\n",
      "Train Epoch: 48 [7680/38438 (20%)]\tLoss: 0.352934\n",
      "Train Epoch: 48 [10240/38438 (26%)]\tLoss: 0.423192\n",
      "Train Epoch: 48 [12800/38438 (33%)]\tLoss: 0.403117\n",
      "Train Epoch: 48 [15360/38438 (40%)]\tLoss: 0.417320\n",
      "Train Epoch: 48 [17920/38438 (46%)]\tLoss: 0.376998\n",
      "Train Epoch: 48 [20480/38438 (53%)]\tLoss: 0.321562\n",
      "Train Epoch: 48 [23040/38438 (60%)]\tLoss: 0.372790\n",
      "Train Epoch: 48 [25600/38438 (66%)]\tLoss: 0.380435\n",
      "Train Epoch: 48 [28160/38438 (73%)]\tLoss: 0.360194\n",
      "Train Epoch: 48 [30720/38438 (79%)]\tLoss: 0.340674\n",
      "Train Epoch: 48 [33280/38438 (86%)]\tLoss: 0.338456\n",
      "Train Epoch: 48 [35840/38438 (93%)]\tLoss: 0.377348\n",
      "Train Epoch: 48 [5700/38438 (99%)]\tLoss: 0.231578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.3497, Accuracy: 5695/6784 (83%)\n",
      "\n",
      "Train Epoch: 49 [0/38438 (0%)]\tLoss: 0.325700\n",
      "Train Epoch: 49 [2560/38438 (7%)]\tLoss: 0.346312\n",
      "Train Epoch: 49 [5120/38438 (13%)]\tLoss: 0.354382\n",
      "Train Epoch: 49 [7680/38438 (20%)]\tLoss: 0.333532\n",
      "Train Epoch: 49 [10240/38438 (26%)]\tLoss: 0.367780\n",
      "Train Epoch: 49 [12800/38438 (33%)]\tLoss: 0.394387\n",
      "Train Epoch: 49 [15360/38438 (40%)]\tLoss: 0.391301\n",
      "Train Epoch: 49 [17920/38438 (46%)]\tLoss: 0.361632\n",
      "Train Epoch: 49 [20480/38438 (53%)]\tLoss: 0.371136\n",
      "Train Epoch: 49 [23040/38438 (60%)]\tLoss: 0.306512\n",
      "Train Epoch: 49 [25600/38438 (66%)]\tLoss: 0.394374\n",
      "Train Epoch: 49 [28160/38438 (73%)]\tLoss: 0.339978\n",
      "Train Epoch: 49 [30720/38438 (79%)]\tLoss: 0.378826\n",
      "Train Epoch: 49 [33280/38438 (86%)]\tLoss: 0.362177\n",
      "Train Epoch: 49 [35840/38438 (93%)]\tLoss: 0.391493\n",
      "Train Epoch: 49 [5700/38438 (99%)]\tLoss: 0.433938\n",
      "\n",
      "Test set: Average loss: 0.3523, Accuracy: 5696/6784 (83%)\n",
      "\n",
      "Train Epoch: 50 [0/38438 (0%)]\tLoss: 0.368141\n",
      "Train Epoch: 50 [2560/38438 (7%)]\tLoss: 0.339135\n",
      "Train Epoch: 50 [5120/38438 (13%)]\tLoss: 0.330761\n",
      "Train Epoch: 50 [7680/38438 (20%)]\tLoss: 0.392698\n",
      "Train Epoch: 50 [10240/38438 (26%)]\tLoss: 0.408582\n",
      "Train Epoch: 50 [12800/38438 (33%)]\tLoss: 0.420721\n",
      "Train Epoch: 50 [15360/38438 (40%)]\tLoss: 0.349631\n",
      "Train Epoch: 50 [17920/38438 (46%)]\tLoss: 0.368019\n",
      "Train Epoch: 50 [20480/38438 (53%)]\tLoss: 0.343458\n",
      "Train Epoch: 50 [23040/38438 (60%)]\tLoss: 0.439316\n",
      "Train Epoch: 50 [25600/38438 (66%)]\tLoss: 0.397402\n",
      "Train Epoch: 50 [28160/38438 (73%)]\tLoss: 0.332489\n",
      "Train Epoch: 50 [30720/38438 (79%)]\tLoss: 0.386440\n",
      "Train Epoch: 50 [33280/38438 (86%)]\tLoss: 0.333752\n",
      "Train Epoch: 50 [35840/38438 (93%)]\tLoss: 0.335562\n",
      "Train Epoch: 50 [5700/38438 (99%)]\tLoss: 0.418896\n",
      "\n",
      "Test set: Average loss: 0.3542, Accuracy: 5696/6784 (83%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for epoch in range(1, epochs + 1):\n",
    "        train(net, train_loader, optimizer, epoch,device)\n",
    "        test(net, test_loader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Evaluate Accuracy\n",
    "print('Training Loss:', train_loss[-1])\n",
    "print('Training Accuracy:', train_accu[-1])\n",
    "print()\n",
    "print('Test Loss:', val_loss[-1])\n",
    "print('Testing Accuracy:', test_accu[-1])\n",
    "print()\n",
    "\n",
    "plt.plot(train_loss,'r', label='Training Loss')\n",
    "plt.plot(val_loss,'b', label='Testing Loss')\n",
    "plt.title('Test Loss' + str(val_loss[-1]))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(train_accu,'r', label='Training accuracy')\n",
    "plt.plot(test_accu,'b', label='Testing accuracy')\n",
    "plt.title('Test Accuracy : '+ str(test_accu[-1]))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model_ft,(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
